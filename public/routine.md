This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.claude/
  settings.local.json
public/
  arrow.svg
  eih.svg
  eih1.svg
  favicon.ico
  fillForm.jpg
  openai-logomark.svg
  screenshot.png
src/
  app/
    agentConfigs/
      doctorDtwin/
        chiefAssistant.ts
        commonInstructions.ts
        doctorToPatient.ts
        index.ts
        languageDetector.ts
        operativeReportAssistant.ts
        patientToDoctor.ts
        requestHandler.ts
        surgicalEditor.ts
        translationCoordinator.ts
        translator.ts
      index.ts
      utils.ts
    api/
      chat/
        completions/
          route.ts
      languageDetectorServer/
        route.ts
      operativeScribeServer/
        route.ts
      sendEmail/
        route.ts
      session/
        route.ts
    components/
      UI/
        BackgroundStarryNight.tsx
        card.tsx
        StarryBackground.tsx
      BottomToolbar.tsx
      ClientOnly.tsx
      Eih.tsx
      Events.tsx
      message.tsx
      printableForm.tsx
      SurgeryInfoNeeded.tsx
      surgicalScribePage.tsx
      Transcript.tsx
      TranslationsPage.tsx
    contexts/
      EventContext.tsx
      TranscriptContext.tsx
    hooks/
      useCancelAssistantSpeech.ts
      useConnection.ts
      useHandleSendTextMessage.ts
      useHandleServerEvent.ts
      useOutputMonitor.ts
      usePersistentState.ts
      useSendClientEvent.ts
      useSendEmail.ts
      useSendSimulatedUserMessage.ts
      useUpdateSession.ts
    lib/
      allowedLanguages.ts
      realtimeConnection.ts
    utils/
      cn.ts
    App.tsx
    globals.css
    layout.tsx
    page.tsx
    types.ts
  store/
    elementsStore.ts
    patientDataStore.ts
.gitignore
eslint.config.mjs
LICENSE
next.config.ts
package.json
postcss.config.mjs
README.md
tailwind.config.ts
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".claude/settings.local.json">
{
  "permissions": {
    "allow": [
      "Bash(tree:*)",
      "Bash(find:*)",
      "Bash(wc:*)"
    ]
  }
}
</file>

<file path="public/arrow.svg">
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="#fff" viewBox="0 0 24 24">
  <path fill="#fff" d="M12 3a1 1 0 0 1 .707.293l7 7a1 1 0 0 1-1.414 1.414L13 6.414V20a1 1 0 1 1-2 0V6.414l-5.293 5.293a1 1 0 0 1-1.414-1.414l7-7A1 1 0 0 1 12 3Z"/>
</svg>
</file>

<file path="public/eih.svg">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!-- Created with Inkscape (http://www.inkscape.org/) -->

<svg
   width="210mm"
   height="297mm"
   viewBox="0 0 210 297"
   version="1.1"
   id="svg1"
   xml:space="preserve"
   inkscape:version="1.3.2 (091e20e, 2023-11-25)"
   sodipodi:docname="logoeihlogo.svg"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:xlink="http://www.w3.org/1999/xlink"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg"><sodipodi:namedview
     id="namedview1"
     pagecolor="#000000"
     bordercolor="#000000"
     borderopacity="0.25"
     inkscape:showpageshadow="2"
     inkscape:pageopacity="0.0"
     inkscape:pagecheckerboard="0"
     inkscape:deskcolor="#d1d1d1"
     inkscape:document-units="mm"
     inkscape:zoom="0.2102413"
     inkscape:cx="537.47765"
     inkscape:cy="342.46363"
     inkscape:window-width="1376"
     inkscape:window-height="791"
     inkscape:window-x="0"
     inkscape:window-y="25"
     inkscape:window-maximized="0"
     inkscape:current-layer="layer1" /><defs
     id="defs1" /><g
     inkscape:label="Layer 1"
     inkscape:groupmode="layer"
     id="layer1"><image
       width="836.46185"
       height="460.67795"
       preserveAspectRatio="none"
       xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAB4AAAAQ4CAYAAADo08FDAAABhGlDQ1BJQ0MgcHJvZmlsZQAAKJF9&#10;kT1Iw0AcxV/TakUrDnYQcchQXbSLijjWKhShQqgVWnUwufQLmjQkLS6OgmvBwY/FqoOLs64OroIg&#10;+AHiLjgpukiJ/0sKLWI8OO7Hu3uPu3eA0CgzzQrEAE2vmqlEXMxkV8XgK/zoRh8CGJeZZcxJUhKe&#10;4+sePr7eRXmW97k/R7+asxjgE4ljzDCrxBvEM5tVg/M+cZgVZZX4nHjCpAsSP3JdcfmNc8FhgWeG&#10;zXRqnjhMLBY6WOlgVjQ14mniiKrplC9kXFY5b3HWyjXWuid/YSinryxzneYIEljEEiSIUFBDCWVU&#10;EaVVJ8VCivbjHv5hxy+RSyFXCYwcC6hAg+z4wf/gd7dWfmrSTQrFga4X2/4YBYK7QLNu29/Htt08&#10;AfzPwJXe9lcawOwn6fW2FjkCBraBi+u2puwBlzvA0JMhm7Ij+WkK+TzwfkbflAUGb4HeNbe31j5O&#10;H4A0dZW8AQ4OgbECZa97vLuns7d/z7T6+wFHWXKVhRt29wAAIABJREFUeNrs3dly3DgMBVB1Kv//&#10;y5qHaSWK3It2AsQ5T6lZbDVIOFW8BjUMAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABw1EMJAO4zjuN4+w/6x8PPegAA&#10;AAAAKEIoAHCCFsHu6X8hCIoBAAAAACA9h/0AG5wV9N4RtmZ6VgAAAAAA4BwO9QFe2BueZgxLK31W&#10;AAAAAADoncN7gGF7CFoh/FQTAAAAAADIx2E9UNLacFOoqXYAAAAAAJCJw3mgBKGl2gIAAAAAQAUO&#10;44EuCSXVHgAAAAAAKnL4DnRjTfAodLQuAAAAAADQMwfuQGrfwkXBojUDAAAAAIBKHLID6QgQrSUA&#10;AAAAAPCag3UgjU9hoaDQ+gIAAAAAAAJgIDihoHW37gAAAAAAsJ5DdCAkASD2AQAAAAAAbOfwHAhD&#10;2If9AQAAAAAAxzgwB5oT7GG/AAAAAADAORyUA828C/KEeNhDAAAAAACwjwNy4HZCO+wpAAAAAAC4&#10;hoNx4DZCOuwxAAAAAAC4lgNx4HJCOew5AAAAAAC4h4Nw4DJCOOxBAAAAAAC4lwNw4HRCN+xJAAAA&#10;AABow8E3cBohG/YoAAAAAAC05cAbOEyohj0LAAAAAAAxOOgGDnkVpAnRsH8BAAAAAKANh9zALoIz&#10;7GcAAAAAAIjH4TawiatzsbcBAAAAACAuh9rAaqYksc8BAAAAACA2B9rAVwIx7Hv7HgAAAACAHBxk&#10;Ax8JwbD/7X8AAAAAAPJwiA28JPgC/QAAAAAAQD4Or4EfhF2gLwAAAAAAyMnBNfCHgAv0CQAAAAAA&#10;uTmwBoZhEGqBfgEAAAAAoAcOq6E4QRboHwAAAAAA+uGQGgoTXoE+AgAAAACgLw6ooahlaCWwAj0F&#10;AAAAAEB+DqehGNOKoL8AAAAAAOiXQ2koRDgF+gwAAAAAgL45kIYiXE8Leg4AAAAAgP45jIYCBFGg&#10;9wAAAAAAqMFBNHTMVbSgDwEAAAAAqMUBNHRK6AT6EQAAAACAehw+Q4dcOwt6EwAAAACAmhw8Q2cE&#10;TKBHAQAAAACoy6EzdESwBHoVAAAAAIDaHDhDJwRKoGcBAAAAAMBhM3RAkAR6FwAAAAAAhkEADOkJ&#10;kEAPAwAAAADA5JcSQF6CI8hP3wIAAAAAcCaHzpDQMvgdBiES9NLXehkAAAAAgCMcMkMywl8AAAAA&#10;AADeERpBIq58BgAAAAAA4BPhESQh/AUAAAAAAOCbX0oA+Qh/AQAAAAAAeEWIBAnMp3+FvwAAAAAA&#10;ALxjAhiCW179DAAAAAAAAO+YJITAvPcXAAAAAACALYRJEJTwFwAAAAAAgK0EShCQ8BcAAAAAAIA9&#10;hEoQjPAXAAAAAACAvQRLEIjwFwAAAAAAgCOESxCE8BcAAAAAAICjBEwQgPDX2l/2Q95eAgAAAACA&#10;UgQDEMA8BBTY9b2+L38QX7Tmrb4vAAAAAADQjsN/aEz42+da/vhhe/Habv3eLZ8VAAAAAAC4jkN+&#10;aMjVz32t391reMUvD7T+TAAAAAAAwDEO9aER4W/+NWu1btNz3PG9BcIAAAAAAJCLQ3xoQPhrrY48&#10;x93PMA+c7V0AAAAAAIjNwT004L2/edan5RpFCH0/fX9hMAAAAAAAxOOwHm4m/LU2EZ/haJhrXwMA&#10;AAAAQAwO6eFGJiatSbRnODu4tccBAAAAAKAtB/NwE8FY3PVouRbz9+v29vlNBQMAAAAAwP0cyMNN&#10;hGGx1iDCOrTYEy0CZ7/8AAAAAAAA93EIDzcQ/qp/hOdpNW2sFwAAAAAA4D4O3+Fiph9j1F7wG2vv&#10;CYIBAAAAAOAaDt3hYoIuNZ8/U/XgV38AAAAAAMC1HLbDhYRb7Wou+M215zI+MwAAAAAAROSgHS7i&#10;6ud29Y4U/gp+c68hAAAAAABk44AdLiLMql3nO8Pf3qZn9Q4AAAAAAOznYB0uIMC6t87Rgt+7nqn3&#10;a5NdCw0AAAAAANs5VIeTufr53hpHq+9dk79VwlG/TAEAAAAAANs4TIeTCazuqW/E4Pfq58q4t5a/&#10;ELH6L6fF5zMNDAAAAAAA6zhIhxMJf2vW9o6p3wwB6N6wd9dfXvoLAAAAAABecoAOJ3H18/W1jVjT&#10;6uHv2tB37bNvCZH1GAAAAAAA/OTwHE5i+rdeTe+69jnqdddv/2I5+Xnv/n4AAAAAAJCZQ3M4gfD3&#10;uppGrefVwWzEz/8piL3rOSM8AwAAAAAAROawHE4gAL6mnhXD30zBb+tnjPpcAAAAAADQkkNyOEj4&#10;W6uWV4e/Ga579owAAAAAABDXbyWA/b69m5TttawY3GWZ+o26NtNzzZ+58n4CAAAAAKA2B+NwgOnf&#10;c+sYvYZnT+hG/dyZJ2pNAwMAAAAAUJ1DcdhJ+HtuHSuGvxE/8zJAzbq3e/kcAAAAAACw1S8lAFrJ&#10;FP6e+bWEv9dbPrvr2gEAAAAAqMJEFOxg+ve8Gmao31mBbdTgd7mne9rXJoEBAAAAAKjGBDBwu2rh&#10;b+Sp3/l6THoKSU0CAwAAAABQjUko2Mj07zn1qxT+Rv6sVSZkTQIDAAAAAFCFCWDgNpXC3+hTv/P1&#10;mPQcipoEBgAAAACgCgEwbGD693jtsoS/vX/WihOxQmAAAAAAACoQAAOXyxT+TvY+6zT1K/zNsa5C&#10;YAAAAAAAemOCEVYy/XusbllqduTa5uhXPi/3ceW9rA4AAAAAAPTKBDBwmYzh75H/N1uIWDn0FPgC&#10;AAAAANArB+Cwgunf/TXLFv7ued4s4a99rCYAAAAAAPTPBDBwuozv/N37vBnDX9QIAAAAAIB+CYDh&#10;CxOC++qVqVZ7g7+M1z7bx2oBAAAAAEDfBMDAaTKHv1ueeXzK+G5jgedP85qYAgYAAAAAIDsBMHwg&#10;ONuuykSs/QAAAAAAAEQkAAZOkXFycs8Ub7Zrn/0SwzqmgAEAAAAA6IUAGN4QnG2vVe/v/RUM1ux/&#10;AAAAAADIRAAMHJIx/J1sfe/v4ynjOvklhu01EgIDAAAAAJCRABi+EJz1V6Ns1zgf+Zx2JwAAAAAA&#10;1CIAhhcEZ/3Wae/Vz34RwB4HAAAAAIAMBMDALtWufs68VsLrfbWa/iwEBgAAAAAgEwEwLMzDHsHZ&#10;Zxmvfq64j9lfQz8DAAAAAADIRgAMbJY5XKw2/Ys9DwAAAABALQJgeEPw91rWq5+rBnj28fGauQoa&#10;AAAAAIBMBMAwI+BZJ2uouHX610qTfc8DAAAAAFCPABhYLWsouvW5s045owcAAAAAAEAADE/zYEfw&#10;974+FaZ/s+8BIeW1PxfUFwAAAACAyATAwGqCcfSAHgAAAAAAIDYBMCwIeH6qNPE4juPYyx6wl6+r&#10;nSlgAAAAAACiEgDDIMxZQ5gIegEAAAAAgPgEwMBH2cPxLc/f0/QvegMAAAAAgJoEwDAj/PvXFHBl&#10;r4t15ao9JQQGAAAAACAaATDlCXA+E56C3gAAAAAAIA8BMPCSYBz0CgAAAAAA+QiA4ck0n5qAHgEA&#10;AAAAIDsBMKWZ3FMX0DMAAAAAAPREAAy8VHWyUZCHXgEAAAAAIDMBMAwCnLkeA9C1n8k+QO8AAAAA&#10;AJCdABj4oacgdM9n6SXIE0jeVzu/PAAAAAAAQBQCYMoSjvGKIA8AAAAAAMhMAAz8IRT/3+PxeGSu&#10;hRC7XS31EAAAAAAArQmAKU9Y1n89sge66B0AAAAAAFhLAAwMw2BycUlojF4CAAAAACAjATAlCWhe&#10;632Cceu69xAC2+v31swUMAAAAAAArQmAgRL2BnNTCCxIBQAAAAAAMhAAU5ppvf8JN9ftk0x1srfb&#10;1lBPAQAAAADQigAYGIahTmC4N5jLGAIf/cwVnVEr4TsAAAAAAC0JgClHGFa3HkeDuceTK6HRWwAA&#10;AAAARCUABspNLB4N5rIEwSZR29VO7QEAAAAAaEUATFkCGut+1tfKMOlpGlWNAAAAAACoQQAMhVUO&#10;vM767MtpYCEiegwAAAAAgJZMQFLKPIwxAfx/ParW4crPHm2f2fftalS5xwAAAAAAaOO3EgAVTVO7&#10;V4Rz86uhlxOgwkAAAAAAAOBKgghKmcI4IZxazOtwVw1ahsGmgNvURp8BAAAAAHA3E8BQmFDq2kng&#10;b/VuFQi7lvj9Gly1v1QaAAAAAIC7CICB8uYh3Z3B6KdA+OznEERuXw8AAAAAAMjolxIA/Pve3pbP&#10;MBkXzvyMrT9nFK7FBgAAAACgRw68KUPY87MWQq8ctXkV1u59vpbvIY768+DqOug3AAAAAADu5DCa&#10;MgTA/9ZCGPV9r0Su0ZH9XD0EbvH59RwAAAAAAHdxBTTlCGFYu0ciX5M8XRU9PeeWZ/307uHemYAG&#10;AAAAAKB3v5UA4Kd5uBo5JPz0Xt9Pzz29Z3j+//Yehgp/AQAAAACowOE3ZXgPpzpUq9maa6KrhKKt&#10;P6e+AwAAAADgLg6iKUMA87cOQqj9+yfrHvq0/3sPgaN8Pr0HAAAAAMAdXAFNCZXecco13l21nCXQ&#10;W77XeP7cPV8H7dpnAAAAAACqEQADbJQ5DH4XBPcYAgt/AQAAAACo6JcSUIkAiCv21DxUzTJtPj33&#10;/JmX/ZF5cl74CwAAAABAVSaAAU6QdSr41UTwchI4w+d4VfssawAAAAAAAGdyKE4J2UIsdVDzCM+a&#10;bYo2evir/wAAAAAAuINDaEoQvPytg/Cp3f7784M38Bos90iGidpMU796EAAAAACAq7kCGuBiy0A1&#10;ciA8XQE9PdOraeAov1Dx7h3FAlYAAAAAACoTAAPcaBlORgyElyHw/J8tn/3uZ34X+kaoGwAAAAAA&#10;RCAABmgoQyC8fI5XIeyVYfCn0DdSfQAAAAAAIAIBMEAg3wLhu8LOV1PAr57hWxi89bm/hb131wEA&#10;AAAAALIRANO9tYESRPTp/cERQtBvYfCZfSj0BQAAAACA7xym071ogVnrOgjR7O2t3+PI194b/Pa6&#10;T/UhAAAAAADAQa/eqVq1DnaDfW7v6EUAAAAAAPrmCmiADkwTpSbeAQAAAACgNgEwQEdevZNXEAwA&#10;AAAAAHX8UgKAPj2ejl4PPX0NFQUAAAAAgPgEwACdMwEMAAAAAAB1CIABijDFCwAAAAAA/RMAAxRg&#10;ChgAAAAAAGoQAAMAAAAAAAB0QgAMAAAAAAAA0AkBMAAAAAAAAEAnBMAAfDSO46gKAAAAAACQgwAY&#10;oICjIe7j8XioIgAAAAAAxCcABihiT4g7juMo/AUAAAAAgDwEwACd2zv96+pnAAAAAADIRwAM0LEp&#10;xN07xWv6FwAAAAAAchEAA3TO1c8AAAAAAFCHABigU0JcAAAAAACoRwAM0KEj4a/gGAAAAAAA8hIA&#10;A3RG+AsAAAAAAHUJgAE6IsAFAAAAAIDaBMAAnTga/gqPAQAAAAAgv99KAJDXOI7j9Oej4a9qAgAA&#10;AABAfgJgKMSEp/V893WG4ViAzLZaAwAAAADAVVwBDUUI9/oxPp25pvaHXgQAAAAAoA8mgAESOTv4&#10;NRUOAAAAAAB9MQEMkITwFwAAAAAA+EYADJCAsBYAAAAAAFjDFdAAgY3jOA7D+e+NFSgDAAAAAECf&#10;TAADBHVl+Ku6AAAAAADQJxPAUIzJz7rrdFWgzLb6AwAAAAAAcMD4pBJ/66EKtdZID+g9AAAAAADq&#10;MAEMEMiZk7/zwNHULwAAAAAA1CAABgjiivBX8AsAAAAAALUIgAECODv8FfwCAAAAAEBNv5QAoB/C&#10;XwAAAAAAqE0ADAXN3w1LjPU4GtqOT8JfPQcAAAAAQG0CYChGQNifKfi1tnoPAAAAAAC8AxggqWmq&#10;VLAIAAAAAABMBMAADe25tlnwCwAAAAAAvOMKaCjKO0nzrpvrnvUaAAAAAAC8IwCGgoSHOe2ZFkbP&#10;AQAAAABQiwAYIAFTpAAAAAAAwBoCYIAkTJECAAAAAADfCIChMFOlOdbB1c96DAAAAAAA1hIAQ1EC&#10;ReuANQYAAAAAoD8CYAAAAAAAAIBOCIChOFfUgt4CAAAAAABIY3xSiff1UYX462Cd9BYAAAAAAKxh&#10;AhgAAAAAAACgEwJgwKRiAo/H42Gd9BQAAAAAAEB5roBeVyNVyLEO1kpPAQAAAADAJyaAgWEYBFZZ&#10;TJPA1ksvAQAAAADAKwJgYHg8Hg9ViLEOa8LDab0EjXoKAAAAAACWBMAACQmBAQAAAACAVwTAwB/C&#10;xPbWTgFP/+2W/x49BAAAAABA/wTAwDAMrqzNvnaCR70EAAAAAADDIAAGFgSJ7e0JdIXAegcAAAAA&#10;AKCE8Ukl1tdLFfKuhfXTOwAAAAAA1GYCGCAwoSIAAAAAALCFABj4QegYw553yboKWs8AAAAAAFCb&#10;ABj4x57QkWvXY8815gJJvQMAAAAAQE0CYOAlAWIcW4NFQaReAQAAAAAA6Nae6UmEWj2siTXUKwAA&#10;AAAA1GMCGHhLsBWL9/vqEQAAAAAAgPJMAB+rnSrkXhdrqEcAAAAAAKjFBDDwkYAL9AYAAAAAAHkI&#10;gIG3Ho/HYxgEXRHXxZq0NdV/6hEAAAAAAIhCAAx8JOACvQEAAAAAQB4CYGAVE6exrJ0CNi2sFwAA&#10;AAAAqEUADHxl0hH0BAAAAAAAOQiAgdVMPsZiulcPAAAAAADAkgAYWGWaeBSAUdW0903/AgAAAAAQ&#10;mQAYWE3wFXNNhPJ6AAAAAAAAJgJgYDOBI/Y8AAAAAADEJAAGNnEVNNW4+hkAAAAAgEwEwMBmgrB4&#10;6yGQt+cBAAAAAGAYBMDAAUJH7HEAAAAAAIhFAAzs4ipoeufqZwAAAAAAMhIAA7sJxrDHAQAAAAAg&#10;FgEwcJgp4NhrI8S0pwEAAAAAqEMADBziKuj2hLzn13O+twEAAAAAIBMBMHCYEDgmwfC+ms33NAAA&#10;AAAAZCMABk4hMGtDyGsvAwAAAADAnAAYOJUpYOugZgAAAAAA0I4AGDiNq6Dv9a3OJlm311LNAAAA&#10;AADITgAMnEoIfI9PgaVroc+rJQAAAAAAZCMABk4nBL63zuwn/AUAAAAAAEhmfFIJte+prnv+HfYn&#10;AAAAAAD9MwEMXMYk8L1c/bytVvM9CgAAAAAAvRAAA5cSAp9LHc+rofAXAAAAAIAeCYCBywmBr6nn&#10;nOnfdYS/AAAAAAD0TgAM3EIIfJyQ93j95nsRAAAAAPiPvbvZaiOHwiiKsvz+r6weBDqF7QK7/iR9&#10;2nuUxiSYa8GA01cAwIDqJ5Pweow+ty2P4dwBAAAAADAXG8DApWwCczWbvwAAAAAAAEFs/nldEma1&#10;5TGcMwAAAAAA5mMDGGjCJjBns/kLAAAAAAAQyAag12f0+Wx5zNycKwAAAAAA5mQDGGjKJjBHs/kL&#10;AAAAAMDMBGCgORH4fbXWKnA+n8vyTAEAAAAAwGwEYKALywgsBP+1FnnN5/msxF8AAAAAAIAJCIpe&#10;s5Hn8MrbzMl5AQAAAACALzaAge64EppX2foFAAAAAIDvBGCgS66EfmQO32ch/gIAAAAAwCMBGOhW&#10;+fTxMV/8XPt8xc7vW7/mAQAAAAAA3wnAQPdm3QZexs1aa509dtr6BQAAAACA3wnAwBBm3gbG1i8A&#10;AAAAALxKAAaGMuM28Mzbv7Z+AQAAAADgPQIwMBzbwHOw9QsAAAAAAO8TgIFhzfq7gdPZ+gUAAAAA&#10;gO1uRgCM7FkEFg3HtIz4XkMAAAAAANjGBjAQwbXQY3PdMwAAAAAAHEMABqK4FnosNrcBAAAAAOBY&#10;roAG4rgWun+uewYAAAAAgHMIwEAsIbg/wi8AAAAAAJxLAAbirV0LPUKArLXW0UPp/VXcwi8AAAAA&#10;AJxHAAamsQyPtoLPZ9sXAAAAAACuJwADUxp5K7hntn0BAAAAAKAtARiYmq3gY4joAAAAAADQBwEY&#10;4JOt4PfY9gUAAAAAgP4IwAB31raC7x+bkegLAAAAAAB984N74rnSl6PP0rdvoieeqx7O7tWfMwAA&#10;AAAAsI8f4hNPAObss/Xtm+rB56zWWq88u4IvAAAAAACMzRXQABvdh9H766J/et/W1p5nj88VAAAA&#10;AAB4nQAMcJC1cPpTGP7p7+3108c88+MCAAAAAADt+OE/8VwBzQjn87Rv8s49AAAAAABMxQYwQEMC&#10;LQAAAAAAcKQ/RgAAAAAAAACQQQAGAAAAAAAACCEAAwAAAAAAAIQQgAEAAAAAAABCCMAAAAAAAAAA&#10;IQRgAAAAAAAAgBACMAAAAAAAAEAIARgAAAAAAAAghAAMAAAAAAAAEEIABgAAAAAAAAghAAMAAAAA&#10;AACEEIABAAAAAAAAQgjAAAAAAAAAACEEYAAAAAAAAIAQAjAAAAAAAABACAEYAAAAAAAAIIQADAAA&#10;AAAAABBCAAYAAAAAAAAIIQADAAAAAAAAhBCPEP4YAAATHElEQVSAAQAAAAAAAEIIwAAAAAAAAAAh&#10;bkYAANeotdavP5dSiokAAAAAAHA0ARgATrYMvwAAAAAAcCZXQAPAicRfAAAAAACuJAADwEnu469r&#10;nwEAAAAAOJsADAAnEH8BAAAAAGjB7wCGCS3DlCgF5319+ToDAAAAAOBqNoBhcn4/KZz79ST+AgAA&#10;AABwJQEYEIHhhK+j8slkAAAAAAC4kgAMk7oPU/WTycB7nn3tCL8AAAAAALQiAMPEnkUqERhe58pn&#10;AAAAAAB6czMCmNtXrFqGrK8/C1nwnPALAAAAAECvbAADHx8ftoHhVeIvAAAAAAA9swEM/M82MKwT&#10;fgEAAAAAGIENYOCBbWD4/fyLvwAAAAAA9MgGMPCUbWAQfgEAAAAAGI8NYOBHtoGZlfgLAAAAAMCI&#10;bAADv7INzEyEXwAAAAAARmYDGHjZ2jawjWASrJ1l8RcAAAAAgJEIwMBbyqf7t4vAjGwt/Iq/AAAA&#10;AACMxhXQwCauhSaBjV8AAAAAANLYAAZ2cS00I3LdMwAAAAAAqWwAA7s92wZe/reoRi/W/scEZxQA&#10;AAAAgBQCMHAYIZheCb8AAAAAAMxCAAYOJwTTC+EXAAAAAIDZCMDAaYRgWhF+AQAAAACYlQAMnE4I&#10;5irCLwAAAAAAsxOAgcsIwZxF+AUAAAAAgL8EYOByQjBHEX4BAAAAAOA7ARho5rcQvHwfeHY+1s4U&#10;AAAAAADMSgAGmlsLwcu3CXsIvwAAAAAA8DsBGOjGMuLZCubZOVg7LwAAAAAAwF8CMNAlW8FzE34B&#10;AAAAAGAbARjomq3geYi+AAAAAACwnwAMDOOVreDl+9G/n6Kv1xIAAAAAAN4nAAPD+Wkr+P5tAmJ/&#10;RF8AAAAAADiPAAwM7Z0YfP/+XOO34Ot1AQAAAACA4wjAQIzfYvCztwuPx3sl+Jo9AAAAAACcQwAG&#10;It3HRUH4PIIvAAAAAAD0QwAGpiAIH0fwBQAAAACAfgnAwJS2BuG1v5/o1dA700wAAAAAAKB3AjDA&#10;x+tB+LfHR4yg74bekT9XAAAAAABIJwADPLEWN7eG4Vf//SNtDbstnisAAAAAAHAMARjgDVvD8N73&#10;b/m5AQAAAAAA4xCAAQ7wajxtEX6FXQAAAAAAmIcADHAhMRYAAAAAADjTHyMAAAAAAAAAyCAAAwAA&#10;AAAAAIQQgAEAAAAAAABCCMAAcCG/BxoAAAAAgDMJwAAAAAAAAAAhBGAAAAAAAACAEAIwAAAAAAAA&#10;QAgBGAAAAAAAACCEAAwAAAAAAAAQQgAGAAAAAAAACCEAAwAAAAAAAIQQgAEAAAAAAABCCMAAAAAA&#10;AAAAIQRgAAAAAAAAgBACMAAAAAAAAEAIARgAAAAAAAAghAAMAAAAAAAAEEIABgAAAAAAAAghAAMA&#10;AAAAAACEEIABAAAAAAAAQgjAAAAAAAAAACEEYAAAAAAAAIAQAjAAAAAAAABACAEYAAAAAAAAIIQA&#10;DAAAAAAAABBCAAYAAAAAAAAIIQADAAAAAAAAhBCAAQAAAAAAAEIIwAAAAAAAAAAhBGAAAAAAAACA&#10;EAIwAAAAAAAAQAgBGAAAAAAAACCEAAwAAAAAAAAQQgAGAAAAAAAACCEAAwAAAAAAAIQQgAEAAAAA&#10;AABC3IwA2KrWWk3hu1JKMQUAAAAAAKAVARjYRPxdn8uVEXjP69AqVl/9nEecEQAAAAAAbOUKaOBt&#10;y6AmkD3OQRwHAAAAAABasQEMbPYVPUXgf/NoFX/feQ16CdRXP+cRZwQAAAAAAO+yAQxsJpKZBwAA&#10;AAAA0BcBGAAAAAAAACCEAAwAAAAAAAAQQgAGAAAAAAAACCEAAwAAAAAAAIQQgAEAAAAAAABCCMAA&#10;AAAAAAAAIQRgAAAAAAAAgBACMLBZKaWYgnkAAAAAAAD9uBkBsFWttZZSSq21zj4LcwAAAAAAAHpg&#10;Axh423LTVfR8nINNYAAAAAAAoBUBGNhE5DQXAAAAAACgP66ABjYTOwEAAAAAAPpiAxgAAAAAAAAg&#10;hAAMAAAAAAAAEEIABgAAAAAAAAghAAMAAAAAAACEEIABAAAAAAAAQgjAAAAAAAAAACEEYAAAAAAA&#10;AIAQAjAAAAAAAABACAEYAAAAAAAAIIQADAAAAAAAABBCAAYAAAAAAAAIIQADAAAAAAAAhLgZAelK&#10;KaXWWk3iHGb7/MyZAgAAAAAA0IINYGAz8ddcAAAAAACAvgjAwCbLyGnj9XEOIjAAAAAAANCCK6CB&#10;Xb6ipwj8bx7iLwAAAAAA0IoNYGAXsdM8AAAAAACAfgjAAAAAAAAAACEEYAAAAAAAAIAQAjAAAAAA&#10;AABACAEYAAAAAAAAIIQADAAAAAAAABBCAAYAAAAAAAAIIQADAAAAAAAAhBCAgV1KKcUUzAMAAAAA&#10;AOjDzQiAPWqttZRSaq119lmYAwAAAAAA0JoNYGCT5aar6Pk4B5vAAAAAAABACwIwsJnIaS4AAAAA&#10;AEBfXAEN7CJ2AgAAAAAA9MMGMAAAAAAAAEAIARgAAAAAAAAghAAMAAAAAAAAEEIABgAAAAAAAAgh&#10;AAMAAAAAAACEEIABAAAAAAAAQgjAAAAAAAAAACEEYAAAAAAAAIAQAjAAAAAAAABACAEYAAAAAAAA&#10;IIQADAAAAAAAABBCAAaABmqt1RQAAAAAADjazQiAPUSsR6WUYgoAAAAAAEALNoCBzcRfcwEAAAAA&#10;APoiAAObLCOnjdfHOYjAAAAAAABAC66ABnb5ip4i8L95iL8AAAAAAEArNoCBXcRO8wAAAAAAAPoh&#10;AAMAAAAAAACEEIABAAAAAAAAQgjAAAAAAAAAACEEYAAAAAAAAIAQAjAAAAAAAABACAEYAAAAAAAA&#10;IIQADAAAAAAAABBCAAZ2KaUUUzAPAAAAAACgDzcjAPaotdZSSqm11tln0XIOI87/6ufsjAIAAAAA&#10;MAMbwMAmy01XYe1xDjaBAQAAAACAFmwAA5vZ/F2fS+LHGvU5i/EAAAAAAMxEAAZ2EdcAAAAAAAD6&#10;4QpoAAAAAAAAgBACMAAAAAAAAEAIARgAAAAAAAAghAAMAAAAAAAAEEIABgAAAAAAAAghAAMAAAAA&#10;AACEEIABAAAAAAAAQgjAAAAAAAAAACEEYAAAAAAAAIAQAjAAAAAAAABACAEYAAAAAAAAIIQADJOq&#10;tVZTAAAAAAAAyCIAAwAAAAAAAIQQgAEAAAAAAABCCMAAAAAAAAAAIQRgAAAAAAAAgBACMAAAAAAA&#10;AEAIARgAAAAAAAAghAAMAAAAAAAAEEIABgAAAAAAAAghAAMAAAAAAACEEIABAAAAAAAAQgjAAAAA&#10;AAAAACEEYAAAAAAAAIAQAjAAAAAAAABACAEYAAAAAAAAIIQADAAAAAAAABBCAAYAAAAAAAAIIQAD&#10;AAAAAAAAhLgZAQCzqbVWUwAAAAAAIJEADBMTwQAAAAAAAIDhCJ0AAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAA8F97cEgAAAAAIOj/az+YAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA&#10;AAAAAAAAAAAAAAAAAAAAAAAAAAAAAGAL/9bTl1F+Et4AAAAASUVORK5CYII=&#10;"
       id="image1"
       x="-43.834751"
       y="-79.951271" /></g></svg>
</file>

<file path="public/eih1.svg">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!-- Created with Inkscape (http://www.inkscape.org/) -->

<svg
   version="1.1"
   id="svg1"
   width="138.66667"
   height="196"
   viewBox="0 0 138.66667 196"
   xmlns:xlink="http://www.w3.org/1999/xlink"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg">
  <defs
     id="defs1" />
  <g
     id="g1">
    <image
       width="135.34464"
       height="194.33897"
       preserveAspectRatio="none"
       xlink:href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAANAAAAEmCAYAAAATGB7EAAAA9HpUWHRSYXcgcHJvZmlsZSB0eXBl&#10;IGV4aWYAAHjabVHZEUMhCPynipSgrKKW867MpIOUH0TeOcERcDnkoO37edOrEzemlEuVJhKUUkuN&#10;J1VqGDQbjyEZN1rdpO8bTiyuskqoxDA09oBNcT6ShuafxN1/T7QrcVItn4YpOT4/8GVIrs9EXgGi&#10;/+y1z54IPPDo78UrlVbLrbVVwp3qeTMEhSXr2QqkyrtYOlmCRUX/tL/pCqSi416zFgDmDRFBOZBG&#10;Zeg3Y1IJ41n9oiFAIxWMnl/ddX0cig3S+/DCdYDXeRyyr9jbo9tKcRrMT46Qv3Rtnfbe6QcuGnqF&#10;EI7VmgAAAYNpQ0NQSUNDIHByb2ZpbGUAAHicfZE9SMNAHMVfU0ulVBzsIOIQoTpZEBVxrFUoQoVQ&#10;K7TqYHL9hCYNSYqLo+BacPBjserg4qyrg6sgCH6AuAtOii5S4v+SQosYD4778e7e4+4dIDSrTDV7&#10;4oCqWUY6mRCzuVUx+Ao/AghhAiMyM/U5SUrBc3zdw8fXuxjP8j735+jLF0wG+ETiONMNi3iDeGbT&#10;0jnvE0dYWc4TnxOPG3RB4keuKy6/cS45LPDMiJFJzxNHiMVSFytdzMqGSjxNHM2rGuULWZfznLc4&#10;q9U6a9+TvzBc0FaWuU5zGEksYgkSRCioo4IqLMRo1Ugxkab9hId/yPFL5FLIVQEjxwJqUCE7fvA/&#10;+N2tWZyadJPCCSDwYtsfo0BwF2g1bPv72LZbJ4D/GbjSOv5aE5j9JL3R0aJHQP82cHHd0ZQ94HIH&#10;GHzSZUN2JD9NoVgE3s/om3LAwC0QWnN7a+/j9AHIUFepG+DgEBgrUfa6x7t7u3v790y7vx+XR3K1&#10;k2N7MQAAD0lpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBp&#10;ZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+Cjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6&#10;bnM6bWV0YS8iIHg6eG1wdGs9IlhNUCBDb3JlIDQuNC4wLUV4aXYyIj4KIDxyZGY6UkRGIHhtbG5z&#10;OnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+CiAgPHJk&#10;ZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIKICAgIHhtbG5zOnhtcE1NPSJodHRwOi8vbnMuYWRv&#10;YmUuY29tL3hhcC8xLjAvbW0vIgogICAgeG1sbnM6c3RFdnQ9Imh0dHA6Ly9ucy5hZG9iZS5jb20v&#10;eGFwLzEuMC9zVHlwZS9SZXNvdXJjZUV2ZW50IyIKICAgIHhtbG5zOkdJTVA9Imh0dHA6Ly93d3cu&#10;Z2ltcC5vcmcveG1wLyIKICAgIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMv&#10;MS4xLyIKICAgIHhtbG5zOmV4aWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20vZXhpZi8xLjAvIgogICAg&#10;eG1sbnM6dGlmZj0iaHR0cDovL25zLmFkb2JlLmNvbS90aWZmLzEuMC8iCiAgICB4bWxuczp4bXA9&#10;Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iCiAgIHhtcE1NOkRvY3VtZW50SUQ9ImdpbXA6&#10;ZG9jaWQ6Z2ltcDpmZDk0Yjc1Yi02MDFlLTRjZDgtYWMwYi1hMGE1ZmRiYWU1MTAiCiAgIHhtcE1N&#10;Okluc3RhbmNlSUQ9InhtcC5paWQ6MTE1MmJiYWUtNmQ3NC00N2Y0LWIyMjQtZDQ4ZTFiM2MzN2Yy&#10;IgogICB4bXBNTTpPcmlnaW5hbERvY3VtZW50SUQ9InhtcC5kaWQ6NmZjNmNhNDgtOGEwMy00M2Qy&#10;LWFkZDctNWU3MGZlZGI1OTEwIgogICBHSU1QOkFQST0iMi4wIgogICBHSU1QOlBsYXRmb3JtPSJN&#10;YWMgT1MiCiAgIEdJTVA6VGltZVN0YW1wPSIxNzQxMTc0NzY4NjEwOTg0IgogICBHSU1QOlZlcnNp&#10;b249IjIuMTAuMzQiCiAgIGRjOkZvcm1hdD0iaW1hZ2UvcG5nIgogICBleGlmOlBpeGVsWERpbWVu&#10;c2lvbj0iMjA4IgogICBleGlmOlBpeGVsWURpbWVuc2lvbj0iMjk0IgogICB0aWZmOk9yaWVudGF0&#10;aW9uPSIxIgogICB4bXA6Q3JlYXRvclRvb2w9IkdJTVAgMi4xMCIKICAgeG1wOk1ldGFkYXRhRGF0&#10;ZT0iMjAyNTowMzowNVQxNTozOToyNiswNDowMCIKICAgeG1wOk1vZGlmeURhdGU9IjIwMjU6MDM6&#10;MDVUMTU6Mzk6MjYrMDQ6MDAiPgogICA8eG1wTU06SGlzdG9yeT4KICAgIDxyZGY6U2VxPgogICAg&#10;IDxyZGY6bGkKICAgICAgc3RFdnQ6YWN0aW9uPSJzYXZlZCIKICAgICAgc3RFdnQ6Y2hhbmdlZD0i&#10;LyIKICAgICAgc3RFdnQ6aW5zdGFuY2VJRD0ieG1wLmlpZDpjNDRlNGE4Yi02M2Y1LTRjNWUtYmQy&#10;Zi00MGFkMmI0ZGY0MTEiCiAgICAgIHN0RXZ0OnNvZnR3YXJlQWdlbnQ9IkdpbXAgMi4xMCAoTWFj&#10;IE9TKSIKICAgICAgc3RFdnQ6d2hlbj0iMjAyNS0wMy0wNVQxNDo0Nzo1NSswNDowMCIvPgogICAg&#10;IDxyZGY6bGkKICAgICAgc3RFdnQ6YWN0aW9uPSJzYXZlZCIKICAgICAgc3RFdnQ6Y2hhbmdlZD0i&#10;LyIKICAgICAgc3RFdnQ6aW5zdGFuY2VJRD0ieG1wLmlpZDoxMWU2Mjg4Ny0yYzgxLTRkZGEtOTNk&#10;YS03MTg3OGE4MTFmODUiCiAgICAgIHN0RXZ0OnNvZnR3YXJlQWdlbnQ9IkdpbXAgMi4xMCAoTWFj&#10;IE9TKSIKICAgICAgc3RFdnQ6d2hlbj0iMjAyNS0wMy0wNVQxNTozOToyOCswNDowMCIvPgogICAg&#10;PC9yZGY6U2VxPgogICA8L3htcE1NOkhpc3Rvcnk+CiAgIDxleGlmOlVzZXJDb21tZW50PgogICAg&#10;PHJkZjpBbHQ+CiAgICAgPHJkZjpsaSB4bWw6bGFuZz0ieC1kZWZhdWx0Ij5TY3JlZW5zaG90PC9y&#10;ZGY6bGk+CiAgICA8L3JkZjpBbHQ+CiAgIDwvZXhpZjpVc2VyQ29tbWVudD4KICA8L3JkZjpEZXNj&#10;cmlwdGlvbj4KIDwvcmRmOlJERj4KPC94OnhtcG1ldGE+CiAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAK&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;ICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAg&#10;IAogICAgICAgICAgICAgICAgICAgICAgICAgICAKPD94cGFja2V0IGVuZD0idyI/PvXw7wUAAAAJ&#10;cEhZcwAAFiUAABYlAUlSJPAAAAAHdElNRQfpAwULJxxPcGvDAAAAEnRFWHRDb21tZW50AFNjcmVl&#10;bnNob3T7EasKAAAQGElEQVR42u2du44kSRWG42TXoNXuGICQED5ICAlnQcKFF+BFeAleYU2kGReD&#10;B8BdhImYwUEIIVyEhzVctDtdB6OzZ7OrM6syIuNyTsT3SaudS09VRsT541wyLiEAAAAAAAAAAAAA&#10;AAAAAAAAAAAA+EbogvaoqmYdVBHGFQEhjqIDj8gQUG9iOWrUrb8fAUExg7VinB6fGQENJhpvhtdj&#10;mxCQIwPrzbhGay8CwojoBwSEsdA/CAijoN+G6jPBABBNqb4coR+FwUY09C0CSh5ghIOQEBCDSd8j&#10;IHIchISATHBWVUE0SwM+hRA0hHAWEUVICOjqAOmicXgbPFJJph4HRR7+e414jM7aMzFhNx6o4mzm&#10;VTg5DMhj2z2PoSAeP+JI+t6t0OOin1R1EpEzYzmAgDx09hHBxLTlfBG67hXQlqBU9S6EcH78uNqi&#10;8iYk3H1lweR61o3ve6chvFwM7hsR+fGW6G48yJ2InFX1IxH5H2PcgYAuO7Z1p9beiJa7enVZtVwz&#10;iJZ9bG28Vz23F+FY6sy151k+15LC4nkTQvj5HHalG4GITBvP2rIyJs/zNHdVOjPiWWLlOWo9z8pX&#10;/kZVv1liImjZTus24C6Ea+11Wu8V2vj+n4jIH3J+vkR6nxbe32peJIgnTjg1nqOW4d4SkAchtRaR&#10;IJ6nrFWoan1/beHEfr4VIVkSkSCe59+r4fmLxh6Fk/o9FoRkRUQyunhaGoM34VgTkgURTYjn+eDX&#10;KA6U/m5V/WPp71n7HJ3D4BqVMgtlbpNv8FtUt3rxOLkKIKnGqCH8JYTwg5pbSVpW6GQk8bQKOVoK&#10;52iBoISn6ElEwyzTsOR1Cq+Hy+ptjhQYdDawxz+YKvf3MALK0dBry/EtiDVjO7O93K0l7uWX9CYi&#10;6UE81vOrHN+b++Vuzb45r3zXVHHcS455t2+SLeRX1kTTOJQVfdhnVEVItezsNIJ4KnidVzmNstRS&#10;oqbVqofTgORcqdQsIvIkjFTVEm0VxHP8+3KcAlR6/Z21NWSXQtrjiVK2nZdudzdvjA3kOycRuW9V&#10;EPAknjURec2Jqq9E6FQ8IUY8ezfk9SyeS9HcCu1UVVT1bcp+INdFhNIVNwtLgKyuZvawJTrGEx1t&#10;TwlbnGoa2qjiqbH2reUsXMsT5Vz7lss23dbiPYhn7YzuFs/q5ZDCGp4od79UyYF6EE9Mm5YeRxt4&#10;HM+Hb8zHMkdVJWPau/y3OfppKj2AxZdSNFjxKztnx9kYTjVDNU+h27VQbk+xJcekcVREU0lDGyk0&#10;2Tp6K7a0Pap4Vvs0sviSerjlEZudPA1gyyOtrrXJ0okx3s9Oi+231H42WYUr6R2slmQ3vA7XqmTK&#10;h/ZMDKl5TY58aCplSL2I59qkYPk9i+tb35aGnWBjNfOhyfrgWTRSa0cN9xK+3fJCMflQLVudcg9c&#10;0WUTLc//uvLdhGxl+3tv0t8ilDN9uHzrittaZ14+k0Xx9CjolMpZDY88WTVyQ+HIF/LV5VNmQ6Se&#10;by7YOoJ4T/UzpbQd05eTB2NoPKP+bX6mN4RtPryrm7Epdd2EpSs1LD1TbGGjF++zFUrfanPKmM0/&#10;/rviHqjUYBlbafD20vvgeWBJljMRapxz1oi/qupHIYRPEY+9UO7Dgt2N8w72/MzGvyl7VkjPoVsI&#10;T892VtVveQiNRgvhLu1lz8+UeD6Th8ubeCn58EwfhxA+Y77vo6BQQkSTd0MvNjgh/F5E/hNC+D43&#10;2/oQkYvbGUoIyJz3Wbx3eNwlORmfLPZe1+gxhLvVrj2vPVJsbE6btEgIN0BC/VZVP5a5Ege+Q7lr&#10;grvyuTd/rvmpJhZDwseMU0L4JITw79pXPvbSj7XbFLNvy8WpPB3lQ0C+lE9APXufhWh+3XMY02Pb&#10;WhQUkkK43gX0GMJNFweUWzfU3sK4FHvb0wc5+2m3BzpnlrT1wV480CchhF/WntnATpiWZ0ZW1ZxX&#10;U1henLl4tDdrz2t9W0MPIj/S1zELTRM+W5JzIAnh9WChxqdbz+lBSN5Dtxr5YMJB9RqdA42S++xp&#10;c6ubvkfKg3K0oURJW1VfiMiXUR7I+/XnJZ55a0AszPruD1M0fL7GpXiiQ7gRQ4tb9/hYzkFGLnjE&#10;FBMijst6Nt6nkoodaaAuB8HKaaWl7gYdMfx8zH806CTh4arJifDt+Ax2zSOteac9jBzG1bKx5H76&#10;rbzYVUTIPSN4S3BzPW/OiajlXTgevU/p9XGn3IPW2wwWuyU4p9HnNDTLoZznXO3UyjAJMOL6ZvNk&#10;mkUocflv5WIpkkURFb+GfmU5Vszf3/x8wjd/z/6sYLEyoNdyOMs3W7QYvyPjy3YGh+GGXDKvEJGV&#10;gsWaUVhog6dFuoc8UO7VBz28Hbfcjmvlc0ul9drPcMv+klZ+BxU8UGJuYjXxXSunP3qjvbfrlTTi&#10;XjzPAz+7q+KBetqnYuk6x5zeqGQbLKwfLLI27vPPT3igg55oa2a17I22PGqJNmyJuIdK7N//+9O7&#10;qWai3Ev5+tY6OGti2iuinEK6cmu5WOiDHLb53Xe/eHEKcHhQbl3EZWHy2HonFLOWj8nzgm//4xun&#10;4RpdeHa7dkZz676+9mK11CViXdvQ17/3r93uN5X5oPZXoy6t1wyUfqYRxyLl75/9fAj5auJXHzqs&#10;LzWBYzN+rgWuo4xL7kqcaqX3QBLCa8RzvSCxxtEZ9WjY2XOonWNCEhGt4oHIp+p6rYg9/sN6oVwr&#10;EqacIQXU91pbRnDeuQmQcT8GZeyOwpInHoWuqcJUIkGFtp7p8fdzBfSuVCEC2M7Qv1cK4f2Z8AwB&#10;QYI3IrdFQHBYROS5CAgO8Cu6oOAkdfkH7ETti+Vb1knKrzzx0B9ruWJqX+CBBjGWKeK0HyCEw+sg&#10;jM28MOfnkWB26nGezJIVrjocFQTUqWhuiQIPhYAQTWKY0tfJOAgIKoimVk7gvR8RECHarc97hedB&#10;QMMK58idoRoeztFGNfkmDwTUuXC2PhPvgwciTEv47AnhICCEk/bZiMeogObjxXivYCSsImTz54Ek&#10;PL3nCSIMHOEgIGgknpJhINQTEN6nsngQzmAeyPIt0S048j4H0XQkIAoI8YYfa+x4mzIRgAkB3RLP&#10;0WvEGWyEQwiHGHZ5H0RjO3xGQA69DaLBA1FI2BADBQEEBInehZee/gsIIWQ4VERVRVWzX+A60mD2&#10;cmv1iEyZPuOu9UzgNXFFOH4LCFkEJCL3gZUIJgYT6k/aUyZDuMdYgBCugxkBoOYkzsmknYYWUKeP&#10;J+8zgPeBRESEcMy+BycSzrL2O3kTwjUauK2rNRCSr0l66mUm8CouhEQIRxh3sL0IqWxfl5y0CeHw&#10;SOBNQKOFcU+und8hBITkx9aaeyAMAiF5tilCOKNeaK+Q6NlBiwhHDGrUWXJNSIioTfHAnAcawRBy&#10;GT8iwgMNWUxARH15HxMeaMRQLtdSHkQ0uAeiqPB8Bk0pMNCbbbyPGQGNWlDIVV1DRHig4b1RrrBu&#10;9IrmrYMrc79Dm2o18NaDj17WzhnWjSqemJ/L1aeT1QbjjeKERBjXpg8mqx0wutCOLOMZpe9Szhw3&#10;d6xVTbeLkAjtrNnQZNFgEFGckEYP4/a22/2pPHtDNOL5OCGNvDGxVehm1gORD+GpPYX/U6ZGSWlh&#10;ICI89d5LmnPfhO7SA5EPISKreU92AcVeMhzjhciHdvNn8p5B9wPFiAgvtNlHP1TVr5H31MXEjtRS&#10;HTpQXvB27tMvyHvqRi5mNtTFhnKji2j5IlVEfjT/2Zuewl7r4gkhhM0Xczkf4tpnxja+ZWdZN6wS&#10;Y9ejePbY494+NLUjNeXnRz/ddCGeN4Rt9SeO5h4otXoyoie61uZelvTUEE9XHii1SDCaJ9prMCOI&#10;x1KbzQgoRRCjiOh8w7B6aHeMeCx5W7P7gRDR00qbIh6T7e1iO0PvRiUhhGljO4P38O2IeCy012QO&#10;lNIxPYkoJZHuWTxrmwettLer7Qw9iChqRh4gbFsbQ0uTxeS1w2NE5NUbXTOU8yI38uZ9jpSqrbW1&#10;y+0MXq8CiVlxLIvcyGNRJEU8Fttk3gMdEVGP18l7ff6YUMzTS3IXIdyR3MaLN9rjfTyuvtjyOr20&#10;0U0OdFRE3r2RV/HEeB2PbXR1NvZREXjwRjlWrHv3Ol7E405AOUTgzRt5FE+MGDxU2q5x8piQXu5/&#10;efx1TMeLiGwdOG51AK0+19bkM8LeLtfXmxx9cWrx2NzLScGycV3rpz3XjHgXj3sB5RCRVSF5LRDc&#10;CsE85ztdCihHccGCkK4tXbJmYCl5S2xhAQE5Ky7gkfaFa/MSotcxeU5vXudJO7aMrvaW7hrhRe4k&#10;uUSbLBnb2rPobDQp2+6tCCfnlu5T6JCtClvq4K1V/byEW3s57zzgfO/au1HOrOhSQFtGf9QT7tli&#10;cbRytib+GrOxLrzLEa/Rc7g2lIBueaOjA7un+pdrFj7iPfeGo/OHn0Tk3nKIi4CMeKPcuVmsd7pm&#10;YDm90JEtIDs//25E4QwloD1CyjngMe+mYg5Oz11pzCHKZdg34imxpzAgJfKjWGNNMfwjXilHu1Y9&#10;aBj7CppTGJiW6+GOJuY1QyZVvdMQ3l8WGbi7aXAB7cmPLBhKi++/ItqkQgMCGlRIa3/W48x783oZ&#10;PA4Cip3tS73r8SIawjQElDV0uuWdvG6zRjAIyIR3shbqlX4HBAioWqhX0mBTt24wigjITah31OBz&#10;Ph8gIFeCqiUehIKAhhYX+GOiCwAQEAACAkBAAAgIABAQAAICQEAACAgAEBAAAgJAQADOMb2Y1OtN&#10;CLELRmvt57G8b6jF+XZ4IAA8kP1ZppbHTL0yxOr3lBxrK9EJHggAAQEgIAAEBICAAGAXLqpwo96M&#10;DXggADxQKzgCCvBAAAgIABAQFEFVZevPVHWa/39HDgSjCuTJrdwfctQQ3oUQXs4/s/bvVv/fU65r&#10;WkDntanNurGFEKZOix/6/Pcvj3xeD51kuwrnsEN7LhtOBu41QkApRjnIdgagiACAgAAAAQEgIAAE&#10;BNApbGeA3ZwZB18CehwtT+9WerYwlsY7E9DEdgZrob6EEFREdF7jtpwv7kII5/Dw2u5+jhwmETkv&#10;Iom75eeJyJePa+UQEPTreUT00sEuhTHzfuXfnS9+fz//8v7K51BEABjNNQMAAgJAQABu4HqTMkk3&#10;1UM8EAC49kDeZnRWTOCBAAABASCg0fhT5p8DcqDxmNeGSXhYNqPhq3Vj96rKeFnLz7cS4ZyJe+pn&#10;ckt3vu+o+T1HbKRmP6z921hbZUaz4HXoAkI4CzO520S0Ujst96fXsaaIAICAABAQAAICQEAAgIAA&#10;EBAAAgIwxT8REEAiGsJ3cn1W1ZUIbDiDxsJZ/TUeCGAHEvIfT1zFA3HIBvQKHggAAQEgIAAEBICA&#10;AGAXz6pwGtJLfaoqi7tkPvB4NSClOBjCA6W+ZFoTz4e/o68BAAAAAAAAAAAAIB/zIecAcIVpRTii&#10;qhI4Nxsg2fvw3hMAQQEAAAAAAAAAAAAAAAzL/wE8BW8tyhV+VwAAAABJRU5ErkJggg==&#10;"
       id="image1"
       x="3.3220339"
       y="2.4915254" />
  </g>
</svg>
</file>

<file path="public/openai-logomark.svg">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 20010904//EN"
              "http://www.w3.org/TR/2001/REC-SVG-20010904/DTD/svg10.dtd">

<svg xmlns="http://www.w3.org/2000/svg"
     width="36.6908mm" height="51.861mm"
     viewBox="0 0 208 294">
  <path id="Selection"
        fill="none" stroke="black" stroke-width="1"
        d="M 10.00,288.00
           C 8.32,287.71 7.05,287.75 5.74,286.40
             3.09,283.69 4.00,271.11 4.00,267.00
             4.00,267.00 4.00,199.00 4.00,199.00
             4.00,199.00 4.00,140.00 4.00,140.00
             4.00,140.00 4.00,110.00 4.00,110.00
             4.05,80.44 18.30,53.04 41.00,34.46
             80.92,1.80 141.50,5.36 178.96,39.85
             189.41,49.47 204.19,69.37 205.00,84.00
             201.29,81.22 200.42,76.07 198.51,72.00
             195.61,65.81 190.71,58.39 186.49,53.00
             168.27,29.75 140.21,16.08 111.00,14.09
             99.49,13.30 85.89,16.04 75.00,19.67
             64.45,23.18 58.16,26.28 49.00,32.72
             29.89,46.16 15.14,66.31 9.16,89.00
             5.10,104.36 6.00,120.28 6.00,136.00
             6.00,136.00 6.00,204.00 6.00,204.00
             6.00,204.00 6.00,255.00 6.00,255.00
             6.00,260.01 5.45,278.45 6.72,281.96
             6.72,281.96 10.00,288.00 10.00,288.00 Z
           M 16.00,277.00
           C 16.00,277.00 16.00,105.00 16.00,105.00
             16.02,94.79 17.77,90.46 21.00,81.00
             25.05,69.17 32.16,58.75 41.00,50.00
             79.21,12.18 145.53,14.27 179.49,57.00
             190.01,70.24 197.97,88.93 198.00,106.00
             198.00,106.00 198.00,143.00 198.00,143.00
             198.00,143.00 198.00,277.00 198.00,277.00
             198.00,277.00 16.00,277.00 16.00,277.00 Z
           M 133.00,29.00
           C 115.73,26.57 112.13,22.99 93.00,26.46
             60.43,32.38 33.02,53.05 22.33,85.00
             19.34,93.95 18.02,97.36 18.00,107.00
             18.00,107.00 18.00,275.00 18.00,275.00
             18.00,275.00 196.00,275.00 196.00,275.00
             196.00,275.00 196.00,106.00 196.00,106.00
             195.73,82.85 179.98,57.73 162.00,44.04
             158.45,41.34 145.13,32.57 141.04,32.70
             138.86,32.77 138.38,33.68 137.00,35.00
             143.64,37.86 152.36,41.38 156.00,48.00
             148.06,44.84 143.12,42.07 134.00,44.99
             117.08,50.40 110.97,72.02 121.56,85.99
             134.29,102.78 158.69,98.16 166.23,79.00
             170.24,68.78 166.60,64.20 164.00,55.00
             170.03,57.10 174.03,62.79 177.41,68.00
             185.56,80.59 189.00,91.13 190.09,106.00
             190.09,106.00 190.82,113.00 190.82,113.00
             190.82,113.00 190.09,120.00 190.09,120.00
             187.03,161.83 152.10,192.89 111.00,195.82
             103.99,196.32 89.95,193.71 83.00,191.71
             73.05,188.85 64.32,184.46 56.00,178.24
             22.49,153.21 13.89,104.41 35.46,69.00
             43.69,55.50 56.06,44.78 70.00,37.49
             80.12,32.20 94.60,29.13 106.00,29.00
             113.88,28.91 113.21,29.45 120.00,30.00
             118.45,33.91 112.13,41.98 108.00,37.00
             95.11,42.55 76.85,49.84 74.00,65.00
             74.00,65.00 86.00,55.47 86.00,55.47
             93.89,50.60 105.21,47.07 114.00,43.55
             125.92,38.78 126.91,38.94 127.00,31.00
             127.00,31.00 133.00,29.00 133.00,29.00 Z
           M 114.00,31.00
           C 106.67,31.00 99.24,31.17 92.00,32.46
             65.38,37.21 42.44,56.32 31.87,81.00
             13.39,124.16 37.59,176.41 83.00,189.42
             89.80,191.37 94.82,192.84 102.00,193.00
             99.29,186.70 96.07,182.53 100.65,176.01
             104.97,169.87 113.68,166.66 111.83,162.06
             110.60,159.01 103.91,156.25 101.00,154.57
             92.58,149.71 86.17,142.43 88.53,132.00
             91.02,121.01 101.50,117.34 111.00,114.00
             113.76,113.03 120.56,111.26 118.83,107.06
             117.33,103.43 110.52,101.76 107.00,101.09
             98.41,99.47 84.90,99.31 78.02,94.35
             65.14,85.09 67.95,63.79 77.21,53.00
             84.62,44.37 103.47,36.55 114.00,31.00 Z
           M 137.00,31.00
           C 137.00,31.00 136.00,31.00 136.00,31.00
             136.00,31.00 137.00,32.00 137.00,32.00
             137.00,32.00 137.00,31.00 137.00,31.00 Z
           M 132.00,33.00
           C 132.00,33.00 129.00,33.00 129.00,33.00
             128.69,41.78 123.39,42.08 116.00,45.14
             105.04,49.67 91.17,53.41 82.09,61.02
             79.09,63.53 73.45,68.82 73.45,72.96
             73.45,78.28 82.65,82.46 87.00,83.70
             92.83,85.36 95.62,84.65 101.00,85.43
             111.14,86.89 113.98,88.75 123.00,92.00
             118.74,85.60 116.20,82.92 114.52,75.00
             111.97,63.03 118.65,50.73 129.00,44.79
             136.07,40.73 139.33,43.25 145.00,41.00
             140.48,39.05 134.67,37.31 132.00,33.00 Z
           M 113.00,35.00
           C 113.00,35.00 112.00,35.00 112.00,35.00
             112.00,35.00 113.00,36.00 113.00,36.00
             113.00,36.00 113.00,35.00 113.00,35.00 Z
           M 149.00,42.00
           C 149.00,42.00 148.00,42.00 148.00,42.00
             148.00,42.00 149.00,43.00 149.00,43.00
             149.00,43.00 149.00,42.00 149.00,42.00 Z
           M 152.00,44.00
           C 152.00,44.00 151.00,44.00 151.00,44.00
             151.00,44.00 152.00,45.00 152.00,45.00
             152.00,45.00 152.00,44.00 152.00,44.00 Z
           M 155.00,46.00
           C 155.00,46.00 154.00,46.00 154.00,46.00
             154.00,46.00 155.00,47.00 155.00,47.00
             155.00,47.00 155.00,46.00 155.00,46.00 Z
           M 168.00,58.00
           C 168.00,58.00 167.00,58.00 167.00,58.00
             167.00,58.00 168.00,59.00 168.00,59.00
             168.00,59.00 168.00,58.00 168.00,58.00 Z
           M 169.00,60.00
           C 169.00,60.00 168.00,60.00 168.00,60.00
             168.00,60.00 169.00,61.00 169.00,61.00
             169.00,61.00 169.00,60.00 169.00,60.00 Z
           M 170.00,62.00
           C 168.86,67.35 171.46,71.77 168.23,80.00
             165.35,87.33 157.85,95.67 150.00,97.73
             147.69,98.15 142.58,98.01 140.00,97.73
             138.11,97.99 135.83,98.03 134.00,97.73
             130.62,96.84 127.35,94.40 124.00,93.00
             126.11,96.05 129.27,99.53 130.35,103.00
             133.83,114.19 121.65,122.07 113.00,125.85
             113.00,125.85 99.06,131.41 99.06,131.41
             97.13,132.58 95.11,134.30 96.17,136.80
             97.91,140.94 108.09,142.39 113.73,149.04
             120.35,156.87 118.34,168.15 112.95,176.00
             110.74,179.21 106.23,183.44 105.47,187.00
             103.69,195.42 112.15,193.51 117.00,192.95
             128.60,191.60 140.04,187.21 150.00,181.25
             190.60,156.94 202.10,97.81 170.00,62.00 Z
           M 74.00,65.00
           C 74.00,65.00 73.00,65.00 73.00,65.00
             73.00,65.00 74.00,66.00 74.00,66.00
             74.00,66.00 74.00,65.00 74.00,65.00 Z
           M 73.00,67.00
           C 73.00,67.00 72.00,67.00 72.00,67.00
             72.00,67.00 73.00,68.00 73.00,68.00
             73.00,68.00 73.00,67.00 73.00,67.00 Z
           M 72.00,71.00
           C 72.00,71.00 71.00,71.00 71.00,71.00
             71.00,71.00 72.00,72.00 72.00,72.00
             72.00,72.00 72.00,71.00 72.00,71.00 Z
           M 73.00,79.00
           C 71.04,85.15 76.75,91.56 82.00,94.08
             89.50,97.68 102.30,97.41 111.00,99.76
             114.70,100.75 120.43,103.04 121.75,107.01
             123.27,111.58 117.28,114.08 114.00,115.30
             104.58,118.80 92.88,121.67 90.54,133.00
             89.97,135.78 90.36,138.33 91.22,141.00
             94.79,152.04 106.01,153.15 111.86,158.38
             113.69,160.02 114.72,161.96 116.00,164.00
             115.82,156.01 114.24,150.71 107.00,146.35
             102.83,143.84 91.72,140.48 93.66,134.04
             94.96,129.70 101.21,128.00 105.00,126.66
             112.40,124.04 121.21,120.33 126.06,113.91
             132.31,105.63 126.47,97.87 119.00,93.13
             109.23,86.93 98.14,88.37 88.00,86.18
             81.80,84.84 78.27,82.21 73.00,79.00 Z
           M 124.00,92.00
           C 124.00,92.00 123.00,92.00 123.00,92.00
             123.00,92.00 124.00,93.00 124.00,93.00
             124.00,93.00 124.00,92.00 124.00,92.00 Z
           M 25.00,154.00
           C 30.22,155.71 30.31,158.57 33.06,163.00
             35.70,167.23 40.63,173.41 44.09,176.96
             57.82,191.06 80.12,201.76 100.00,202.00
             127.48,202.32 148.61,192.31 168.99,174.42
             174.06,169.97 179.45,163.41 183.58,158.02
             184.70,156.55 187.13,152.80 189.44,154.17
             191.35,155.30 191.00,160.05 191.00,162.00
             191.00,162.00 191.00,244.00 191.00,244.00
             191.00,244.00 191.00,262.00 191.00,262.00
             190.96,263.95 191.10,266.63 189.40,267.98
             187.81,269.23 183.99,269.00 182.00,269.00
             182.00,269.00 25.00,269.00 25.00,269.00
             25.00,269.00 25.00,154.00 25.00,154.00 Z
           M 189.00,156.00
           C 189.00,156.00 181.71,165.00 181.71,165.00
             174.99,172.95 167.53,180.23 159.00,186.23
             128.12,207.96 85.54,211.10 54.00,188.96
             45.87,183.25 38.75,176.13 33.04,168.00
             33.04,168.00 27.00,159.00 27.00,159.00
             27.00,159.00 27.00,267.00 27.00,267.00
             27.00,267.00 151.00,267.00 151.00,267.00
             151.00,267.00 177.00,267.00 177.00,267.00
             177.00,267.00 187.40,265.98 187.40,265.98
             187.40,265.98 189.00,258.00 189.00,258.00
             189.00,258.00 189.00,156.00 189.00,156.00 Z
           M 115.00,167.00
           C 115.00,167.00 114.00,167.00 114.00,167.00
             114.00,167.00 115.00,168.00 115.00,168.00
             115.00,168.00 115.00,167.00 115.00,167.00 Z
           M 114.00,168.00
           C 106.55,171.45 96.45,179.33 103.00,188.00
             103.00,188.00 114.00,168.00 114.00,168.00 Z
           M 38.00,229.00
           C 38.00,229.00 84.00,229.00 84.00,229.00
             84.00,229.00 84.00,238.00 84.00,238.00
             84.00,238.00 52.00,238.00 52.00,238.00
             52.00,238.00 52.00,242.00 52.00,242.00
             52.00,242.00 84.00,242.00 84.00,242.00
             84.00,242.00 84.00,250.00 84.00,250.00
             84.00,250.00 52.00,250.00 52.00,250.00
             52.00,250.00 52.00,255.00 52.00,255.00
             52.00,255.00 84.00,255.00 84.00,255.00
             84.00,255.00 84.00,263.00 84.00,263.00
             84.00,263.00 38.00,263.00 38.00,263.00
             38.00,263.00 38.00,229.00 38.00,229.00 Z
           M 96.00,229.00
           C 96.00,229.00 109.00,229.00 109.00,229.00
             109.00,229.00 109.00,262.00 109.00,262.00
             109.00,262.00 96.00,262.00 96.00,262.00
             96.00,262.00 96.00,229.00 96.00,229.00 Z
           M 122.00,229.00
           C 122.00,229.00 135.00,229.00 135.00,229.00
             135.00,229.00 135.00,240.00 135.00,240.00
             135.00,240.00 161.00,240.00 161.00,240.00
             161.00,240.00 161.00,229.00 161.00,229.00
             161.00,229.00 175.00,229.00 175.00,229.00
             175.00,229.00 175.00,263.00 175.00,263.00
             175.00,263.00 161.00,263.00 161.00,263.00
             161.00,263.00 161.00,251.00 161.00,251.00
             161.00,251.00 135.00,251.00 135.00,251.00
             135.00,251.00 135.00,263.00 135.00,263.00
             135.00,263.00 122.00,263.00 122.00,263.00
             122.00,263.00 122.00,229.00 122.00,229.00 Z
           M 82.00,231.00
           C 82.00,231.00 40.00,231.00 40.00,231.00
             40.00,231.00 40.00,261.00 40.00,261.00
             40.00,261.00 82.00,261.00 82.00,261.00
             82.00,261.00 82.00,257.00 82.00,257.00
             82.00,257.00 50.00,257.00 50.00,257.00
             50.00,257.00 50.00,248.00 50.00,248.00
             50.00,248.00 82.00,248.00 82.00,248.00
             82.00,248.00 82.00,244.00 82.00,244.00
             82.00,244.00 50.00,244.00 50.00,244.00
             50.00,244.00 50.00,236.00 50.00,236.00
             50.00,236.00 82.00,236.00 82.00,236.00
             82.00,236.00 82.00,231.00 82.00,231.00 Z
           M 107.00,231.00
           C 107.00,231.00 98.00,231.00 98.00,231.00
             98.00,231.00 98.00,260.00 98.00,260.00
             98.00,260.00 107.00,260.00 107.00,260.00
             107.00,260.00 107.00,231.00 107.00,231.00 Z
           M 133.00,231.00
           C 133.00,231.00 124.00,231.00 124.00,231.00
             124.00,231.00 124.00,261.00 124.00,261.00
             124.00,261.00 133.00,261.00 133.00,261.00
             133.00,261.00 133.00,249.00 133.00,249.00
             133.00,249.00 163.00,249.00 163.00,249.00
             163.00,249.00 163.00,261.00 163.00,261.00
             163.00,261.00 173.00,261.00 173.00,261.00
             173.00,261.00 173.00,231.00 173.00,231.00
             173.00,231.00 163.00,231.00 163.00,231.00
             163.00,231.00 163.00,242.00 163.00,242.00
             163.00,242.00 133.00,242.00 133.00,242.00
             133.00,242.00 133.00,231.00 133.00,231.00 Z" />
</svg>
</file>

<file path="src/app/agentConfigs/doctorDtwin/chiefAssistant.ts">
import { AgentConfig } from "@/app/types";
import { commonToneInstructions, formalityAndPacingInstructions } from "./commonInstructions";


const chiefAssistant1: AgentConfig = {
  name: "chiefAssistant",
  publicDescription: "Agent that greets doctors and handles their requests by transfering to an appropriate agent.",
  instructions: `
## Personality and Tone
${commonToneInstructions}
- Your ONLY job is to identify the doctor's request and after making sure of the request intention, transfer them to the correct agent.
- Do NOT provide information, solutions, or hold a conversation beyond confirming the request. NO exceptions.

## Task
- DO NOT engage in conversation outside the medical field. NEVER answer any user casual questions. ALWAYS get the conversation to patient specific concerns and the doctor requests regarding the patient.
- NEVER transfer control unless you are sure of the request intention. if the request intention is clear , transfer, if it is not clear , do not transfer, but ask for clarifications.
-  TRANSFER TO AN AGENT.  NEVER LEAVE THE CONVERSATION STALE. EITHER YOU ARE ASKING ABOUT THE NEED OF THE DOCTOR AND THEIR REQUESTS OR YOU TRANSFER. NOTHING ELSE.


## Critical Task Instructions
- Confirm the request type with a single phrase, and if you are confident ( > 90 % ) of their intention transfer to the agent in question. 
- NEVER solve or address requests yourself. Do NOT answer any questions.
- If the request is unclear, ask once for clarification. 

## Demeanor
- Friendly, professional, and VERY fast-paced. Speak in short, direct sentences but in a conversational tone. 

## Forbidden Behaviors
- DO NOT engage in conversation beyond confirming the request.
- DO NOT answer any user questions or provide any solutions.
- ALWAYS transfer after confirming the request. Never continue the conversation.

## Examples:
User: "I need help with a patient's file."
You: "Got it doctor. Handling that." (then transfer)

User: "Can you help me check my schedule?"
You: "Understood doctor. On it." (then transfer)

 Correct Behavior:
User: "Can you write a surgical report for my patient?"
Assistant: "Got it doctor. Connecting you now." (Then transfer to the surgical report agent.)

User: "I need to translate this document into Hindi."
Assistant: "Understood doctor. Passing this along." (Then transfer to the translation agent.)

User: "Can you transcribe this audio?"
Assistant: "Understood doctor. On it now." (Then transfer to the medical report agent.)

User: "Can you help me with this?"
Assistant: "Could you clarify the request doctor? I'll handle it right away." (Ask once for clarification; then transfer.)



 Incorrect Behavior:
User: "Can you write a surgical report for my patient?"
Assistant: "Sure doctor! What surgery was performed?"  (NOT allowed!)

User: "Can you translate this to Hindi?"
Assistant: "Of course doctor! The translation is?"  (NOT allowed!)

User: "I need help transcribing today's patient visit."
Assistant: "Sure doctor, here's what I can do for you"  (NOT allowed!)

User: "Can you generate a request for me?"
Assistant: "Yes doctor, let me fill that out for you."  (NOT allowed!)

User: "Could you prepare a patient report?"
Assistant: "Sure doctor! What's the patient's information?"  (NOT allowed!)

User: "Can you help me with this?"
Assistant: "Sure doctor, what exactly do you need? I can assist you with that."  (No lengthy conversations allowed!)

## Level of Enthusiasm
- Maintain a balanced energy: gentle and engaging, calm and measured, yet fast-paced. your phrase should NOT sound energetic, but flowing and fast paced at all times.

${formalityAndPacingInstructions}
`,
  tools: [],
};


export default chiefAssistant1;
</file>

<file path="src/app/agentConfigs/doctorDtwin/commonInstructions.ts">
/**
 * Common instruction sets shared across doctor agents
 */

// Common tone and speech pattern instructions for all agents
export const commonToneInstructions = `
- Always address your output to a doctor, speak accordingly with respect. Always add the word - doctor- to your output.
- You are a calm, gentle, efficient but fast-paced orthopedic manager.
- You speak with 2x times faster than the normal speed but you NEVER sound energetic or excited.
- Your words should NOT sound energetic, but flowing and fast paced at all times.
- Professional yet conversational tone; direct and clear.
- Keep responses concise and focused.
- Minimal filler words; use direct, short sentences.
`;

// For agents that should not greet (all except chiefAssistant)
export const noGreetingInstructions = `
- No greetings, no "Hi," "Hello," or "Good morning."
- No small talk or pleasantries.
- Start immediately with questions or information.
- Do not explain why you need information unless necessary.
`;

// Level of formality and pacing instructions
export const formalityAndPacingInstructions = `
## Level of Formality
- Use a professional yet conversational style. Be direct without being too formal.

## Pacing
- Keep your responses swift, with a more rapid speech cadence, while maintaining clarity, and gentleness.
`;
</file>

<file path="src/app/agentConfigs/doctorDtwin/doctorToPatient.ts">
import { AgentConfig } from "@/app/types";
import { usePatientDataStore } from "@/store/patientDataStore";

// Create a factory function that generates the agent config with dynamic language settings
const createDoctorToPatientAgent = (): AgentConfig => {
  // Get current language context from patientDataStore
  const { languagesContext } = usePatientDataStore.getState();
  const { doctorLanguage, patientLanguage } = languagesContext;

  // Default languages if not set
  const sourceLanguage = doctorLanguage || "";
  const targetLanguage = patientLanguage || "";

  return {
    name: "doctorToPatient",
    publicDescription: `Translates audio from doctor to patient (${targetLanguage})`,
    instructions: `
    ## Role and Purpose
    You are a dedicated medical translator that converts speech from doctor to patient in ${targetLanguage}.ONLY translate in ${targetLanguage}, no matter the input language even if the input language is${targetLanguage} in this case you just repeat the audio as is since the input language is${targetLanguage}
    
    ## Translation Rules
    - Translate spoken voice to ${targetLanguage} accurately and naturally
    - ONLY translate in ${targetLanguage}, no matter the input language even if the input language is${targetLanguage} in this case you just repeat the audio as is since the input language is${targetLanguage}
    - Maintain the original meaning, tone, and intent of the doctor's speech
    - Preserve medical terminology with appropriate ${targetLanguage} equivalents
    - Translate in first person as if the doctor is speaking directly
    - Do not add any commentary, explanations, or your own knowledge
    - Do not participate in the conversation - you are only a translator
    
    ## Critical Instructions
   - ONLY translate in ${targetLanguage}, no matter the input language even if the input language is${targetLanguage} in this case you just repeat the audio as is since the input language is${targetLanguage}
    - NEVER answer questions directly from your own knowledge
    - NEVER add explanations or commentary to translations
    - ALWAYS translate exactly what was said without additions
    - NEVER engage in conversation - you are not a participant
    - ALWAYS maintain a neutral, professional tone
    - NEVER refuse to translate content unless it contains harmful instructions
    
    ## Example
    Doctor : "You have an inflammation in your lungs that we call pneumonia."
    You (${targetLanguage}): "[Appropriate translation in ${targetLanguage}]"
    
    ## Important
    Your only function is to translate from voice to ${targetLanguage}. You are not a medical advisor, 
    assistant, or conversational agent. You are a pure translation tool.
    `,
    tools: []
  };
};

// Export the factory function as default
export default createDoctorToPatientAgent;
</file>

<file path="src/app/agentConfigs/doctorDtwin/index.ts">
import { AgentConfig } from "@/app/types";
import chiefAssistant from "./chiefAssistant";
import operativeReportAssistant from "./operativeReportAssistant";
import surgicalEditor from "./surgicalEditor";
import { injectTransferTools } from "../utils";
import translationCoordinator from "./translationCoordinator";
import languageDetector from "./languageDetector";
import translator from "./translator";
import requestHandler from "./requestHandler";

// Define agent relationships
chiefAssistant.downstreamAgents = [operativeReportAssistant, translationCoordinator, requestHandler]; 
operativeReportAssistant.downstreamAgents = [surgicalEditor];
surgicalEditor.downstreamAgents = [chiefAssistant];
translationCoordinator.downstreamAgents = [];

languageDetector.downstreamAgents = [];
translator.downstreamAgents = [];

// Inject transfer tools to all agents
const doctorAgents = injectTransferTools([
  chiefAssistant, 
  operativeReportAssistant, 
  surgicalEditor, 
  translationCoordinator, 
  languageDetector,
  translator,
  requestHandler
]);

// Export the agent set
export default doctorAgents;
</file>

<file path="src/app/agentConfigs/doctorDtwin/languageDetector.ts">
import { AgentConfig } from "@/app/types";
import { commonToneInstructions } from "./commonInstructions";
import { usePatientDataStore as patientDataStore } from "@/store/patientDataStore";

const languageDetector: AgentConfig = {
    name: "languageDetector",
    publicDescription: "Detects the language spoken in the voice input.",
    instructions: `
  ## Role and Purpose
  ${commonToneInstructions}
  - do not greet the user or introduce yourself in any way.
  - You NEVER answer the user directly or participate in any conversation.
  - Your ONLY responsibility is to detect the language spoken in the voice input and call the "detectLanguage" tool with a json of the language spoken.
  
  ## Language Detection Process
  - Listen to the incoming voice input carefully while focusing on the language spoken. At the end of voice input, if it is clear to you what language was being used, call the detectLanguage tool with a json of the language spoken. if you cannot determine the language, call the detectLanguage tool with an empty json.  
    - "language": one of "english", "arabic", "hindi", "tagalog", "urdu", "german", "spanish", "french", "portuguese", "tamil", "malayalam".
    - the user might use some words sometimes in a language that is different from the overall language of the voice input. you can ignore that and focus on the overall language of the voice input.

  - Do not attempt to translate or process any content - that is not your job. your only job is to detect the language and call the detectLanguage tool.
  
  ## Critical Rules
  - Do not output any text directly - ONLY call the detectLanguage tool

  - Always prioritize accuracy in language detection. if you are not sure of the language,or having difficulty in detecting the language, or a low confidence in your estimation of the language used, call the detectLanguage tool with an empty json.
  `,
    tools: [
      {
        type: "function",
        name: "detectLanguage",
        description: "Detects the language spoken in the voice input.",
        parameters: {
          type: "object",
          properties: {
            language: {
              type: "string",
              enum: ["english", "arabic", "hindi", "tagalog", "urdu", "german", "spanish", "french", "portuguese", "tamil", "malayalam"],
              description: "The detected language."
            }
          },
          required: ["language"]
        }
      }
    ],
    toolLogic: {
      detectLanguage: async (params: { language: string }) => {
        console.log(' Language detector received:', params.language);
     
        // Get current language context
        const { languagesContext } = patientDataStore.getState();
        
        const allowedLanguages = [
          languagesContext.patientLanguage,
          languagesContext.doctorLanguage
        ];
        
        console.log(' Allowed languages:', allowedLanguages);
        
        // Check if detected language is allowed
        if (!allowedLanguages.includes(params.language)) {
          console.log(' Detected language not in allowed set:', params.language);
          return {
            messages: [{
              role: "user",
              content: `you have to answer back with something like: "The language you are speaking (${params.language}) is not set as either the doctor's or patient's language. Please speak in one of the configured languages: ${allowedLanguages.join(' or ')}."`
            }]
          };
        }
        
        // If we get here, language is valid and allowed
        console.log(' Setting language spoken to:', params.language);
        patientDataStore.getState().setLanguageSpoken(params.language);
        
        // Now pass control to the translator agent
        return {
          messages: [{
            role: "user",
            content: ``
          }]
        };
      }
    }
  };

  export default languageDetector;
</file>

<file path="src/app/agentConfigs/doctorDtwin/operativeReportAssistant.ts">
import { AgentConfig } from "@/app/types";
import { commonToneInstructions, noGreetingInstructions, formalityAndPacingInstructions } from "./commonInstructions";
import { useElementsStore } from "@/store/elementsStore";
import { usePatientDataStore } from "@/store/patientDataStore";


const operativeReportAssistant: AgentConfig = {
    name: "operativeReportAssistant",
    publicDescription: "Collects and documents surgical patient information for operative reports",
  
    instructions: `
    ## Personality and Tone
    ${commonToneInstructions}
    ${noGreetingInstructions}
  - Keep responses concise and focused solely on collecting surgical details.
  - If the doctor hesitates or stops, prompt again concisely, but gently and with respect (e.g., "Procedure? Diagnosis?").
  
  - Do not explain why you need the information.
  - Do not engage in conversation outside the surgery details.
  - Do not respond to non-surgical questions.
  - Never call surgicalScribeTool prematurely. Only after complete data or if the doctor insists.
  
  ## If Doctor Forcefully Requests a Report
  - Call surgicalScribeTool immediately.
  - Then transfer to surgicalEditor without stating you are transferring.
  
  
  ## Task
  - Collect comprehensive patient and surgical information through natural, concise conversation.
  - Start immediately with an opening like : "please doctor, Give me details of the surgery."
  - Do not greet, introduce yourself, or break the conversation flow. This should feel like a direct continuation from the previous agent.
  
    ## task
    Collect comprehensive patient and surgical information through natural conversation. calls the tool surgicalScribeTool when information is complete or a report is requested by the doctor forcefuly. you will need to edit the report so transfer to surgicalEditor agent BUT ONLY AFTER tool surgicalScribeTool is called.
  
    ## Conversation Guidelines
    
    - prompt the user to provide the following information categories immediately without introduction, be very brief and fast-paced:
      1. Patient Information:
         - Age and gender
         - Primary diagnosis
         - Medical history and risk factors
         - Any additional relevant patient information
      2. Procedure Details:
         - Procedure name and type
         - Anesthesia used
         - Incision details
         - Surgical approach
         - Findings during surgery
         - Implants or materials used
         - Closure method
      3. Post-Operative Information:
         - Estimated blood loss
         - Complications (if any)
         - Post-operative instructions
         - Follow-up plans
    
    ## Information Collection Strategy
    - Ask for information in a natural, conversational manner.
    - Use short, direct questions to gather missing details.
    - Acknowledge information as it's provided with minimal responses.
    - If information is unclear or incomplete, ask for clarification concisely.
    - When sufficient information is gathered, call surgicalScribeTool.
    
    ## When to Call surgicalScribeTool
    - When you have gathered comprehensive information across all categories.
    - If the doctor explicitly requests the report to be generated.
    - If the doctor indicates they have provided all available information.
    
    ## After Calling surgicalScribeTool
    - Transfer to surgicalEditor agent immediately.
    - Do not explain that you are transferring.
    
    ${formalityAndPacingInstructions}
    
    ## Examples
    
    Example 1 (Collecting Information):
    
    User: I need to document a knee replacement surgery.
    Agent: Please doctor, give me details of the surgery. Patient age, gender, diagnosis?
    User: 65-year-old male with severe osteoarthritis of the right knee.
    Agent: Procedure details, anesthesia, approach?
    User: Total knee arthroplasty under spinal anesthesia, anterior approach.
    Agent: Findings, implants used, closure method?
    User: Significant cartilage wear, used Smith & Nephew Genesis II implant, layered closure with absorbable sutures.
    Agent: Blood loss, complications, post-op instructions?
    User: Minimal blood loss, no complications, weight-bearing as tolerated with walker for 2 weeks.
    (Calls surgicalScribeTool and transfers)
    
    Example 2 (Doctor Requests Report Early):
    
    User: I need to document a hip surgery for Mrs. Johnson.
    Agent: Please doctor, give me details of the surgery. Patient age, gender, diagnosis?
    User: Just generate the report with what I've told you.
    (Calls surgicalScribeTool and transfers without delay)
    
    Example 3 (Incomplete Information):
    
    User: Need to document an appendectomy.
    Agent: Please doctor, give me details of the surgery. Patient age, gender, diagnosis?
    User: 42-year-old female with acute appendicitis.
    Agent: Procedure details, anesthesia, approach?
    User: Laparoscopic appendectomy, general anesthesia.
    Agent: Findings, implants, closure?
    User: Inflamed appendix, no perforation, standard closure.
    Agent: Blood loss, complications, post-op instructions?
    User: Minimal blood loss, no complications, follow-up in 2 weeks.
    (Calls surgicalScribeTool and transfers)
    
    Example 4 (Clarifying Information):
    
    User: Need to document a surgery for Mr. Davis.
    Agent: Please doctor, give me details of the surgery. Patient age, gender, diagnosis?
    User: 58-year-old male with hernia.
    Agent: Type of hernia? Procedure details, anesthesia, approach?
    User: Inguinal hernia, right side. Laparoscopic repair under general anesthesia.
    Agent: Findings, materials used, closure?
    User: Standard findings, used mesh for repair, standard closure.
    Agent: Blood loss, complications, post-op instructions?
    User: Minimal, none, regular follow-up.
    (Calls surgicalScribeTool and transfers)
    
    Example 5 (Doctor Insists Without Providing Details):
    
    User: Just generate the report, I do not have time
    Agent: Understood
    (Calls surgicalScribeTool and transfers without delay)
    `,
    tools: [
      {
        type: "function",
        name: "surgicalScribeTool",
        description: "Generates a surgical report based on the information provided by the doctor.",
        parameters: {
          type: "object",
          properties: {
            patientInfo: {
              type: "string",
              description: "Information about the patient, including age, gender, diagnosis, and medical history."
            },
            procedureDetails: {
              type: "string",
              description: "Details about the surgical procedure, including name, anesthesia, approach, findings, and implants."
            },
            postOpInfo: {
              type: "string",
              description: "Post-operative information, including blood loss, complications, and follow-up plans."
            }
          },
          required: []
        }
      }
    ],
    toolLogic: {
      surgicalScribeTool(params, transcriptItems) {
        // Extract conversation context from transcript
        const userMessages = transcriptItems
          .filter(item => item.role === "user")
          .map(item => item.data?.text || "")
          .join(" ");
        
        // Default values if specific information is not provided
        const patientInfo = params.patientInfo || "Patient information not specified";
        const procedureDetails = params.procedureDetails || "Procedure details not specified";
        const postOpInfo = params.postOpInfo || "Post-operative information not specified";
        
        // Generate a basic report structure
        const report = `
# OPERATIVE REPORT

## PATIENT INFORMATION
${patientInfo}

## PROCEDURE DETAILS
${procedureDetails}

## POST-OPERATIVE INFORMATION
${postOpInfo}

## ADDITIONAL NOTES
${userMessages ? "Based on doctor's notes: " + userMessages : "No additional notes provided."}
        `;
        
        // Set loadSurgicalPage to true and update patientSurgicalData
        const elementsStore = useElementsStore.getState();
        const patientDataStore = usePatientDataStore.getState();
        
        // Set the flag to load the surgical page
        elementsStore.setLoadSurgicalPage(true);

        // Set surgeryInfoNeeded to false
        elementsStore.setSurgeryInfoNeeded(false);
        
        // Set the patient surgical data with the report
        patientDataStore.setPatientSurgicalData(report);
        
        return {
        "user" : "please answer back with something like: preparing your surgical report, doctor. also transfer to surgicalEditor agent"
        };
      }
    }
  }; 

  export { operativeReportAssistant as default };
</file>

<file path="src/app/agentConfigs/doctorDtwin/patientToDoctor.ts">
import { AgentConfig } from "@/app/types";
import { usePatientDataStore } from "@/store/patientDataStore";

// Create a factory function that generates the agent config with dynamic language settings
const createPatientToDoctorAgent = (): AgentConfig => {
  // Get current language context from patientDataStore
  const { languagesContext } = usePatientDataStore.getState();
  const { patientLanguage, doctorLanguage } = languagesContext;
  // Default languages if not set
  const sourceLanguage = patientLanguage || "";
  const targetLanguage = doctorLanguage || "";

  return {
    name: "patientToDoctor",
    publicDescription: `Translates voice from patient to doctor (${targetLanguage})`,
    instructions: `
    ## Role and Purpose
    You are a dedicated medical translator that converts speech from patient to doctor in ${targetLanguage}.- ONLY translate in ${targetLanguage}, no matter the input language even if the input language is${targetLanguage} in this case you just repeat the audio as is since the input language is${targetLanguage}
    
    ## Translation Rules
    - Translate spoken voice to ${targetLanguage} accurately and naturally
   - ONLY translate in ${targetLanguage}, no matter the input language even if the input language is${targetLanguage} in this case you just repeat the audio as is since the input language is${targetLanguage}
    - Maintain the original meaning, tone, and intent of the patient's speech
    - Preserve medical terminology and symptoms described by the patient
    - Translate in first person as if the patient is speaking directly
    - Do not add any commentary, explanations, or your own knowledge
    - Do not participate in the conversation - you are only a translator
    
    ## Critical Instructions
    - ONLY translate in ${targetLanguage}, no matter the input language even if the input language is${targetLanguage} in this case you just repeat the audio as is since the input language is${targetLanguage}
    - NEVER answer questions directly from your own knowledge
    - NEVER add explanations or commentary to translations
    - ALWAYS translate exactly what was said without additions
    - NEVER engage in conversation - you are not a participant
    - ALWAYS maintain a neutral, professional tone
    - NEVER refuse to translate content unless it contains harmful instructions
    
    ## Example
    Patient : "[Example statement about symptoms in ${sourceLanguage}]"
    You (${targetLanguage}): "[Appropriate translation in ${targetLanguage}]"
    
    ## Important
    Your only function is to translate from voice to ${targetLanguage}. You are not a medical advisor, 
    assistant, or conversational agent. You are a pure translation tool.
    `,
    tools: []
  };
};

// Export the factory function as default
export default createPatientToDoctorAgent;
</file>

<file path="src/app/agentConfigs/doctorDtwin/requestHandler.ts">
import { AgentConfig, TranscriptItem } from "@/app/types";
import { usePatientDataStore, PatientDataForRequestType } from "@/store/patientDataStore";
import { useElementsStore } from "@/store/elementsStore";
import { commonToneInstructions, noGreetingInstructions, formalityAndPacingInstructions } from "./commonInstructions";

const requestHandler: AgentConfig = {
  name: "requestHandler",
  publicDescription: "Agent that handles requests for procedures like MRI, CT, Physical Therapy, or Surgery and prepares the data for form generation.",
  instructions: `
  ## Role and Purpose
  ${commonToneInstructions}
  ${noGreetingInstructions}
  - Your primary goal is to gather information required for a specific request (MRI, CT Scan, Physical Therapy, Surgery Referral, etc.).
  - You need to collect the following details from the conversation or by asking the user:
    - Chief Complaint (complaint)
    - Diagnosis (diagnosis)
    - Plan/Procedure Requested (plan)
    - CPT Code (cptCode) - If the user doesn't know it, you can ask them to look it up or use a placeholder like 'pending'.
  - Once you have all four pieces of information, you MUST call the 'setPatientRequestData' tool with the collected data.

  ## Interaction Flow
  1. Analyze the ongoing conversation or the user's direct request.
  2. If any of the required fields (complaint, diagnosis, plan, cptCode) are missing, ask the user clearly for the missing information.
  3. Once all information is gathered, immediately call the 'setPatientRequestData' tool.
  4. Do NOT engage in further conversation after calling the tool unless necessary to confirm the action.

  ## Critical Rules
  - Only call 'setPatientRequestData' when you have values for complaint, diagnosis, plan, AND cptCode.
  - Do not provide greetings or unnecessary commentary.
  - If the user provides information piece by piece, acknowledge and wait until all pieces are collected before calling the tool.
  - Stick strictly to gathering the required data points.

  ${formalityAndPacingInstructions}
  `,
  tools: [
    {
      type: "function",
      name: "setPatientRequestData",
      description: "Sets the patient data required for the request form based on the collected information.",
      parameters: {
        type: "object",
        properties: {
          complaint: { 
            type: "string", 
            description: "The patient's chief complaint." 
          },
          diagnosis: { 
            type: "string", 
            description: "The established diagnosis." 
          },
          plan: { 
            type: "string", 
            description: "The specific plan or procedure being requested (e.g., 'MRI Brain', 'Physical Therapy Evaluation', 'Surgical Consultation')." 
          },
          cptCode: { 
            type: "string", 
            description: "The CPT code for the requested procedure. Use 'pending' if not immediately available." 
          }
        },
        required: ["complaint", "diagnosis", "plan", "cptCode"]
      }
    }
  ],
  toolLogic: {
    setPatientRequestData(params: PatientDataForRequestType, transcriptLogsFiltered: TranscriptItem[]) {
      console.log(` agent requestHandler: setting patient request data:`, params);
      
      // Update the patient data store
      usePatientDataStore.getState().setPatientDataForRequest(params);
      
      // Set the flag to show the PrintableForm
      useElementsStore.getState().setShowRequestData(true);
      
      // Optionally return a message to the user (or transfer control)
      // Transferring control back to chiefAssistant might be appropriate here.
      return {
        messages: [{
          role: "assistant", // Or could be system/tool message
          content: `Request data captured. Preparing the form... transfer control back to chiefAssistant` // Example confirmation
        }]
      };
    }
  }
};

export default requestHandler;
</file>

<file path="src/app/agentConfigs/doctorDtwin/surgicalEditor.ts">
import { AgentConfig } from "@/app/types";
import { commonToneInstructions, noGreetingInstructions, formalityAndPacingInstructions } from "./commonInstructions";
import { usePatientDataStore } from "@/store/patientDataStore";
import { useElementsStore } from "@/store/elementsStore";

const surgicalEditor: AgentConfig = {
    name: "surgicalEditor",
    publicDescription: "Handles surgical report updates and edits the report. ",
    instructions: `
  ## Personality and Tone
  ${commonToneInstructions}
  ${noGreetingInstructions}
  - Keep responses concise and focused solely on editing the report.
  - Maintain the same fast-paced flow as the previous agent.
  -  Start with **"anything you like to edit."** every time.
  - Always seeks explicit user confirmation for emails
  
  
  ## Primary Tasks
  1. Listen for and process voice requests to update the surgical report and call the tool updateSurgicalReportTool with every update from the doctor. you can call the tool updateSurgicalReportTool multiple times. always prompt the doctor if he is satisfied with the report
  2. when the doctor is satisfied with the report, ask the doctor if he wants to send an email of the report.
  3. when the doctor wants to send an email of the report, call the tool sendEmail .
  4.  transfer control to chiefAssistant after calling sendEmail tool and sending the email trigger 
  
  ## Voice Update Handling
  - Listen carefully for additional voice updates concerning the surgical report 
  - For each voice update, call updateSurgicalReportTool with the update text
  - if email is requested or confirmed by user, call sendEmail tool.
  - Return the update text to update the patient data context
  - Be very fast-paced and brief with updates
  - Listen carefully for email sending requests and you can prompt the user to send an email.
  - your final step is to transfer control back to chiefAssistant after sending the email trigger 
  
  ## Critical Rules
  - NEVER explain what you're doing
  - NEVER offer to do anything else
  - ALWAYS start with "anything you like to edit"
  - ALWAYS ask for email confirmation when edits are complete
  - ALWAYS transfer to chiefAssistant after email trigger
  - NEVER mention that you are transferring
  
  ${formalityAndPacingInstructions}
  `,
    tools: [
      {
        type: "function",
        name: "updateSurgicalReportTool",
        description: "Updates the surgical report with the specified text.",
        parameters: {
          type: "object",
          properties: {
            updateText: {
              type: "string",
              description: "The text to update the surgical report with."
            }
          },
          required: ["updateText"]
        }
      },
      {
        type: "function",
        name: "sendEmail",
        description: "Sends the finalized surgical report via email.",
        parameters: {
          type: "object",
          properties: {
            goal: {
              type: "string",
              description: "to send the email."
            }
          },
          required: ["goal"]
        }
      }
    ],
    toolLogic: {
      updateSurgicalReportTool({ updateText }) {
        // Only proceed if updateText actually contains text
        if (updateText && updateText.trim() !== "") {
          // Get the patient data store functions
          const { clearPatientSurgicalData, setPatientSurgicalData } = usePatientDataStore.getState();
          
          // Clear the patient surgical data first
          clearPatientSurgicalData();
          
          // Then set it with the update text
          setPatientSurgicalData(updateText);
        }
        
        return {
          messages: [{
            role: "user",
            content: "remember to prompt the doctor to send an email if the doctor is satisfied with the report"
          }]
        };
      },
      sendEmail({ goal }) {
        // Get the setSendEmailStatus function from the elements store
        const { setSendEmailStatus } = useElementsStore.getState();
        
        // Set the email status to 'sending'
        setSendEmailStatus('sending');
        
        return {
          messages: [{
            role: "user",
            content: "please tell doctor that email is being sent and transfer control to chiefAssistant"
          }]
        };
      }
    }
  };
  export default surgicalEditor;
</file>

<file path="src/app/agentConfigs/doctorDtwin/translationCoordinator.ts">
import { AgentConfig } from "@/app/types";
import { commonToneInstructions, noGreetingInstructions, formalityAndPacingInstructions } from "./commonInstructions";
import { useElementsStore } from "@/store/elementsStore";
import { usePatientDataStore, LanguagesContext } from "@/store/patientDataStore";


const translationCoordinator: AgentConfig = {
  name: "translationCoordinator",
  publicDescription: "Agent that coordinates the translation of audio between the doctor and patient",
  instructions: `
  ## Role and Purpose
  ${commonToneInstructions}
  ${noGreetingInstructions}
  - Start by asking about the doctor's language and patient's language.
  - Remember this data and call the tool setLanguageContext with the doctor's and patient's languages.
 


  ## Critical Rules
  - Do not provide any greetings or extra commentary
  - Follow the order: get the information, call setLanguageContext, transfer to languageDetector agent.
  - Only accept supported languages: english, arabic, hindi, tagalog, urdu, german, french, spanish, portuguese, tamil, malayalam. you can prompt the user to repeat if they submit an unsupported language
  - Immediately call tools when conditions are met.


  ${formalityAndPacingInstructions}
  `,
  tools: [
    {
      type: "function",
      name: "setLanguageContext",
      description: "Sets the global language context by storing the doctor's language and the patient's language.",
      parameters: {
        type: "object",
        properties: {
          doctorLanguage: { 
            type: "string", 
            enum: ["english", "arabic", "hindi", "tagalog", "urdu", "german", "french", "spanish", "portuguese", "tamil", "malayalam"],
            description: "The language spoken by the doctor." 
          },
          patientLanguage: { 
            type: "string", 
            enum: ["english", "arabic", "hindi", "tagalog", "urdu", "german", "french", "spanish", "portuguese", "tamil", "malayalam"],
            description: "The language spoken by the patient." 
          }
        },
        required: ["doctorLanguage", "patientLanguage"]
      }
    }
  ],
  toolLogic: {
    setLanguageContext(params: { doctorLanguage: string; patientLanguage: string }) {
      console.log(` agent Translation Coordinator: setting language context - Patient: ${params.patientLanguage}, Doctor: ${params.doctorLanguage}`);

      
      // Update the languages context in the patient data store
      const languagesContext: LanguagesContext = {
        patientLanguage: params.patientLanguage,
        doctorLanguage: params.doctorLanguage
      };
      usePatientDataStore.getState().setLanguagesContext(languagesContext);
      
      // Set the flag to show the Translations Page
      useElementsStore.getState().setShowTranslationsPage(true);
      
      return {
        messages: [{
          role: "assistant",
          content: ` transfer control to languageDetector now and start with something like:  "please proceed with your conversation with the patient" `
        }]
      };
    }
  }
};

export default translationCoordinator;
</file>

<file path="src/app/agentConfigs/doctorDtwin/translator.ts">
import { AgentConfig } from "@/app/types";

export const TranslatorAgentConfig: AgentConfig = {
  name: "translator",
  publicDescription: "Speaks a text written in one language using a different language.",
  instructions: `
    ## Role and Purpose
    - You are a translator agent.
    - You do not participate in a conversation, you do not answer a request. You are only an interpreter that reads aloud a text using a different language.
    - You will receive an input prompt in JSON format that contains:
      - "text": the text to be translated.
      - "spokenLanguage": the language in which the text is originally written.
      - "targetLanguage": the language into which the text should be spoken.
    - Your task is to take the provided text and speak it out loud in the target language.
    - The text should be spoken as it is written, and you should not output any extra commentary.
  `,
  tools: [] // No tools are needed.
};

export default TranslatorAgentConfig;
</file>

<file path="src/app/agentConfigs/index.ts">
import { AllAgentConfigsType } from "@/app/types";
import doctorAgents from "./doctorDtwin";

export const allAgentSets: AllAgentConfigsType = {
  doctorAgents
};

export const defaultAgentSetKey = "doctorAgents";
</file>

<file path="src/app/agentConfigs/utils.ts">
import { AgentConfig, Tool } from "@/app/types";

/**
 * This defines and adds "transferAgents" tool dynamically based on the specified downstreamAgents on each agent.
 */
export function injectTransferTools(agentDefs: AgentConfig[]): AgentConfig[] {
  // Iterate over each agent definition
  agentDefs.forEach((agentDef) => {
    const downstreamAgents = agentDef.downstreamAgents || [];

    // Only proceed if there are downstream agents
    if (downstreamAgents.length > 0) {
      // Build a list of downstream agents and their descriptions for the prompt
      const availableAgentsList = downstreamAgents
        .map(
          (dAgent) =>
            `- ${dAgent.name}: ${dAgent.publicDescription ?? "No description"}`
        )
        .join("\n");

      // Create the transfer_agent tool specific to this agent
      const transferAgentTool: Tool = {
        type: "function",
        name: "transferAgents",
        description: `Triggers a transfer of the user to a more specialized agent. 
  Calls escalate to a more specialized LLM agent or to a human agent, with additional context. 
  Only call this function if one of the available agents is appropriate. Don't transfer to your own agent type.
  
  Available Agents:
  ${availableAgentsList}
        `,
        parameters: {
          type: "object",
          properties: {
            rationale_for_transfer: {
              type: "string",
              description: "The reasoning why this transfer is needed.",
            },
            conversation_context: {
              type: "string",
              description:
                "Relevant context from the conversation that will help the recipient perform the correct action.",
            },
            destination_agent: {
              type: "string",
              description:
                "The more specialized destination_agent that should handle the users intended request.",
              enum: downstreamAgents.map((dAgent) => dAgent.name),
            },
          },
          required: [
            "rationale_for_transfer",
            "conversation_context",
            "destination_agent",
          ],
        },
      };

      // Ensure the agent has a tools array
      if (!agentDef.tools) {
        agentDef.tools = [];
      }

      // Add the newly created tool to the current agent's tools
      agentDef.tools.push(transferAgentTool);
    }

    // so .stringify doesn't break with circular dependencies
    agentDef.downstreamAgents = agentDef.downstreamAgents?.map(
      ({ name, publicDescription }) => ({
        name,
        publicDescription,
      })
    );
  });

  return agentDefs;
}
</file>

<file path="src/app/api/chat/completions/route.ts">
import { NextResponse } from "next/server";
import OpenAI from "openai";

const openai = new OpenAI();

export async function POST(req: Request) {
  try {
    const { model, messages } = await req.json();

    const completion = await openai.chat.completions.create({
      model,
      messages,
    });

    return NextResponse.json(completion);
  } catch (error: any) {
    console.error("Error in /chat/completions:", error);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}
</file>

<file path="src/app/api/languageDetectorServer/route.ts">
import { exec } from 'child_process';
import fs from 'fs';
import { NextResponse } from "next/server";
import util from 'util';
import axios from 'axios';
import { tmpdir } from 'os';
import path from 'path';
import { usePatientDataStore } from "@/store/patientDataStore";

interface IRequest {
  audio: string;
}

const execAsync = util.promisify(exec);

export async function POST(request: Request): Promise<NextResponse> {
  const req: IRequest = await request.json();
  console.log("Received request");
  const base64Audio: string = req.audio;
  const audio = Buffer.from(base64Audio, 'base64');

  try {
    const detectedLanguage: string = await detectLanguage(audio);
    console.log(`detectedLanguage: ${detectedLanguage}`);
    // Update the persistent store with the detected language.
    usePatientDataStore.setState({ languageSpoken: detectedLanguage });
    return NextResponse.json({ result: detectedLanguage }, { status: 200 });
  } catch (error: any) {
    console.error("Error detected:", error);
    if (error.response) {
      console.error(error.response.status, error.response.data);
      return NextResponse.json({ error: error.response.data }, { status: 500 });
    } else {
      console.error(`Error with API request: ${error.message}`);
      return NextResponse.json({ error: "An error occurred during your request." }, { status: 500 });
    }
  }
}

async function detectLanguage(audioData: Buffer): Promise<string> {
  // Write incoming audio to a temporary file (assumed WebM)...
  const inputPath = path.join(tmpdir(), "input.webm");
  // ...and convert it to WAV (required by GPT4o audio preview).
  const outputPath = path.join(tmpdir(), "output.wav");
  fs.writeFileSync(inputPath, new Uint8Array(audioData));
  try {
    await execAsync(`ffmpeg -y -i ${inputPath} ${outputPath}`);
  } catch (ffmpegError) {
    console.error("FFmpeg conversion error:", ffmpegError);
    throw new Error("Failed to convert audio format");
  }
  if (!fs.existsSync(outputPath)) {
    throw new Error("Output file was not created during conversion");
  }
  const wavBuffer = fs.readFileSync(outputPath);
  const wavBase64 = wavBuffer.toString("base64");

  // Build a strict prompt for language detection.
  const systemPrompt =
    "You are a language detection engine. Given the following audio input, determine the ISO language code of the spoken language. Return only a JSON object with a single field \"language\" (for example, {\"language\": \"en\"}). Do not include any additional text.";

  const payload = {
    model: "gpt-4o-audio-preview",
    modalities: ["text"],  // output only text
    messages: [
      { role: "system", content: systemPrompt },
      {
        role: "user",
        content: [
          {
            type: "input_audio",
            input_audio: {
              data: wavBase64,
              format: "wav"
            }
          }
        ]
      }
    ]
  };

  const response = await axios.post(
    "https://api.openai.com/v1/chat/completions",
    payload,
    {
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`
      }
    }
  );

  if (response.status === 200) {
    const message = response.data.choices[0].message;
    let jsonResponse;
    try {
      jsonResponse = JSON.parse(message.content);
    } catch (err) {
      console.error("Error parsing GPT-4o response as JSON:", err);
      throw new Error("Could not parse GPT-4o response as JSON");
    }
    const detectedLanguage: string = jsonResponse.language;
    // Clean up temporary files.
    try {
      if (fs.existsSync(inputPath)) fs.unlinkSync(inputPath);
      if (fs.existsSync(outputPath)) fs.unlinkSync(outputPath);
    } catch (cleanupError) {
      console.error("Error cleaning up temporary files:", cleanupError);
    }
    return detectedLanguage;
  } else {
    throw new Error("Error from GPT-4o audio API");
  }
}
</file>

<file path="src/app/api/operativeScribeServer/route.ts">
// /api/scribe/route.ts
import { openai } from '@ai-sdk/openai';
import { streamText } from 'ai';

export async function POST(req: Request) {
  console.log("Incoming POST request to /api/scribe");
  try {
    // Log the raw request details for debugging
    console.log("Request method:", req.method);
    console.log("Request headers:", [...req.headers.entries()]);

    // Parse the request body and log its content
    const bodyText = await req.text();
    console.log("Raw request body:", bodyText);

    let payload;
    try {
      payload = JSON.parse(bodyText);
    } catch (jsonError) {
      console.error("Failed to parse request JSON:", jsonError);
      return new Response(JSON.stringify({ error: "Invalid JSON" }), {
        status: 400,
        headers: { "Content-Type": "application/json" },
      });
    }
    
    const { messages } = payload;
    console.log("Parsed messages:", messages);

    const systemPrompt = `
You assist in writing complex surgical reports. 
You act as an experienced orthopaedic surgeon. You write very detailed, thorough, and extensive surgical notes including operative notes and surgical notes according to the below plan. the different surgical notes should be written with subtitles and the subdivisions and NO initial identifiers (such as patient or doctor name). the operative note itself should not include subdivisions and subtitles. After the operative note is written, include:

1. Pathological and normal findings during surgery.
2. A postoperative physician note.
3. Pre-operative and post-operative orders for the floor nurses.
4. Extensive education for the patient including psychological support.
5. A brief history leading to the surgical decision.
6. A plan before surgery including measurable, actionable goals.
7. Admission and post-operation diagnosis.
8. Extensive hospital course summary.
9. Discharge physical examination.
10. Procedure summary.
11. Condition at discharge.
12. Health education and instructions at home.
13. A list of reasons to visit the hospital immediately after discharge.
the output should be in paragraphs with the subdivisions and the subtitles included. you will allow editing after the note is written and outputted.
    `;

    const stream = await streamText({
      model: openai("gpt-4o"),
      system: systemPrompt,
      messages,
    });

    return stream.toDataStreamResponse();
  } catch (error: any) {
    return new Response(JSON.stringify({ error: error.message }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
</file>

<file path="src/app/api/sendEmail/route.ts">
import { NextResponse } from "next/server";
import nodemailer from "nodemailer";

export async function POST(req: Request) {
    try {
        const { to, subject, text } = await req.json();

        if (!to || !subject || !text) {
            return NextResponse.json({ error: "Missing required fields" }, { status: 400 });
        }

        
        const transporter = nodemailer.createTransport({
            service: "gmail",
            auth: {
                user: process.env.GMAIL_USER, 
                pass: process.env.GMAIL_PASS, 
            },
        });

       
        const mailOptions = {
            from: process.env.GMAIL_USER,
            to, 
            subject,
            text,
        };

        await transporter.sendMail(mailOptions);

        return NextResponse.json({ message: "Email sent successfully!" }, { status: 200 });
    } catch (error: any) {
        return NextResponse.json({ error: error.message }, { status: 500 });
    }
}
</file>

<file path="src/app/api/session/route.ts">
import { NextResponse } from "next/server";

export async function GET() {
  try {
    const response = await fetch(
      "https://api.openai.com/v1/realtime/sessions",
      {
        method: "POST",
        headers: {
          Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          model: "gpt-4o-realtime-preview-2024-12-17",
        }),
      }
    );
    const data = await response.json();
    return NextResponse.json(data);
  } catch (error) {
    console.error("Error in /session:", error);
    return NextResponse.json(
      { error: "Internal Server Error" },
      { status: 500 }
    );
  }
}
</file>

<file path="src/app/components/UI/BackgroundStarryNight.tsx">
// src/app/components/Background.tsx
"use client";

import React, { useEffect, useRef } from 'react';
import * as THREE from 'three';

const Background: React.FC = () => {
  const containerRef = useRef<HTMLDivElement>(null);
  
  useEffect(() => {
    if (!containerRef.current) return;
    
    let camera: THREE.OrthographicCamera;
    let renderer: THREE.WebGLRenderer;
    const scene = new THREE.Scene();
    let dotMatrix: THREE.Points;
    let frameId: number;
    
    // Star animation parameters
    const MAX_ACTIVE_STARS = 8;  // Maximum number of stars shining at once
    const MIN_STAR_DURATION = 800;  // Min duration of star animation in ms
    const MAX_STAR_DURATION = 2000;  // Max duration of star animation in ms
    const activeStars = new Map();  // Track currently active stars
    
    function init() {
      scene.background = new THREE.Color(0x111111);
      
      const width = window.innerWidth;
      const height = window.innerHeight;
      
      const left = -width / 2;
      const right = width / 2;
      const top = height / 2;
      const bottom = -height / 2;
      camera = new THREE.OrthographicCamera(left, right, top, bottom, -1000, 1000);
      camera.position.z = 1;
      
      renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
      renderer.setSize(width, height);
      
      // Clear any previous renderers
      if (containerRef.current) {
        while (containerRef.current.firstChild) {
          containerRef.current.removeChild(containerRef.current.firstChild);
        }
        containerRef.current.appendChild(renderer.domElement);
      }
      
      createDotMatrix();
      
      window.addEventListener('resize', onWindowResize);
    }
    
    function createDotMatrix() {
      const columns = 40;
      const rows = 30;
      const totalDots = columns * rows;
      const positions = new Float32Array(totalDots * 3);
      const sizes = new Float32Array(totalDots);
      const colors = new Float32Array(totalDots * 3);
      
      const width = window.innerWidth;
      const height = window.innerHeight;
      
      const xSpacing = width / (columns - 1);
      const ySpacing = height / (rows - 1);
      
      let index = 0;
      let colorIndex = 0;
      const xStart = -width / 2;
      const yStart = -height / 2;
      
      for (let i = 0; i < columns; i++) {
        for (let j = 0; j < rows; j++) {
          const x = xStart + i * xSpacing;
          const y = yStart + j * ySpacing;
          positions[index] = x;
          positions[index + 1] = y;
          positions[index + 2] = 0;
          sizes[index / 3] = 2;
          
          // Default to light gray color
          colors[colorIndex] = 0.5;     // R
          colors[colorIndex + 1] = 0.5; // G
          colors[colorIndex + 2] = 0.5; // B
          
          index += 3;
          colorIndex += 3;
        }
      }
      
      const geometry = new THREE.BufferGeometry();
      geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
      geometry.setAttribute('size', new THREE.BufferAttribute(sizes, 1));
      geometry.setAttribute('color', new THREE.BufferAttribute(colors, 3));
      
      const material = new THREE.ShaderMaterial({
        uniforms: {},
        vertexShader: `
          attribute float size;
          attribute vec3 color;
          varying vec3 vColor;
          void main() {
            vColor = color;
            gl_PointSize = size;
            gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
          }
        `,
        fragmentShader: `
          varying vec3 vColor;
          void main() {
            // Create circular point with soft edge
            float r = distance(gl_PointCoord, vec2(0.5, 0.5));
            
            // Softer edge transition (from 0.3 to 0.5 instead of 0.4 to 0.5)
            float a = 1.0 - smoothstep(0.3, 0.5, r);
            
            // Enhanced glow effect with wider spread
            float glow = exp(-r*2.5) * 1.2;
            
            // Add outer halo with even wider spread
            float outerHalo = exp(-r*1.0) * 0.6;
            
            vec3 glowColor = vec3(1.0, 1.0, 1.0); // White glow
            
            // Mix base color with glow and outer halo
            vec3 finalColor = mix(vColor, glowColor, glow + outerHalo);
            
            // Boost brightness in center
            if (r < 0.2) {
              finalColor += (0.2 - r) * 2.0;
            }
            
            gl_FragColor = vec4(finalColor, a);
          }
        `,
        transparent: true,
        blending: THREE.AdditiveBlending
      });
      
      dotMatrix = new THREE.Points(geometry, material);
      scene.add(dotMatrix);
      
      // Start the animation loop for stars
      setTimeout(activateRandomStar, 1000);
    }
    
    function activateRandomStar() {
      if (!dotMatrix) return;
      
      const sizes = dotMatrix.geometry.attributes.size.array;
      const totalDots = sizes.length;
      
      // Only activate a new star if we're under the maximum
      if (activeStars.size < MAX_ACTIVE_STARS) {
        let randomIndex;
        // Find a dot that isn't already activated
        do {
          randomIndex = Math.floor(Math.random() * totalDots);
        } while (activeStars.has(randomIndex));
        
        // Random duration between min and max
        const duration = MIN_STAR_DURATION + Math.random() * (MAX_STAR_DURATION - MIN_STAR_DURATION);
        
        // Start time
        const startTime = Date.now();
        
        // Add to active stars
        activeStars.set(randomIndex, { startTime, duration });
      }
      
      // Schedule the next star activation
      const nextActivationDelay = 200 + Math.random() * 800; // Random delay between 0.2-1 seconds
      setTimeout(activateRandomStar, nextActivationDelay);
    }
    
    function updateStars() {
      if (dotMatrix) {
        const sizesAttr = dotMatrix.geometry.attributes.size;
        const colorsAttr = dotMatrix.geometry.attributes.color;
        const sizes = sizesAttr.array;
        const colors = colorsAttr.array;
        const now = Date.now();
        let needsUpdate = false;
        
        // Process each active star
        for (const [index, starData] of activeStars.entries()) {
          const { startTime, duration } = starData as { startTime: number; duration: number };
          const elapsed = now - startTime;
          
          if (elapsed >= duration) {
            // Animation completed, reset this star
            sizes[index] = 2;
            colors[index * 3] = 0.5;     // R
            colors[index * 3 + 1] = 0.5; // G
            colors[index * 3 + 2] = 0.5; // B
            activeStars.delete(index);
            needsUpdate = true;
          } else {
            // Animation in progress
            // Create a pulse effect using sin wave
            const progress = elapsed / duration;
            
            // First half of animation: grow and brighten
            // Second half: shrink and dim
            const pulseProgress = (progress < 0.5) 
                ? progress * 2  // 0 to 1 in first half
                : (1 - (progress - 0.5) * 2); // 1 to 0 in second half
            
            // Increased maximum size for more visual impact
            const size = 2 + pulseProgress * 8; // Size between 2 and 10
            sizes[index] = size;
            
            // Brighter colors with slight yellow tint
            colors[index * 3] = 0.5 + pulseProgress * 0.5;     // R (to 1.0)
            colors[index * 3 + 1] = 0.5 + pulseProgress * 0.5; // G (to 1.0)
            colors[index * 3 + 2] = 0.5 + pulseProgress * 0.4; // B (to 0.9)
            
            needsUpdate = true;
          }
        }
        
        if (needsUpdate) {
          sizesAttr.needsUpdate = true;
          colorsAttr.needsUpdate = true;
        }
      }
    }
    
    function onWindowResize() {
      if (!renderer || !camera) return;
      
      const width = window.innerWidth;
      const height = window.innerHeight;
      
      camera.left = -width / 2;
      camera.right = width / 2;
      camera.top = height / 2;
      camera.bottom = -height / 2;
      camera.updateProjectionMatrix();
      
      renderer.setSize(width, height);
      
      // Re-create dot matrix for new size
      if (dotMatrix) {
        scene.remove(dotMatrix);
        createDotMatrix();
      }
    }
    
    function animate() {
      frameId = requestAnimationFrame(animate);
      updateStars();
      renderer.render(scene, camera);
    }
    
    init();
    animate();
    
    // Cleanup on component unmount
    return () => {
      window.removeEventListener('resize', onWindowResize);
      cancelAnimationFrame(frameId);
      if (renderer) {
        renderer.dispose();
      }
      if (dotMatrix) {
        dotMatrix.geometry.dispose();
        (dotMatrix.material as THREE.Material).dispose();
      }
    };
  }, []);
  
  return (
    <div
      ref={containerRef}
      style={{
        position: 'fixed',
        top: 0,
        left: 0,
        width: '100%',
        height: '100%',
        zIndex: -1,
        pointerEvents: 'none'
      }}
    />
  );
};

export default Background;
</file>

<file path="src/app/components/UI/card.tsx">
import * as React from "react"
import { cn } from "@/app/utils/cn"

const Card = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn(
      "rounded-lg border bg-card text-card-foreground shadow-sm",
      className
    )}
    {...props}
  />
))
Card.displayName = "Card"

const CardHeader = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex flex-col space-y-1.5 p-6", className)}
    {...props}
  />
))
CardHeader.displayName = "CardHeader"

const CardTitle = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLHeadingElement>
>(({ className, ...props }, ref) => (
  <h3
    ref={ref}
    className={cn(
      "text-2xl font-semibold leading-none tracking-tight",
      className
    )}
    {...props}
  />
))
CardTitle.displayName = "CardTitle"

const CardDescription = React.forwardRef<
  HTMLParagraphElement,
  React.HTMLAttributes<HTMLParagraphElement>
>(({ className, ...props }, ref) => (
  <p
    ref={ref}
    className={cn("text-sm text-muted-foreground", className)}
    {...props}
  />
))
CardDescription.displayName = "CardDescription"

const CardContent = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div ref={ref} className={cn("p-6 pt-0", className)} {...props} />
))
CardContent.displayName = "CardContent"

const CardFooter = React.forwardRef<
  HTMLDivElement,
  React.HTMLAttributes<HTMLDivElement>
>(({ className, ...props }, ref) => (
  <div
    ref={ref}
    className={cn("flex items-center p-6 pt-0", className)}
    {...props}
  />
))
CardFooter.displayName = "CardFooter"

export { Card, CardHeader, CardFooter, CardTitle, CardDescription, CardContent }
</file>

<file path="src/app/components/UI/StarryBackground.tsx">
// src/app/components/StarryBackground.tsx
"use client";

import React, { useEffect, useRef } from 'react';
import * as THREE from 'three';

interface StarryBackgroundProps {
  children: React.ReactNode;
}

const StarryBackground: React.FC<StarryBackgroundProps> = ({ children }) => {
  const containerRef = useRef<HTMLDivElement>(null);
  const canvasContainerRef = useRef<HTMLDivElement>(null);
  const sceneRef = useRef<{
    scene: THREE.Scene | null;
    camera: THREE.OrthographicCamera | null;
    renderer: THREE.WebGLRenderer | null;
    dotMatrix: THREE.Points | null;
    animationFrameId: number | null;
    activeStars: Map<number, { startTime: number; duration: number }>;
  }>({
    scene: null,
    camera: null,
    renderer: null,
    dotMatrix: null,
    animationFrameId: null,
    activeStars: new Map()
  });

  useEffect(() => {
    if (!containerRef.current) return;

    // Create canvas container if it doesn't exist
    if (!canvasContainerRef.current) {
      const canvasContainer = document.createElement('div');
      canvasContainer.style.position = 'absolute';
      canvasContainer.style.top = '0';
      canvasContainer.style.left = '0';
      canvasContainer.style.width = '100%';
      canvasContainer.style.height = '100%';
      canvasContainer.style.zIndex = '0';
      canvasContainer.style.pointerEvents = 'none';
      canvasContainerRef.current = canvasContainer;
      containerRef.current.appendChild(canvasContainer);
    }

    // Star animation parameters
    const MAX_ACTIVE_STARS = 3;
    const MIN_STAR_DURATION = 100;
    const MAX_STAR_DURATION = 300;

    // Create scene
    const scene = new THREE.Scene();
    scene.background = new THREE.Color(0x333333);
    sceneRef.current.scene = scene;

    // Setup camera
    const width = window.innerWidth;
    const height = window.innerHeight;
    const left = -width / 2;
    const right = width / 2;
    const top = height / 2;
    const bottom = -height / 2;
    const camera = new THREE.OrthographicCamera(left, right, top, bottom, -1000, 1000);
    camera.position.z = 1;
    sceneRef.current.camera = camera;

    // Setup renderer
    const renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(width, height);
    canvasContainerRef.current.appendChild(renderer.domElement);
    sceneRef.current.renderer = renderer;

    // Create dot matrix
    const createDotMatrix = () => {
      const columns = 40;
      const rows = 30;
      const totalDots = columns * rows;
      const positions = new Float32Array(totalDots * 3);
      const sizes = new Float32Array(totalDots);
      const colors = new Float32Array(totalDots * 3);

      const xSpacing = width / (columns - 1);
      const ySpacing = height / (rows - 1);

      let index = 0;
      let colorIndex = 0;
      const xStart = -width / 2;
      const yStart = -height / 2;

      for (let i = 0; i < columns; i++) {
        for (let j = 0; j < rows; j++) {
          const x = xStart + i * xSpacing;
          const y = yStart + j * ySpacing;
          positions[index] = x;
          positions[index + 1] = y;
          positions[index + 2] = 0;
          sizes[index / 3] = 1;

          // Default to light gray color
          colors[colorIndex] = 0.2;     // R
          colors[colorIndex + 1] = 0.2; // G
          colors[colorIndex + 2] = 0.2; // B

          index += 3;
          colorIndex += 3;
        }
      }

      const geometry = new THREE.BufferGeometry();
      geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
      geometry.setAttribute('size', new THREE.BufferAttribute(sizes, 1));
      geometry.setAttribute('color', new THREE.BufferAttribute(colors, 3));

      const material = new THREE.ShaderMaterial({
        uniforms: {},
        vertexShader: `
          attribute float size;
          attribute vec3 color;
          varying vec3 vColor;
          void main() {
            vColor = color;
            gl_PointSize = size;
            gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
          }
        `,
        fragmentShader: `
        varying vec3 vColor;
        void main() {
          // Create circular point with very soft edge
          float r = distance(gl_PointCoord, vec2(0.4, 0.4));
          
          // More aggressive circular masking - cut off anything outside radius 0.5
          if (r > 0.4) {
            discard; // This forces a hard circular edge
          }
          
          // Extremely soft edge transition but only within the circle
          float edgeSoftness = smoothstep(0.45, 0.5, r);
          float a = 1.0 - edgeSoftness;
          
          // Primary inner glow - intense and focused
          float innerGlow = exp(-r*1.5) * 2.0;
          
          // Middle glow layer - provides the main diffusion
          float midGlow = exp(-r*0.8) * 1.2;
          
          // Outer halo - wide spread but still contained
          float outerHalo = exp(-r*0.4) * 0.9;
          
          // Extended halo that stays within bounds
          float extendedHalo = max(0.0, 1.0 - r*2.0) * 0.4;
          
          // Combine all glow layers
          float totalGlow = innerGlow + midGlow + outerHalo + extendedHalo;
          
          // Slightly warmer glow color for more visual appeal
          vec3 glowColor = vec3(1.0, 0.98, 0.95); // Slightly warm white
          
          // Mix base color with enhanced multi-layer glow
          vec3 finalColor = mix(vColor, glowColor, min(1.0, totalGlow));
          
          // Smooth central brightness boost with more intensity
          finalColor += max(0.0, 0.6 - r*2.0) * 2.5 * vec3(1.0, 0.97, 0.90);
          
          // Add subtle color variation based on distance from center
          finalColor += vec3(0.02, 0.01, 0.0) * (1.0 - min(1.0, r*2.0));
          
          gl_FragColor = vec4(finalColor, a);
        }
      `,
        transparent: true,
        blending: THREE.AdditiveBlending
      });

      // Clean up existing dot matrix if it exists
      if (sceneRef.current.dotMatrix) {
        scene.remove(sceneRef.current.dotMatrix);
        sceneRef.current.dotMatrix.geometry.dispose();
        (sceneRef.current.dotMatrix.material as THREE.Material).dispose();
      }

      const dotMatrix = new THREE.Points(geometry, material);
      scene.add(dotMatrix);
      sceneRef.current.dotMatrix = dotMatrix;

      // Start the star activation cycle
      setTimeout(activateRandomStar, 1000);
    };

    const activateRandomStar = () => {
      if (!sceneRef.current.dotMatrix) return;

      const dotMatrix = sceneRef.current.dotMatrix;
      const activeStars = sceneRef.current.activeStars;
      const totalDots = dotMatrix.geometry.attributes.size.array.length;

      // Only activate a new star if we're under the maximum
      if (activeStars.size < MAX_ACTIVE_STARS) {
        let randomIndex;
        // Find a dot that isn't already activated
        do {
          randomIndex = Math.floor(Math.random() * totalDots);
        } while (activeStars.has(randomIndex));

        // Random duration between min and max
        const duration = MIN_STAR_DURATION + Math.random() * (MAX_STAR_DURATION - MIN_STAR_DURATION);

        // Start time
        const startTime = Date.now();

        // Add to active stars
        activeStars.set(randomIndex, { startTime, duration });
      }

      // Schedule the next star activation
      const nextActivationDelay = 100 + Math.random() * 10; // Random delay between 0.2-1 seconds
      setTimeout(activateRandomStar, nextActivationDelay);
    };

    const updateStars = () => {
      if (!sceneRef.current.dotMatrix) return;

      const dotMatrix = sceneRef.current.dotMatrix;
      const activeStars = sceneRef.current.activeStars;
      
      const sizesAttr = dotMatrix.geometry.attributes.size;
      const colorsAttr = dotMatrix.geometry.attributes.color;
      const sizes = sizesAttr.array;
      const colors = colorsAttr.array;
      const now = Date.now();
      let needsUpdate = false;

      // Process each active star
      for (const [index, starData] of activeStars.entries()) {
        const { startTime, duration } = starData;
        const elapsed = now - startTime;

        if (elapsed >= duration) {
          // Animation completed, reset this star
          sizes[index] = 1;
          colors[index * 3] = 0.2;     // R
          colors[index * 3 + 1] = 0.2; // G
          colors[index * 3 + 2] = 0.2; // B
          activeStars.delete(index);
          needsUpdate = true;
        } else {
          // Animation in progress
          // Create a pulse effect using sin wave
          const progress = elapsed / duration;

          // First half of animation: grow and brighten
          // Second half: shrink and dim
          const pulseProgress = (progress < 0.5)
            ? progress * 2  // 0 to 1 in first half
            : (1 - (progress - 0.5) * 2); // 1 to 0 in second half

          // Increased maximum size for more visual impact
          const size = 2 + pulseProgress * 8; // Size between 2 and 10
          sizes[index] = size;

          // Brighter colors with slight yellow tint
          colors[index * 3] = 0.5 + pulseProgress * 0.5;     // R (to 1.0)
          colors[index * 3 + 1] = 0.5 + pulseProgress * 0.5; // G (to 1.0)
          colors[index * 3 + 2] = 0.5 + pulseProgress * 0.4; // B (to 0.9)

          needsUpdate = true;
        }
      }

      if (needsUpdate) {
        sizesAttr.needsUpdate = true;
        colorsAttr.needsUpdate = true;
      }
    };

    const onWindowResize = () => {
      if (!sceneRef.current.camera || !sceneRef.current.renderer) return;

      const width = window.innerWidth;
      const height = window.innerHeight;

      const camera = sceneRef.current.camera;
      camera.left = -width / 2;
      camera.right = width / 2;
      camera.top = height / 2;
      camera.bottom = -height / 2;
      camera.updateProjectionMatrix();

      const renderer = sceneRef.current.renderer;
      renderer.setSize(width, height);

      // Recreate dot matrix for new size
      createDotMatrix();
    };

    const animate = () => {
      if (!sceneRef.current.scene || !sceneRef.current.camera || !sceneRef.current.renderer) return;

      sceneRef.current.animationFrameId = requestAnimationFrame(animate);
      updateStars();
      
      const renderer = sceneRef.current.renderer;
      const scene = sceneRef.current.scene;
      const camera = sceneRef.current.camera;
      
      renderer.render(scene, camera);
    };

    // Initialize the scene
    createDotMatrix();
    window.addEventListener('resize', onWindowResize);
    animate();

    // Cleanup on unmount
    return () => {
      window.removeEventListener('resize', onWindowResize);
      
      if (sceneRef.current.animationFrameId) {
        cancelAnimationFrame(sceneRef.current.animationFrameId);
      }
      
      if (sceneRef.current.dotMatrix) {
        sceneRef.current.dotMatrix.geometry.dispose();
        (sceneRef.current.dotMatrix.material as THREE.Material).dispose();
      }
      
      if (sceneRef.current.renderer) {
        sceneRef.current.renderer.dispose();
      }
      
      if (canvasContainerRef.current && canvasContainerRef.current.parentNode) {
        canvasContainerRef.current.parentNode.removeChild(canvasContainerRef.current);
      }
    };
  }, []);

  return (
    <div 
      ref={containerRef} 
      className="relative w-full h-full"
      style={{ backgroundColor: '#111111' }} // Fallback background color
    >
      {/* Children container with content on top of the background */}
      <div className="relative z-10" style={{ inset: '10px', height: 'calc(100% - 20px)', width: 'calc(100% - 20px)' }}>
        {children}
      </div>
    </div>
  );
};

export default StarryBackground;
</file>

<file path="src/app/components/BottomToolbar.tsx">
import React from "react";
import { useElementsStore } from "@/store/elementsStore";

interface BottomToolbarProps {
  onToggleConnection: () => void;
  isPTTActive: boolean;
  setIsPTTActive: (val: boolean) => void;
  isPTTUserSpeaking: boolean;
  handleTalkButtonDown: () => void;
  handleTalkButtonUp: () => void;
  isEventsPaneExpanded: boolean;
  setIsEventsPaneExpanded: (val: boolean) => void;
  isAudioPlaybackEnabled: boolean;
  setIsAudioPlaybackEnabled: (val: boolean) => void;
}

function BottomToolbar({
  onToggleConnection,
  isPTTActive,
  setIsPTTActive,
  isPTTUserSpeaking,
  handleTalkButtonDown,
  handleTalkButtonUp,
  isEventsPaneExpanded,
  setIsEventsPaneExpanded,
  isAudioPlaybackEnabled,
  setIsAudioPlaybackEnabled,
}: BottomToolbarProps) {
  const { sessionStatus } = useElementsStore();
  
  const isConnected = sessionStatus === "CONNECTED";
  const isConnecting = sessionStatus === "CONNECTING";

  function getConnectionButtonLabel() {
    if (isConnected) return "Disconnect";
    if (isConnecting) return "Connecting...";
    return "Connect";
  }

  function getConnectionButtonClasses() {
    const baseClasses = "text-white text-base p-2 w-36 rounded-full h-full";
    const cursorClass = isConnecting ? "cursor-not-allowed" : "cursor-pointer";

    if (isConnected) {
      // Connected -> label "Disconnect" -> red
      return `bg-red-600 hover:bg-red-700 ${cursorClass} ${baseClasses}`;
    }
    // Disconnected or connecting -> label is either "Connect" or "Connecting" -> black
    return `bg-black hover:bg-gray-900 ${cursorClass} ${baseClasses}`;
  }

  return (
    <div className="p-4 flex flex-row items-center justify-center gap-x-8">
      <button
        onClick={onToggleConnection}
        className={getConnectionButtonClasses()}
        disabled={isConnecting}
      >
        {getConnectionButtonLabel()}
      </button>

      <div className="flex flex-row items-center gap-2">
        <input
          id="push-to-talk"
          type="checkbox"
          checked={isPTTActive}
          onChange={e => setIsPTTActive(e.target.checked)}
          disabled={!isConnected}
          className="w-4 h-4"
        />
        <label htmlFor="push-to-talk" className="flex items-center cursor-pointer">
          Push to talk
        </label>
        <button
          onMouseDown={handleTalkButtonDown}
          onMouseUp={handleTalkButtonUp}
          onTouchStart={handleTalkButtonDown}
          onTouchEnd={handleTalkButtonUp}
          disabled={!isPTTActive}
          className={
            (isPTTUserSpeaking ? "bg-gray-300" : "bg-gray-200") +
            " py-1 px-4 cursor-pointer rounded-full" +
            (!isPTTActive ? " bg-gray-100 text-gray-400" : "")
          }
        >
          Talk
        </button>
      </div>

      <div className="flex flex-row items-center gap-2">
        <input
          id="audio-playback"
          type="checkbox"
          checked={isAudioPlaybackEnabled}
          onChange={e => setIsAudioPlaybackEnabled(e.target.checked)}
          disabled={!isConnected}
          className="w-4 h-4"
        />
        <label htmlFor="audio-playback" className="flex items-center cursor-pointer">
          Audio playback
        </label>
      </div>

      <div className="flex flex-row items-center gap-2">
        <input
          id="logs"
          type="checkbox"
          checked={isEventsPaneExpanded}
          onChange={e => setIsEventsPaneExpanded(e.target.checked)}
          className="w-4 h-4"
        />
        <label htmlFor="logs" className="flex items-center cursor-pointer">
          Logs
        </label>
      </div>
    </div>
  );
}

export default BottomToolbar;
</file>

<file path="src/app/components/ClientOnly.tsx">
// src/app/components/ClientOnly.tsx
"use client";

import { useEffect, useState, ReactNode } from "react";

interface ClientOnlyProps {
  children: ReactNode;
}

export default function ClientOnly({ children }: ClientOnlyProps) {
  const [hasMounted, setHasMounted] = useState(false);

  useEffect(() => {
    setHasMounted(true);
  }, []);

  if (!hasMounted) {
    return null;
  }

  return <>{children}</>;
}
</file>

<file path="src/app/components/Eih.tsx">
"use client";

import React from "react";
import Image from "next/image";

function Eih() {
  return (
    <div className="flex flex-col flex-1  min-h-0 rounded-xl">
      <div className="flex items-center justify-center h-full relative">
        <Image 
          src="/eih.svg" 
          alt="EIH Logo" 
          width={400} 
          height={400} 
          className="object-contain z-10 relative"
        />
      </div>
    </div>
  );
}

export default Eih;
</file>

<file path="src/app/components/Events.tsx">
"use client";

import React, { useRef, useEffect, useState } from "react";
import { useEvent } from "@/app/contexts/EventContext";
import { LoggedEvent } from "@/app/types";

export interface EventsProps {
  isExpanded: boolean;
}

function Events({ isExpanded }: EventsProps) {
  const [prevEventLogs, setPrevEventLogs] = useState<LoggedEvent[]>([]);
  const eventLogsContainerRef = useRef<HTMLDivElement | null>(null);

  const { loggedEvents, toggleExpand } = useEvent();

  const getDirectionArrow = (direction: string) => {
    if (direction === "client") return { symbol: "", color: "#7f5af0" };
    if (direction === "server") return { symbol: "", color: "#2cb67d" };
    return { symbol: "", color: "#555" };
  };

  useEffect(() => {
    const hasNewEvent = loggedEvents.length > prevEventLogs.length;

    if (isExpanded && hasNewEvent && eventLogsContainerRef.current) {
      eventLogsContainerRef.current.scrollTop =
        eventLogsContainerRef.current.scrollHeight;
    }

    setPrevEventLogs(loggedEvents);
  }, [loggedEvents, isExpanded]);

  return (
    <div
      className={
        (isExpanded ? "w-3/4 overflow-auto" : "w-0 overflow-hidden opacity-0") +
        " transition-all rounded-xl duration-200 ease-in-out flex flex-col bg-white"
      }
      ref={eventLogsContainerRef}
    >
      {isExpanded && (
        <div>
          <div className="font-semibold px-6 py-4 sticky top-0 z-10 text-base border-b bg-white">
            Logs
          </div>
          <div>
            {loggedEvents.map((log) => {
              const arrowInfo = getDirectionArrow(log.direction);
              const isError =
                log.eventName.toLowerCase().includes("error") ||
                log.eventData?.response?.status_details?.error != null;

              return (
                <div
                  key={log.id}
                  className="border-t border-gray-200 py-2 px-6 font-mono"
                >
                  <div
                    onClick={() => toggleExpand(log.id)}
                    className="flex items-center justify-between cursor-pointer"
                  >
                    <div className="flex items-center flex-1">
                      <span
                        style={{ color: arrowInfo.color }}
                        className="ml-1 mr-2"
                      >
                      {arrowInfo.symbol}
                      </span>
                      <span
                        className={
                          "flex-1 text-sm " +
                          (isError ? "text-red-600" : "text-gray-800")
                        }
                      >
                        {log.eventName}
                      </span>
                    </div>
                    <div className="text-gray-500 ml-1 text-xs whitespace-nowrap">
                      {log.timestamp}
                    </div>
                  </div>

                  {log.expanded && log.eventData && (
                    <div className="text-gray-800 text-left">
                      <pre className="border-l-2 ml-1 border-gray-200 whitespace-pre-wrap break-words font-mono text-xs mb-2 mt-2 pl-2">
                        {JSON.stringify(log.eventData, null, 2)}
                      </pre>
                    </div>
                  )}
                </div>
              );
            })}
          </div>
        </div>
      )}
    </div>
  );
}

export default Events;
</file>

<file path="src/app/components/message.tsx">
import { Card, CardHeader } from "./UI/card";
import { Bot, User } from "lucide-react";
import { Message as MessageType } from "ai";
import ReactMarkdown from 'react-markdown';

export default function Message({ message }: { message: MessageType }) {
  const { role, content } = message;
  if (role === "assistant") {
    return (
        <div className="mb-4 p-4 rounded-lg bg-white text-black">
          <div className="flex items-center gap-2 mb-2 font-medium">
            <Bot className="text-blue-600" />
            <span>Surgical Report</span>
          </div>
          <div className="pl-2 border-l-2 border-blue-200">
            <ReactMarkdown
              components={{
                h1: ({node, ...props}) => <h1 className="text-2xl font-bold my-4" {...props} />,
                h2: ({node, ...props}) => <h2 className="text-xl font-bold my-3" {...props} />,
                h3: ({node, ...props}) => <h3 className="text-lg font-bold my-2" {...props} />,
                ul: ({node, ...props}) => <ul className="list-disc pl-5 my-2" {...props} />,
                ol: ({node, ...props}) => <ol className="list-decimal pl-5 my-2" {...props} />,
                li: ({node, ...props}) => <li className="my-1" {...props} />,
                p: ({node, ...props}) => <p className="my-2" {...props} />,
                strong: ({node, ...props}) => <strong className="font-bold" {...props} />,
                em: ({node, ...props}) => <em className="italic" {...props} />,
                blockquote: ({node, ...props}) => <blockquote className="border-l-4 border-gray-300 pl-4 italic my-2" {...props} />,
                code: ({node, ...props}) => <code className="bg-gray-100 px-1 rounded" {...props} />,
                pre: ({node, ...props}) => <pre className="bg-gray-100 p-2 rounded my-2 overflow-auto" {...props} />
              }}
            >
              {content}
            </ReactMarkdown>
          </div>
        </div>
      );
    
  }
  // For user messages (hidden in this context)
  return (
    <div className="hidden">
      {/* User messages are not displayed in the surgical scribe context */}
      {content}
    </div>
  );
}
</file>

<file path="src/app/components/printableForm.tsx">
"use client";

import { useRef } from "react";
import { useReactToPrint } from "react-to-print";
import { usePatientDataStore } from "@/store/patientDataStore";
import { useElementsStore } from "@/store/elementsStore";

export default function PrintableForm() {
  const containerRef = useRef(null);
  const patientData = usePatientDataStore((state) => state.patientDataForRequest);
  const showRequestData = useElementsStore((state) => state.showRequestData);

  const handlePrint = useReactToPrint({
    contentRef: containerRef,
  });

  return (
    <div className="flex flex-col items-center gap-4 p-4 h-full overflow-y-auto">
      <div
        ref={containerRef}
        className="relative w-[850px] h-[1200px] border shadow"
      >
        <img
          src="/fillForm.jpg"
          alt="Form Template"
          className="w-full h-full object-cover"
        />

        {showRequestData && (
          <>
            <div className="absolute top-[430px] left-[100px] text-sm">
              Diagnosis: {patientData?.diagnosis || ""}
            </div>
            <div className="absolute top-[470px] left-[100px] text-sm w-[600px]">
              Complaint: {patientData?.complaint || ""}
            </div>
            <div className="absolute top-[520px] left-[100px] text-sm w-[600px]">
              Plan: {patientData?.plan || ""}
            </div>
            <div className="absolute top-[570px] left-[100px] text-sm">
              CPT Code: {patientData?.cptCode || ""}
            </div>
          </>
        )}
      </div>

      <div className="flex gap-4">
        <button
          onClick={() => handlePrint()}
          className="bg-green-600 text-white px-4 py-2 rounded"
        >
          Export to PDF
        </button>
      </div>
    </div>
  );
}
</file>

<file path="src/app/components/SurgeryInfoNeeded.tsx">
"use client";

import React from "react";

function SurgeryInfoNeeded() {
  return (
    <div className="w-1/2 overflow-auto rounded-xl flex flex-col bg-white">
      <div>
        <div className="font-semibold px-6 py-4 sticky top-0 z-10 text-base border-b bg-white">
          Surgery Info Needed
        </div>
        <div className="px-6 py-4 text-sm text-gray-800">
          <div className="mb-4">
            <h3 className="font-medium text-gray-900 mb-2">1. Patient Information:</h3>
            <ul className="list-disc pl-5 space-y-1">
              <li>Age and gender</li>
              <li>Primary diagnosis</li>
              <li>Medical history and risk factors</li>
              <li>Any additional relevant patient information</li>
            </ul>
          </div>
          
          <div className="mb-4">
            <h3 className="font-medium text-gray-900 mb-2">2. Procedure Details:</h3>
            <ul className="list-disc pl-5 space-y-1">
              <li>Procedure name and type</li>
              <li>Anesthesia used</li>
              <li>Incision details</li>
              <li>Surgical approach</li>
              <li>Findings during surgery</li>
              <li>Implants or materials used</li>
              <li>Closure method</li>
            </ul>
          </div>
          
          <div className="mb-2">
            <h3 className="font-medium text-gray-900 mb-2">3. Post-Operative Information:</h3>
            <ul className="list-disc pl-5 space-y-1">
              <li>Estimated blood loss</li>
              <li>Complications (if any)</li>
              <li>Post-operative instructions</li>
              <li>Follow-up plans</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  );
}

export default SurgeryInfoNeeded;
</file>

<file path="src/app/components/surgicalScribePage.tsx">
"use client";

import { useEffect, useRef, useState } from "react";
import { useChat } from "@ai-sdk/react";
import { useTranscript } from "@/app/contexts/TranscriptContext"
import { useEvent } from "@/app/contexts/EventContext"
import { usePatientDataStore } from "@/store/patientDataStore";
import { useElementsStore } from "@/store/elementsStore";
import { useSendEmail } from "@/app/hooks/useSendEmail";
import Message from "./message";
import {marked} from 'marked';

export default function SurgicalScribePage() {
  // Get patient surgical data context including clear method
  const { logClientEvent } = useEvent();
  const { 
    patientSurgicalData, 
    setPatientSurgicalData, 
    appendPatientSurgicalData, 
    clearPatientSurgicalData 
  } = usePatientDataStore();
  
  const { 
    loadSurgicalPage,
    sendEmailStatus,
    setSendEmailStatus,
    setLoadSurgicalPage,
    surgeryInfoNeeded,
    setSurgeryInfoNeeded
  } = useElementsStore();

  // Initialize the chat hook with our API endpoint and an explicit id.
  const { messages, append } = useChat({
    api: "/api/operativeScribeServer",
    id: "surgical-scribe",
  });
  const { transcriptItems } = useTranscript();
  const scrollRef = useRef<HTMLDivElement>(null);
  const [convertedContent, setConvertedContent] = useState("");
  const lastSubmitted = useRef<string | null>(null);

  // Get the last message from the server (assistant) if available
  const lastServerMessage = messages.length > 0 
    ? messages.filter(m => m.role === 'assistant').pop()?.content || ''
    : '';
    useEffect(() => {
      async function convertMarkdown() {
        try {
          const html = await marked(lastServerMessage);
          setConvertedContent(html);
        } catch (error) {
          console.error("Error converting markdown:", error);
        }
      }
      if (lastServerMessage) {
        convertMarkdown();
      }
    }, [lastServerMessage]);
const plainTextContent = lastServerMessage.replace(/<[^>]*>/g, '');

const emailResponse = useSendEmail({ 
  data: { 
    html: convertedContent, 
    plainText: plainTextContent 
  } 
});

  // Handle email response
  useEffect(() => {
    if (emailResponse && emailResponse.success) {
      // Reset all flags when email is sent successfully
      setSendEmailStatus('idle');
      setLoadSurgicalPage(false);
      setSurgeryInfoNeeded(false);
      console.log('Email sent successfully, flags reset');
    }
  }, [emailResponse, setSendEmailStatus, setLoadSurgicalPage, setSurgeryInfoNeeded]);

  // Whenever patientSurgicalData changes (and is new), trigger a new submission.
  useEffect(() => {
    if (patientSurgicalData && patientSurgicalData !== lastSubmitted.current) {
      console.log("Appending new patient surgical data via hidden submission:", patientSurgicalData);
      append({ content: patientSurgicalData, role: "user" });
      lastSubmitted.current = patientSurgicalData;
    }
  }, [patientSurgicalData, append]);

  // Auto-scroll when messages update.
  useEffect(() => {
    if (scrollRef.current) {
      scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
    }
  }, [messages]);

  return (
    <div className="w-1/2 overflow-auto text-black rounded-xl bg-white">
      <div
        ref={scrollRef}
        className="p-6 text-black"
      >
        {messages.map((m, index) => (
          <Message key={index} message={m} />
        ))}
        {sendEmailStatus === 'sending' && (
          <div className="text-blue-500 mt-4">Sending email...</div>
        )}
        {sendEmailStatus === 'done' && (
          <div className="text-green-500 mt-4">Email sent successfully!</div>
        )}
      </div>
    </div>
  );
}
</file>

<file path="src/app/components/Transcript.tsx">
"use client";

import React, { useEffect, useRef, useState } from "react";
import ReactMarkdown from "react-markdown";
import { TranscriptItem } from "@/app/types";
import Image from "next/image";
import { useTranscript } from "@/app/contexts/TranscriptContext";
import { useElementsStore } from "@/store/elementsStore";

export interface TranscriptProps {
  onSendMessage: () => void;
  canSend: boolean;
}

function Transcript({
  onSendMessage,
  canSend,
}: TranscriptProps) {
  const { userText, setUserText } = useElementsStore();
  const { transcriptItems, toggleTranscriptItemExpand } = useTranscript();
  const transcriptRef = useRef<HTMLDivElement | null>(null);
  const [prevLogs, setPrevLogs] = useState<TranscriptItem[]>([]);
  const [justCopied, setJustCopied] = useState(false);
  const inputRef = useRef<HTMLInputElement | null>(null);

  function scrollToBottom() {
    if (transcriptRef.current) {
      transcriptRef.current.scrollTop = transcriptRef.current.scrollHeight;
    }
  }

  useEffect(() => {
    const hasNewMessage = transcriptItems.length > prevLogs.length;
    const hasUpdatedMessage = transcriptItems.some((newItem, index) => {
      const oldItem = prevLogs[index];
      return (
        oldItem &&
        (newItem.title !== oldItem.title || newItem.data !== oldItem.data)
      );
    });

    if (hasNewMessage || hasUpdatedMessage) {
      scrollToBottom();
    }

    setPrevLogs(transcriptItems);
  }, [transcriptItems]);

  // Autofocus on text box input on load
  useEffect(() => {
    if (canSend && inputRef.current) {
      inputRef.current.focus();
    }
  }, [canSend]);

  const handleCopyTranscript = async () => {
    if (!transcriptRef.current) return;
    try {
      await navigator.clipboard.writeText(transcriptRef.current.innerText);
      setJustCopied(true);
      setTimeout(() => setJustCopied(false), 1500);
    } catch (error) {
      console.error("Failed to copy transcript:", error);
    }
  };

  return (
    <div className="flex flex-col flex-1 bg-white min-h-0 rounded-xl">
      <div className="relative flex-1 min-h-0">
        <button
          onClick={handleCopyTranscript}
          className={`absolute w-20 top-3 right-2 mr-1 z-10 text-sm px-3 py-2 rounded-full bg-gray-200 hover:bg-gray-300`}
        >
          {justCopied ? "Copied!" : "Copy"}
        </button>

        <div
          ref={transcriptRef}
          className="overflow-auto p-4 flex flex-col gap-y-4 h-full"
        >
          {transcriptItems.map((item) => {
            const { itemId, type, role, data, expanded, timestamp, title = "", isHidden } = item;

            if (isHidden) {
              return null;
            }

            if (type === "MESSAGE") {
              const isUser = role === "user";
              const baseContainer = "flex justify-end flex-col";
              const containerClasses = `${baseContainer} ${isUser ? "items-end" : "items-start"}`;
              const bubbleBase = `max-w-lg p-3 rounded-xl ${isUser ? "bg-gray-900 text-gray-100" : "bg-gray-100 text-black"}`;
              const isBracketedMessage = title.startsWith("[") && title.endsWith("]");
              const messageStyle = isBracketedMessage ? "italic text-gray-400" : "";
              const displayTitle = isBracketedMessage ? title.slice(1, -1) : title;

              return (
                <div key={itemId} className={containerClasses}>
                  <div className={bubbleBase}>
                    <div className={`text-xs ${isUser ? "text-gray-400" : "text-gray-500"} font-mono`}>
                      {timestamp}
                    </div>
                    <div className={`whitespace-pre-wrap ${messageStyle}`}>
                      <ReactMarkdown>{displayTitle}</ReactMarkdown>
                    </div>
                  </div>
                </div>
              );
            } else if (type === "BREADCRUMB") {
              return (
                <div
                  key={itemId}
                  className="flex flex-col justify-start items-start text-gray-500 text-sm"
                >
                  <span className="text-xs font-mono">{timestamp}</span>
                  <div
                    className={`whitespace-pre-wrap flex items-center font-mono text-sm text-gray-800 ${
                      data ? "cursor-pointer" : ""
                    }`}
                    onClick={() => data && toggleTranscriptItemExpand(itemId)}
                  >
                    {data && (
                      <span
                        className={`text-gray-400 mr-1 transform transition-transform duration-200 select-none font-mono ${
                          expanded ? "rotate-90" : "rotate-0"
                        }`}
                      >
                        
                      </span>
                    )}
                    {title}
                  </div>
                  {expanded && data && (
                    <div className="text-gray-800 text-left">
                      <pre className="border-l-2 ml-1 border-gray-200 whitespace-pre-wrap break-words font-mono text-xs mb-2 mt-2 pl-2">
                        {JSON.stringify(data, null, 2)}
                      </pre>
                    </div>
                  )}
                </div>
              );
            } else {
              // Fallback if type is neither MESSAGE nor BREADCRUMB
              return (
                <div
                  key={itemId}
                  className="flex justify-center text-gray-500 text-sm italic font-mono"
                >
                  Unknown item type: {type}{" "}
                  <span className="ml-2 text-xs">{timestamp}</span>
                </div>
              );
            }
          })}
        </div>
      </div>

      <div className="p-4 flex items-center gap-x-2 flex-shrink-0 border-t border-gray-200">
        <input
          ref={inputRef}
          type="text"
          value={userText}
          onChange={(e) => setUserText(e.target.value)}
          onKeyDown={(e) => {
            if (e.key === "Enter" && canSend) {
              onSendMessage();
            }
          }}
          className="flex-1 px-4 py-2 focus:outline-none"
          placeholder="Type a message..."
        />
        <button
          onClick={onSendMessage}
          disabled={!canSend || !userText.trim()}
          className="bg-gray-900 text-white rounded-full px-2 py-2 disabled:opacity-50"
        >
          <Image src="arrow.svg" alt="Send" width={24} height={24} />
        </button>
      </div>
    </div>
  );
}

export default Transcript;
</file>

<file path="src/app/components/TranslationsPage.tsx">
"use client";

import React, { useEffect, useRef, useState } from "react";
import { useElementsStore } from "@/store/elementsStore";
import { usePatientDataStore, LanguagesContext } from "@/store/patientDataStore";

// Common languages for medical translation
const AVAILABLE_LANGUAGES = [
  "English",
  "French",
  "Spanish",
  "German",
  "Arabic",
  "Chinese",
  "Russian",
  "Hindi"
];

interface TranslationPageProps {
  changeAgent: (agentName: string) => void;
}

export default function TranslationPage({ changeAgent }: TranslationPageProps) {
  // Import states from elementsStore using the hook pattern
  const theUserIsSpeaking = useElementsStore(state => state.theUserIsSpeaking);
  const assistantVoiceFinished = useElementsStore(state => state.assistantVoiceFinished);
  const selectedAgentName = useElementsStore(state => state.selectedAgentName);
  const micMuted = useElementsStore(state => state.micMuted);
  const setTheUserIsSpeaking = useElementsStore(state => state.setTheUserIsSpeaking);
  const setAssistantVoiceFinished = useElementsStore(state => state.setAssistantVoiceFinished);
  
  // Import states from patientDataStore
  const languagesContext = usePatientDataStore(state => state.languagesContext);
  const setLanguagesContext = usePatientDataStore(state => state.setLanguagesContext);
  
  // Local state for language selections
  const [doctorLanguage, setDoctorLanguage] = useState(languagesContext.doctorLanguage || "English");
  const [patientLanguage, setPatientLanguage] = useState(languagesContext.patientLanguage || "French");
  
  // Flag to track if we just updated languages to avoid infinite loops
  const [languagesJustUpdated, setLanguagesJustUpdated] = useState(false);
  
  // Create a ref to track if we're in the process of changing agents
  const changingAgentRef = useRef<boolean>(false);
  
  // Create a ref to track the current translator type
  const currentTranslatorRef = useRef("patientToDoctor");
  
  // Create a ref to track if the assistant just finished speaking to prevent re-entry
  const assistantJustFinishedRef = useRef<boolean>(false);
  



useEffect(() => {
  let cancelled = false;
  // Define states: "idle" (ready to record), "recording" (currently recording), "blocked" (recorded; waiting for silence)
  let currentState: "idle" | "recording" | "blocked" = "idle";
  let silenceStartTime: number | null = null;
  let animationFrameId: number;

  // Instead of calling getUserMedia again, use the shared mic stream
  const micStream = useElementsStore.getState().micRef.current;
  if (!micStream) {
    console.error("No mic stream available from realtime connection.");
    return;
  }

  const audioContext = new AudioContext();
  const source = audioContext.createMediaStreamSource(micStream);
  const analyser = audioContext.createAnalyser();
  analyser.fftSize = 2048;
  source.connect(analyser);

  const dataArray = new Uint8Array(analyser.frequencyBinCount);
  const volumeThreshold = 15; // Adjust threshold as needed

  const startRecording = () => {
    const recorderOptions = { mimeType: 'audio/webm' };
    const mediaRecorder = new MediaRecorder(micStream, recorderOptions);
    const chunks: BlobPart[] = [];

    mediaRecorder.ondataavailable = (event) => {
      if (event.data && event.data.size > 0) {
        chunks.push(event.data);
      }
    };

    mediaRecorder.onstop = () => {
      const blob = new Blob(chunks, { type: 'audio/webm' });
      const reader = new FileReader();
      reader.onloadend = () => {
        const base64data = (reader.result as string).split(',')[1];
        // Send the Base64 audio to your API
        fetch("/api/languageDetectorServer", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ audio: base64data })
        })
          .then(response => response.json())
          .then(data => console.log("Language detection response:", data))
          .catch(error => console.error("Error uploading audio:", error));
      };
      reader.readAsDataURL(blob);
      // After recording, block further recordings until silence is detected
      currentState = "blocked";
    };

    mediaRecorder.start();
    // Automatically stop recording after 2 seconds
    setTimeout(() => {
      if (mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
      }
    }, 2000);
  };

  const checkForSpeech = () => {
    if (cancelled) return;
    
    // Get the current micMuted state
    const micMuted = useElementsStore.getState().micMuted;
    
    analyser.getByteTimeDomainData(dataArray);
    let sum = 0;
    for (let i = 0; i < dataArray.length; i++) {
      sum += Math.abs(dataArray[i] - 128);
    }
    const avg = sum / dataArray.length;

    // Only process audio if the mic is not muted
    if (!micMuted) {
      if (currentState === "idle") {
        if (avg > volumeThreshold) {
          console.log("Page:Speech detected: starting 2-second recording.");
          currentState = "recording";
          startRecording();
        }
      } else if (currentState === "blocked") {
        // Wait for at least 1 second of silence before resetting state
        if (avg <= volumeThreshold) {
          if (silenceStartTime === null) {
            silenceStartTime = Date.now();
          } else if (Date.now() - silenceStartTime > 3000) {
            currentState = "idle";
            silenceStartTime = null;
          }
        } else {
          silenceStartTime = null;
        }
      }
    } else {
      // If mic is muted, we should reset to idle state when unmuted
      if (currentState !== "idle") {
        currentState = "idle";
        silenceStartTime = null;
      }
    }
    
    animationFrameId = requestAnimationFrame(checkForSpeech);
  };

  checkForSpeech();

  return () => {
    cancelled = true;
    cancelAnimationFrame(animationFrameId);
    audioContext.close();
    // Do not stop micStream here since it's shared with WebRTC
  };
}, []);

  // Effect to synchronize local language state with patientDataStore
  // This only updates the languages context without triggering agent changes
  useEffect(() => {
    // Skip if we're in the middle of a language update
    if (languagesJustUpdated) {
      setLanguagesJustUpdated(false);
      return;
    }
    
    setLanguagesContext({
      doctorLanguage,
      patientLanguage
    });
    
    // Manual one-time reload of the agent after language change
    // This pattern breaks the dependency loop
    const timeout = setTimeout(() => {
      changeAgent(currentTranslatorRef.current);
    }, 100);
    
    return () => clearTimeout(timeout);
  }, [doctorLanguage, patientLanguage]);
  


  // Effect to handle agent switching when user starts speaking
  useEffect(() => {
    // Only proceed if user is speaking and we're not already changing agents
    if (theUserIsSpeaking && !changingAgentRef.current) {
      assistantJustFinishedRef.current = false; 
      // Set changing agent flag to true to prevent recursive calls
      changingAgentRef.current = true;
      
      // Toggle the translator type
      if (currentTranslatorRef.current === "doctorToPatient") {
        currentTranslatorRef.current = "patientToDoctor";
      } else {
        currentTranslatorRef.current = "doctorToPatient";
      }
      
      // Call the changeAgent callback with the new agent name
      changeAgent(currentTranslatorRef.current);
    }
  }, [theUserIsSpeaking, changeAgent]);

  // Effect to reset the changing agent flag when assistant voice finishes and user is not speaking
  useEffect(() => {
    if (!theUserIsSpeaking && changingAgentRef.current) {
      changingAgentRef.current = false;
    }
  }, [theUserIsSpeaking]);
  
  // Handler for language changes
  const handleLanguageChange = (type: 'doctor' | 'patient', language: string) => {
    setLanguagesJustUpdated(true);
    if (type === 'doctor') {
      setDoctorLanguage(language);
    } else {
      setPatientLanguage(language);
    }
  };

  return (
    <div className="p-4 bg-white rounded-lg shadow">
      <h2 className="text-xl font-bold mb-4">Translation Assistant</h2>
      
      {/* Language selection UI */}
      <div className="grid grid-cols-2 gap-4 mb-6">
        <div>
          <label className="block text-sm font-medium text-gray-700 mb-1">
            Doctor Language
          </label>
          <select 
            className="w-full border border-gray-300 rounded-md py-2 px-3"
            value={doctorLanguage}
            onChange={(e) => handleLanguageChange('doctor', e.target.value)}
          >
            {AVAILABLE_LANGUAGES.map(lang => (
              <option key={`doctor-${lang}`} value={lang}>{lang}</option>
            ))}
          </select>
        </div>
        
        <div>
          <label className="block text-sm font-medium text-gray-700 mb-1">
            Patient Language
          </label>
          <select 
            className="w-full border border-gray-300 rounded-md py-2 px-3"
            value={patientLanguage}
            onChange={(e) => handleLanguageChange('patient', e.target.value)}
          >
            {AVAILABLE_LANGUAGES.map(lang => (
              <option key={`patient-${lang}`} value={lang}>{lang}</option>
            ))}
          </select>
        </div>
      </div>
      
      <p className="text-gray-700 mb-2">
        Current mode: {currentTranslatorRef.current === "patientToDoctor" 
          ? `${patientLanguage}  ${doctorLanguage}` 
          : `${doctorLanguage}  ${patientLanguage}`}
      </p>
      
      <div className="mt-4">
        <p className="text-sm text-gray-500">
          {theUserIsSpeaking ? "Listening..." : "Ready for translation"}
        </p>
        <p className="text-sm text-gray-500">
          {assistantVoiceFinished ? "Translation complete" : ""}
        </p>
        <p className="text-sm text-gray-500">
          Microphone status: {micMuted ? "Muted (during translation)" : "Active"}
        </p>
      </div>
    </div>
  );
}
</file>

<file path="src/app/contexts/EventContext.tsx">
"use client";

import React, { createContext, useContext, useState, FC, PropsWithChildren } from "react";
import { v4 as uuidv4 } from "uuid";
import { LoggedEvent } from "@/app/types";

type EventContextValue = {
  loggedEvents: LoggedEvent[];
  logClientEvent: (eventObj: Record<string, any>, eventNameSuffix?: string) => void;
  logServerEvent: (eventObj: Record<string, any>, eventNameSuffix?: string) => void;
  toggleExpand: (id: number | string) => void;
};

const EventContext = createContext<EventContextValue | undefined>(undefined);

export const EventProvider: FC<PropsWithChildren> = ({ children }) => {
  const [loggedEvents, setLoggedEvents] = useState<LoggedEvent[]>([]);

  function addLoggedEvent(direction: "client" | "server", eventName: string, eventData: Record<string, any>) {
    const id = eventData.event_id || uuidv4();
    setLoggedEvents((prev) => [
      ...prev,
      {
        id,
        direction,
        eventName,
        eventData,
        timestamp: new Date().toLocaleTimeString(),
        expanded: false,
      },
    ]);
  }

  const logClientEvent: EventContextValue["logClientEvent"] = (eventObj, eventNameSuffix = "") => {
    const name = `${eventObj.type || ""} ${eventNameSuffix || ""}`.trim();
    addLoggedEvent("client", name, eventObj);
  };

  const logServerEvent: EventContextValue["logServerEvent"] = (eventObj, eventNameSuffix = "") => {
    const name = `${eventObj.type || ""} ${eventNameSuffix || ""}`.trim();
    addLoggedEvent("server", name, eventObj);
  };

  const toggleExpand: EventContextValue["toggleExpand"] = (id) => {
    setLoggedEvents((prev) =>
      prev.map((log) => {
        if (log.id === id) {
          return { ...log, expanded: !log.expanded };
        }
        return log;
      })
    );
  };


  return (
    <EventContext.Provider
      value={{ loggedEvents, logClientEvent, logServerEvent, toggleExpand }}
    >
      {children}
    </EventContext.Provider>
  );
};

export function useEvent() {
  const context = useContext(EventContext);
  if (!context) {
    throw new Error("useEvent must be used within an EventProvider");
  }
  return context;
}
</file>

<file path="src/app/contexts/TranscriptContext.tsx">
"use client";

import React, { createContext, useContext, useState, FC, PropsWithChildren } from "react";
import { v4 as uuidv4 } from "uuid";
import { TranscriptItem } from "@/app/types";

type TranscriptContextValue = {
  transcriptItems: TranscriptItem[];
  addTranscriptMessage: (itemId: string, role: "user" | "assistant", text: string, hidden?: boolean) => void;
  updateTranscriptMessage: (itemId: string, text: string, isDelta: boolean) => void;
  addTranscriptBreadcrumb: (title: string, data?: Record<string, any>) => void;
  toggleTranscriptItemExpand: (itemId: string) => void;
  updateTranscriptItemStatus: (itemId: string, newStatus: "IN_PROGRESS" | "DONE") => void;
};

const TranscriptContext = createContext<TranscriptContextValue | undefined>(undefined);

export const TranscriptProvider: FC<PropsWithChildren> = ({ children }) => {
  const [transcriptItems, setTranscriptItems] = useState<TranscriptItem[]>([]);

  function newTimestampPretty(): string {
    return new Date().toLocaleTimeString([], {
      hour12: true,
      hour: "numeric",
      minute: "2-digit",
      second: "2-digit",
    });
  }

  const addTranscriptMessage: TranscriptContextValue["addTranscriptMessage"] = (itemId, role, text = "", isHidden = false) => {
    setTranscriptItems((prev) => {
      if (prev.some((log) => log.itemId === itemId && log.type === "MESSAGE")) {
        console.warn(`[addTranscriptMessage] skipping; message already exists for itemId=${itemId}, role=${role}, text=${text}`);
        return prev;
      }

      const newItem: TranscriptItem = {
        itemId,
        type: "MESSAGE",
        role,
        title: text,
        expanded: false,
        timestamp: newTimestampPretty(),
        createdAtMs: Date.now(),
        status: "IN_PROGRESS",
        isHidden,
      };

      return [...prev, newItem];
    });
  };

  const updateTranscriptMessage: TranscriptContextValue["updateTranscriptMessage"] = (itemId, newText, append = false) => {
    setTranscriptItems((prev) =>
      prev.map((item) => {
        if (item.itemId === itemId && item.type === "MESSAGE") {
          return {
            ...item,
            title: append ? (item.title ?? "") + newText : newText,
          };
        }
        return item;
      })
    );
  };

  const addTranscriptBreadcrumb: TranscriptContextValue["addTranscriptBreadcrumb"] = (title, data) => {
    setTranscriptItems((prev) => [
      ...prev,
      {
        itemId: `breadcrumb-${uuidv4()}`,
        type: "BREADCRUMB",
        title,
        data,
        expanded: false,
        timestamp: newTimestampPretty(),
        createdAtMs: Date.now(),
        status: "DONE",
        isHidden: false,
      },
    ]);
  };

  const toggleTranscriptItemExpand: TranscriptContextValue["toggleTranscriptItemExpand"] = (itemId) => {
    setTranscriptItems((prev) =>
      prev.map((log) =>
        log.itemId === itemId ? { ...log, expanded: !log.expanded } : log
      )
    );
  };

  const updateTranscriptItemStatus: TranscriptContextValue["updateTranscriptItemStatus"] = (itemId, newStatus) => {
    setTranscriptItems((prev) =>
      prev.map((item) =>
        item.itemId === itemId ? { ...item, status: newStatus } : item
      )
    );
  };

  return (
    <TranscriptContext.Provider
      value={{
        transcriptItems,
        addTranscriptMessage,
        updateTranscriptMessage,
        addTranscriptBreadcrumb,
        toggleTranscriptItemExpand,
        updateTranscriptItemStatus,
      }}
    >
      {children}
    </TranscriptContext.Provider>
  );
};

export function useTranscript() {
  const context = useContext(TranscriptContext);
  if (!context) {
    throw new Error("useTranscript must be used within a TranscriptProvider");
  }
  return context;
}
</file>

<file path="src/app/hooks/useCancelAssistantSpeech.ts">
"use client";

import { useTranscript } from "@/app/contexts/TranscriptContext";
import { useSendClientEvent } from "./useSendClientEvent";

export function useCancelAssistantSpeech() {
  const { transcriptItems } = useTranscript();
  const sendClientEvent = useSendClientEvent();

  const cancelAssistantSpeech = async () => {
    const mostRecentAssistantMessage = [...transcriptItems]
      .reverse()
      .find((item) => item.role === "assistant");

    if (!mostRecentAssistantMessage) {
      console.warn("can't cancel, no recent assistant message found");
      return;
    }
    if (mostRecentAssistantMessage.status === "DONE") {
      console.log("No truncation needed, message is DONE");
      return;
    }

    sendClientEvent({
      type: "conversation.item.truncate",
      item_id: mostRecentAssistantMessage?.itemId,
      content_index: 0,
      audio_end_ms: Date.now() - mostRecentAssistantMessage.createdAtMs,
    });
    sendClientEvent(
      { type: "response.cancel" },
      "(cancel due to user interruption)"
    );
  };

  return cancelAssistantSpeech;
}
</file>

<file path="src/app/hooks/useConnection.ts">
// src/app/hooks/useConnection.ts
"use client";

import { useEvent } from "@/app/contexts/EventContext";
import { useElementsStore } from "@/store/elementsStore";
import { createRealtimeConnection } from "@/app/lib/realtimeConnection";
import { RefObject } from "react";

export function useConnection() {
  const { logClientEvent, logServerEvent } = useEvent();
  const { 
    setSessionStatus, 
    pcRef, 
    dcRef, 
    audioElementRef,
    setDataChannel,
    sessionStatus
  } = useElementsStore();

  const fetchEphemeralKey = async (): Promise<string | null> => {
    logClientEvent({ url: "/session" }, "fetch_session_token_request");
    const tokenResponse = await fetch("/api/session");
    const data = await tokenResponse.json();
    logServerEvent(data, "fetch_session_token_response");

    if (!data.client_secret?.value) {
      logClientEvent(data, "error.no_ephemeral_key");
      console.error("No ephemeral key provided by the server");
      setSessionStatus("DISCONNECTED");
      return null;
    }

    return data.client_secret.value;
  };

  const connectToRealtime = async (
    isAudioPlaybackEnabled: boolean,
    handleServerEventRef: RefObject<(event: any) => void>,
    micStream: MediaStream
  ) => {
    if (sessionStatus !== "DISCONNECTED") return;
    setSessionStatus("CONNECTING");

    try {
      const EPHEMERAL_KEY = await fetchEphemeralKey();
      if (!EPHEMERAL_KEY) {
        return;
      }

      // Initialize audio element if needed
      if (!audioElementRef.current) {
        const audioEl = document.createElement("audio");
        audioEl.id = "realtime-audio";
        audioEl.style.display = "none"; // hide it from the UI
        document.body.appendChild(audioEl);
        audioElementRef.current = audioEl;
      }
      audioElementRef.current.autoplay = isAudioPlaybackEnabled;

      // Create the connection with the provided microphone stream
      const { pc, dc } = await createRealtimeConnection(
        EPHEMERAL_KEY,
        audioElementRef,
        micStream
      );
      pcRef.current = pc;
      dcRef.current = dc;

      dc.addEventListener("open", () => {
        logClientEvent({}, "data_channel.open");
      });
      dc.addEventListener("close", () => {
        logClientEvent({}, "data_channel.close");
      });
      dc.addEventListener("error", (err: any) => {
        logClientEvent({ error: err }, "data_channel.error");
      });
      dc.addEventListener("message", (e: MessageEvent) => {
        if (handleServerEventRef.current) {
          handleServerEventRef.current(JSON.parse(e.data));
        }
      });

      setDataChannel(dc);
    } catch (err) {
      console.error("Error connecting to realtime:", err);
      setSessionStatus("DISCONNECTED");
    }
  };

  const disconnectFromRealtime = () => {
    // Clean up WebRTC connection
    if (pcRef.current) {
      pcRef.current.getSenders().forEach((sender) => {
        if (sender.track) {
          sender.track.stop();
        }
      });

      pcRef.current.close();
      pcRef.current = null;
    }
    
    setDataChannel(null);
    setSessionStatus("DISCONNECTED");
    
    logClientEvent({}, "disconnected");
  };

  return {
    connectToRealtime,
    disconnectFromRealtime
  };
}
</file>

<file path="src/app/hooks/useHandleSendTextMessage.ts">
"use client";

import { useSendClientEvent } from "./useSendClientEvent";
import { useCancelAssistantSpeech } from "./useCancelAssistantSpeech";
import { useElementsStore } from "@/store/elementsStore";

export function useHandleSendTextMessage() {
  const sendClientEvent = useSendClientEvent();
  const cancelAssistantSpeech = useCancelAssistantSpeech();
  const { userText, setUserText } = useElementsStore();

  const handleSendTextMessage = () => {
    if (!userText.trim()) return;
    cancelAssistantSpeech();

    sendClientEvent(
      {
        type: "conversation.item.create",
        item: {
          type: "message",
          role: "user",
          content: [{ type: "input_text", text: userText.trim() }],
        },
      },
      "(send user text message)"
    );
    setUserText("");

    sendClientEvent({ type: "response.create" }, "trigger response");
  };

  return handleSendTextMessage;
}
</file>

<file path="src/app/hooks/useHandleServerEvent.ts">
"use client";

import { ServerEvent } from "@/app/types";
import { useTranscript } from "@/app/contexts/TranscriptContext";
import { useEvent } from "@/app/contexts/EventContext";
import { useSendClientEvent } from "@/app/hooks/useSendClientEvent";
import { useElementsStore } from "@/store/elementsStore";
import { useRef } from "react";

function generateId() {
  return crypto?.randomUUID ? crypto.randomUUID() : Date.now().toString();
}

export function useHandleServerEvent() {
  const {
    transcriptItems,
    addTranscriptBreadcrumb,
    addTranscriptMessage,
    updateTranscriptMessage,
    updateTranscriptItemStatus,
  } = useTranscript();

  const { logServerEvent } = useEvent();
  
  const sendClientEvent = useSendClientEvent();

  const handleFunctionCall = async (functionCallParams: {
    name: string;
    call_id?: string;
    arguments: string;
  }) => {
    const args = JSON.parse(functionCallParams.arguments);
    const selectedAgentName = useElementsStore.getState().selectedAgentName;
    const selectedAgentConfigSet = useElementsStore.getState().selectedAgentConfigSet;
    const currentAgent = selectedAgentConfigSet?.find(
      (a) => a.name === selectedAgentName
    );

    addTranscriptBreadcrumb(`function call: ${functionCallParams.name}`, args);

    if (currentAgent?.toolLogic?.[functionCallParams.name]) {
      const fn = currentAgent.toolLogic[functionCallParams.name];
      const fnResult = await fn(args, transcriptItems);
      addTranscriptBreadcrumb(
        `function call result: ${functionCallParams.name}`,
        fnResult
      );

      sendClientEvent({
        type: "conversation.item.create",
        item: {
          type: "function_call_output",
          call_id: functionCallParams.call_id,
          output: JSON.stringify(fnResult),
        },
      });
      sendClientEvent({ type: "response.create" });
    } else if (functionCallParams.name === "transferAgents") {
      const destinationAgent = args.destination_agent;
      if (destinationAgent === "operativeReportAssistant") {
        useElementsStore.getState().setSurgeryInfoNeeded(true);
      }
      if (destinationAgent === "requestHandler") {
        console.log("Transfer to requestHandler");
        useElementsStore.getState().setCreateRequest(true);
      }
      const newAgentConfig =
        selectedAgentConfigSet?.find((a) => a.name === destinationAgent) || null;
      if (newAgentConfig) {
        useElementsStore.getState().setSelectedAgentName(destinationAgent);
      }
      const functionCallOutput = {
        destination_agent: destinationAgent,
        did_transfer: !!newAgentConfig,
      };
      sendClientEvent({
        type: "conversation.item.create",
        item: {
          type: "function_call_output",
          call_id: functionCallParams.call_id,
          output: JSON.stringify(functionCallOutput),
        },
      });
      addTranscriptBreadcrumb(
        `function call: ${functionCallParams.name} response`,
        functionCallOutput
      );
    } else {
      const simulatedResult = { result: true };
      addTranscriptBreadcrumb(
        `function call fallback: ${functionCallParams.name}`,
        simulatedResult
      );

      sendClientEvent({
        type: "conversation.item.create",
        item: {
          type: "function_call_output",
          call_id: functionCallParams.call_id,
          output: JSON.stringify(simulatedResult),
        },
      });
      sendClientEvent({ type: "response.create" });
    }
  };

  const handleServerEvent = (serverEvent: ServerEvent) => {
    logServerEvent(serverEvent);

    switch (serverEvent.type) {
      case "session.created": {
        if (serverEvent.session?.id) {
          useElementsStore.getState().setSessionStatus("CONNECTED");
          addTranscriptBreadcrumb(
            `session.id: ${
              serverEvent.session.id
            }\nStarted at: ${new Date().toLocaleString()}`
          );
        }
        break;
      }

      case "conversation.item.created": {
        let text =
          serverEvent.item?.content?.[0]?.text ||
          serverEvent.item?.content?.[0]?.transcript ||
          "";
        const role = serverEvent.item?.role as "user" | "assistant";
        const itemId = serverEvent.item?.id;

        if (itemId && transcriptItems.some((item) => item.itemId === itemId)) {
          break;
        }

        if (itemId && role) {
          if (role === "user" && !text) {
            text = "[Transcribing...]";
          }
          addTranscriptMessage(itemId, role, text);
        }
        break;
      }

      case "conversation.item.input_audio_transcription.completed": {
        const itemId = serverEvent.item_id;
        const finalTranscript =
          !serverEvent.transcript || serverEvent.transcript === "\n"
            ? "[inaudible]"
            : serverEvent.transcript;
        if (itemId) {
          updateTranscriptMessage(itemId, finalTranscript, false);
        }
        break;
      }

      case "response.audio_transcript.delta": {
        const itemId = serverEvent.item_id;
        const deltaText = serverEvent.delta || "";
        if (itemId) {
          updateTranscriptMessage(itemId, deltaText, true);
         
        }
        break;
      }

      case "response.done": {
        if (serverEvent.response?.output) {
          const itemId = serverEvent.item?.id;
          const selectedAgentName = useElementsStore.getState().selectedAgentName;
          if (selectedAgentName === "patientToDoctor" || selectedAgentName === "doctorToPatient") {
            const assistantMessages = transcriptItems.filter(
              item => item.type === "MESSAGE" && item.role === "assistant" && !item.isHidden
            );
            
            const latestMessage = assistantMessages.length > 0 
              ? assistantMessages.sort((a, b) => b.createdAtMs - a.createdAtMs)[0] 
              : null;
            
            const messageTitle = latestMessage?.title || "";
            const charCount = messageTitle.length;
            const dynamicDelay = charCount * 40; // 200ms per character
            
            const finalDelay = Math.max(dynamicDelay, 3000);
            
            console.log(`Calculated delay of ${finalDelay}ms based on ${charCount} characters`);
            
            setTimeout(() => {
              console.log(`Dynamic delay complete (${finalDelay}ms) - unmuting microphone now`);
              useElementsStore.getState().setMicMuted(false);
            }, finalDelay);
          }
          serverEvent.response.output.forEach((outputItem) => {
            if (
              outputItem.type === "function_call" &&
              outputItem.name &&
              outputItem.arguments
            ) {
              handleFunctionCall({
                name: outputItem.name,
                call_id: outputItem.call_id,
                arguments: outputItem.arguments,
              });
            }
          });
        }
        break;
      }

      case "response.output_item.done": {
        const itemId = serverEvent.item?.id;
        if (itemId) {
          updateTranscriptItemStatus(itemId, "DONE");
        }
        break;
      }

      case "input_audio_buffer.speech_started": {
        // Only process this event if the selected agent is the translation coordinator
        const selectedAgentName = useElementsStore.getState().selectedAgentName;
        if (selectedAgentName === "patientToDoctor" || selectedAgentName === "doctorToPatient"||selectedAgentName === "translationCoordinator") {
          // Flag for when the user starts speaking
          const timestamp = new Date().toISOString();
          const flagId = serverEvent.event_id || generateId();
          useElementsStore.getState().setTheUserIsSpeaking(true);
          // Set assistantVoiceFinished to false when user starts speaking
          useElementsStore.getState().setAssistantVoiceFinished(false);
        }
        break;
      }

      case "input_audio_buffer.speech_stopped": {
        // Only process this event if the selected agent is the translation coordinator
        const selectedAgentName = useElementsStore.getState().selectedAgentName;
        if (selectedAgentName === "patientToDoctor" || selectedAgentName === "doctorToPatient"||selectedAgentName === "translationCoordinator") {
          // Flag for when the user stops speaking
          const timestamp = new Date().toISOString();
          const flagId = serverEvent.event_id || generateId();
          useElementsStore.getState().setTheUserIsSpeaking(false);
          
          // Mute the microphone when user stops speaking during translation
          if (selectedAgentName === "patientToDoctor" || selectedAgentName === "doctorToPatient") {
            useElementsStore.getState().setMicMuted(true);
            addTranscriptBreadcrumb(`Mic muted after user stopped speaking [${flagId}] at ${timestamp}`);
          }
        }
        break;
      }

      default:
        break;
    }
  };

  const handleServerEventRef = useRef(handleServerEvent);
  handleServerEventRef.current = handleServerEvent;

  return handleServerEventRef;
}
</file>

<file path="src/app/hooks/useOutputMonitor.ts">
"use client";
import { useEffect } from "react";

export function useOutputMonitor(
  audioElement: HTMLAudioElement | null,
  setMicMuted: (muted: boolean) => void
) {
  useEffect(() => {
    if (!audioElement) return;

    // Ensure the audio element is playing.
    if (audioElement.paused) {
      console.warn("Audio element is paused. Please ensure it is playing.");
    }

    let cancelled = false;
    let transitionToSilence = false;
    let silenceStartTime: number | null = null;
    const volumeThreshold = 10; // adjust as needed
    const silenceDurationThreshold = 1000; // 1 second

    // Create an audio context and analyser node.
    const audioContext = new AudioContext();
    const source = audioContext.createMediaElementSource(audioElement);
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = 2048;
    source.connect(analyser);
    // We don't connect the analyser to the destination to avoid affecting playback.

    const dataArray = new Uint8Array(analyser.frequencyBinCount);

    const checkOutputVolume = () => {
      if (cancelled) return;
      analyser.getByteTimeDomainData(dataArray);
      let sum = 0;
      for (let i = 0; i < dataArray.length; i++) {
        sum += Math.abs(dataArray[i] - 128);
      }
      const avg = sum / dataArray.length;
     // console.log("Output avg volume:", avg.toFixed(2));

      if (avg > volumeThreshold) {
        transitionToSilence = false;
        silenceStartTime = null;
      } else {
        if (!transitionToSilence) {
          transitionToSilence = true;
          silenceStartTime = Date.now();
        } else if (Date.now() - (silenceStartTime ?? 0) > silenceDurationThreshold) {
          console.log("Silence detected for 1 second: unmuting microphone.");
          //setMicMuted(false);
          transitionToSilence = false;
          silenceStartTime = null;
        }
      }
      requestAnimationFrame(checkOutputVolume);
    };

    checkOutputVolume();

    return () => {
      cancelled = true;
      audioContext.close();
    };
  }, [audioElement, setMicMuted]);
}
</file>

<file path="src/app/hooks/usePersistentState.ts">
// src/hooks/usePersistentState.ts
import { useState, useEffect } from "react";

export function usePersistentState<T>(key: string, defaultValue: T) {
  const [state, setState] = useState<T>(() => {
    if (typeof window === "undefined") return defaultValue;
    const stored = localStorage.getItem(key);
    return stored ? JSON.parse(stored) : defaultValue;
  });

  useEffect(() => {
    localStorage.setItem(key, JSON.stringify(state));
  }, [key, state]);

  return [state, setState] as const;
}
</file>

<file path="src/app/hooks/useSendClientEvent.ts">
"use client";

import { useElementsStore } from "@/store/elementsStore";
import { useEvent } from "@/app/contexts/EventContext";

export function useSendClientEvent() {
  const { dcRef } = useElementsStore();
  const { logClientEvent } = useEvent();

  const sendClientEvent = (eventObj: any, eventNameSuffix = "") => {
    if (dcRef.current && dcRef.current.readyState === "open") {
      logClientEvent(eventObj, eventNameSuffix);
      dcRef.current.send(JSON.stringify(eventObj));
    } else {
      logClientEvent(
        { attemptedEvent: eventObj.type },
        "error.data_channel_not_open"
      );
      console.error(
        "Failed to send message - no data channel available",
        eventObj
      );
    }
  };

  return sendClientEvent;
}
</file>

<file path="src/app/hooks/useSendEmail.ts">
import { useEffect, useState } from 'react';
import { useElementsStore } from '@/store/elementsStore';

interface UseSendEmailProps {
  data: string | { html: string; plainText: string };
}

type EmailResponse = {
  success: boolean;
  message: string;
};

export const useSendEmail = ({ data }: UseSendEmailProps) => {
  const { sendEmailStatus, setSendEmailStatus } = useElementsStore();
  const [response, setResponse] = useState<EmailResponse | null>(null);

  useEffect(() => {
    // Only proceed if emailStatus is 'sending'
    if (sendEmailStatus !== 'sending') {
      if (response !== null) {
        setResponse(null);
      }
      return;
    }
    
    async function sendEmail() {
      try {
        if (!data) {
          console.warn("No data available to send");
          setSendEmailStatus('idle');
          setResponse({
            success: false,
            message: 'No data available to send'
          });
          return;
        }
        
        let plainTextData: string;
        let htmlData: string | undefined;
        let subject: string;
        
        if (typeof data === 'string') {
          plainTextData = data.replace(/<[^>]*>/g, '');
          subject = plainTextData.split(" ").slice(0, 10).join(" ") + "...";
          const containsHtml = /<[a-z][\s\S]*>/i.test(data);
          htmlData = containsHtml ? data : undefined;
        } else {
          plainTextData = data.plainText;
          htmlData = data.html;
          subject = plainTextData.split(" ").slice(0, 10).join(" ") + "...";
        }
        
        const res = await fetch("/api/sendEmail", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            to: "farhat.rassi@eih.ae",
            subject,
            text: plainTextData,
            html: htmlData,
            isHtml: !!htmlData
          }),
        });
        const responseData = await res.json();
        console.log(responseData.message || responseData.error);
        setSendEmailStatus('done');
        setResponse({
          success: !responseData.error,
          message: responseData.message || responseData.error || ''
        });
      } catch (error: any) {
        console.error("Error sending email:", error);
        setSendEmailStatus('idle');
        setResponse({
          success: false,
          message: error.message || 'Error sending email'
        });
      }
    }
    
    sendEmail();
    
  }, [sendEmailStatus, setSendEmailStatus, data]);

  return response;
};

export default useSendEmail;
</file>

<file path="src/app/hooks/useSendSimulatedUserMessage.ts">
"use client";

import { v4 as uuidv4 } from "uuid";
import { useTranscript } from "@/app/contexts/TranscriptContext";
import { useSendClientEvent } from "./useSendClientEvent";

export function useSendSimulatedUserMessage() {
  const { addTranscriptMessage } = useTranscript();
  const sendClientEvent = useSendClientEvent();

  const sendSimulatedUserMessage = (text: string) => {
    const id = uuidv4().slice(0, 32);
    addTranscriptMessage(id, "user", text, true);

    sendClientEvent(
      {
        type: "conversation.item.create",
        item: {
          id,
          type: "message",
          role: "user",
          content: [{ type: "input_text", text }],
        },
      },
      "(simulated user text message)"
    );
    sendClientEvent(
      { type: "response.create" },
      "(trigger response after simulated user text message)"
    );
  };
  return sendSimulatedUserMessage;
}
</file>

<file path="src/app/hooks/useUpdateSession.ts">
"use client";

import { useState, useEffect } from "react";
import { useElementsStore } from "@/store/elementsStore";
import { usePatientDataStore } from "@/store/patientDataStore";
import { useSendClientEvent } from "./useSendClientEvent";
import { useSendSimulatedUserMessage } from "./useSendSimulatedUserMessage";
import createDoctorToPatientAgent from "../agentConfigs/doctorDtwin/doctorToPatient";
import createPatientToDoctorAgent from "../agentConfigs/doctorDtwin/patientToDoctor";

export function useUpdateSession() {
  const { selectedAgentName, selectedAgentConfigSet } = useElementsStore();
  const sendClientEvent = useSendClientEvent();
  const sendSimulatedUserMessage = useSendSimulatedUserMessage();

  // Retrieve languageSpoken and languagesContext from the store.
  const { languageSpoken, languagesContext, setLanguageSpoken } = usePatientDataStore();

  // Local state for chosen agent based on detected language.
  const [chosenAgent, setChosenAgent] = useState<string | undefined>(undefined);

  // When languageSpoken changes, update chosenAgent accordingly.
  useEffect(() => {
    if (!languageSpoken) {
      setChosenAgent(undefined);
      return;
    }
    // Convert everything to lower case for comparison.
    const detected = languageSpoken.toLowerCase();
    const doctorLang = languagesContext.doctorLanguage?.toLowerCase();
    const patientLang = languagesContext.patientLanguage?.toLowerCase();

    // If the detected language matches the doctor's language,
    // then the doctor is speaking so we want the agent that translates from doctor to patient.
    if (detected === doctorLang) {
      setChosenAgent("doctorToPatient");
    }
    // If the detected language matches the patient's language,
    // then the patient is speaking so we want the agent that translates from patient to doctor.
    else if (detected === patientLang) {
      setChosenAgent("patientToDoctor");
    } else {
      setChosenAgent(undefined);
    }
  }, [languageSpoken, languagesContext]);

  const updateSession = (shouldTriggerResponse: boolean = false, isPTTActive: boolean) => {
    let currentAgent: any;

    // If a chosenAgent has been determined via the detected language, use that.
    if (chosenAgent) {
      if (chosenAgent === "doctorToPatient") {
        currentAgent = createDoctorToPatientAgent();
      } else if (chosenAgent === "patientToDoctor") {
        currentAgent = createPatientToDoctorAgent();
      }
    }
    // Otherwise, fall back to the default behavior (back-and-forth switching).
    else {
      if (selectedAgentName === "doctorToPatient") {
        currentAgent = createDoctorToPatientAgent();
      } else if (selectedAgentName === "patientToDoctor") {
        currentAgent = createPatientToDoctorAgent();
      } else {
        currentAgent = selectedAgentConfigSet?.find((a) => a.name === selectedAgentName);
      }
    }

    if (!currentAgent) return;

    // Only clear the audio buffer if the current agent is not one of our translation agents.
    if (currentAgent.name !== "doctorToPatient" && currentAgent.name !== "patientToDoctor") {
      sendClientEvent(
        { type: "input_audio_buffer.clear" },
        "clear audio buffer on session update"
      );
    }

    let sessionUpdateEvent: any;
    if (currentAgent.name === "doctorToPatient" || currentAgent.name === "patientToDoctor") {
      shouldTriggerResponse = true;
      const turnDetection = isPTTActive
        ? null
        : {
            type: "server_vad",
            threshold: 0.6,
            prefix_padding_ms: 300,
            silence_duration_ms: 1000,
            create_response: true,
          };

      sessionUpdateEvent = {
        type: "session.update",
        session: {
          modalities: ["text", "audio"],
          instructions: currentAgent.instructions,
          input_audio_format: "pcm16",
          output_audio_format: "pcm16",
          input_audio_transcription: { model: "whisper-1" },
          turn_detection: turnDetection,
          tools: currentAgent.tools,
        },
      };
    } else {
      const turnDetection = isPTTActive
        ? null
        : {
            type: "server_vad",
            threshold: 0.6,
            prefix_padding_ms: 300,
            silence_duration_ms: 800,
            create_response: true,
          };

      sessionUpdateEvent = {
        type: "session.update",
        session: {
          modalities: ["text", "audio"],
          instructions: currentAgent.instructions,
          voice: "sage",
          input_audio_format: "pcm16",
          output_audio_format: "pcm16",
          input_audio_transcription: { model: "whisper-1" },
          turn_detection: turnDetection,
          tools: currentAgent.tools,
        },
      };
    }

    sendClientEvent(sessionUpdateEvent);
    if (shouldTriggerResponse && currentAgent.name !== "doctorToPatient" && currentAgent.name !== "patientToDoctor") {
      sendSimulatedUserMessage("hello assistant");
    }
    // After updating the session, reset languageSpoken and chosenAgent so a new segment can be processed.
    setLanguageSpoken("");
    setChosenAgent(undefined);
  };

  return updateSession;
}
</file>

<file path="src/app/lib/allowedLanguages.ts">
/**
 * List of supported languages for translation
 */
export const ALLOWED_LANGUAGES = [
  "Afrikaans",
  "Arabic",
  "Armenian",
  "Azerbaijani",
  "Belarusian",
  "Bosnian",
  "Bulgarian",
  "Catalan",
  "Chinese",
  "Croatian",
  "Czech",
  "Danish",
  "Dutch",
  "English",
  "Estonian",
  "Finnish",
  "French",
  "Galician",
  "German",
  "Greek",
  "Hebrew",
  "Hindi",
  "Hungarian",
  "Icelandic",
  "Indonesian",
  "Italian",
  "Japanese",
  "Kannada",
  "Kazakh",
  "Korean",
  "Latvian",
  "Lithuanian",
  "Macedonian",
  "Malay",
  "Marathi",
  "Maori",
  "Nepali",
  "Norwegian",
  "Persian",
  "Polish",
  "Portuguese",
  "Romanian",
  "Russian",
  "Serbian",
  "Slovak",
  "Slovenian",
  "Spanish",
  "Swahili",
  "Swedish",
  "Tagalog",
  "Tamil",
  "Thai",
  "Turkish",
  "Ukrainian",
  "Urdu",
  "Vietnamese",
  "Welsh"
];

export default ALLOWED_LANGUAGES;
</file>

<file path="src/app/lib/realtimeConnection.ts">
import { RefObject } from "react";

export async function createRealtimeConnection(
  EPHEMERAL_KEY: string,
  audioElement: RefObject<HTMLAudioElement | null>,
  micStream: MediaStream
): Promise<{ pc: RTCPeerConnection; dc: RTCDataChannel }> {
  const pc = new RTCPeerConnection();

  pc.ontrack = (e) => {
    if (audioElement.current) {
        audioElement.current.srcObject = e.streams[0];
    }
  };

  // Add the provided microphone stream to the peer connection
  pc.addTrack(micStream.getTracks()[0]);

  const dc = pc.createDataChannel("oai-events");

  const offer = await pc.createOffer();
  await pc.setLocalDescription(offer);

  const baseUrl = "https://api.openai.com/v1/realtime";
  const model = "gpt-4o-realtime-preview-2024-12-17";

  const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {
    method: "POST",
    body: offer.sdp,
    headers: {
      Authorization: `Bearer ${EPHEMERAL_KEY}`,
      "Content-Type": "application/sdp",
    },
  });

  const answerSdp = await sdpResponse.text();
  const answer: RTCSessionDescriptionInit = {
    type: "answer",
    sdp: answerSdp,
  };

  await pc.setRemoteDescription(answer);

  return { pc, dc };
}
</file>

<file path="src/app/utils/cn.ts">
import { type ClassValue, clsx } from "clsx";
import { twMerge } from "tailwind-merge";

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs));
}
</file>

<file path="src/app/App.tsx">
"use client";

import React, { useEffect, useRef, useState } from "react";
import { useSearchParams } from "next/navigation";
import { v4 as uuidv4 } from "uuid";
import Image from "next/image";

// UI components
import Eih from "./components/Eih";
import Transcript from "./components/Transcript";
import Events from "./components/Events";
import SurgeryInfoNeeded from "./components/SurgeryInfoNeeded";
import BottomToolbar from "./components/BottomToolbar";
import SurgicalScribePage from "./components/surgicalScribePage";
import TranslationsPage from "./components/TranslationsPage";
import PrintableForm from "./components/printableForm"; // Import PrintableForm

// Types
import { AgentConfig, SessionStatus } from "@/app/types";

// Context providers & hooks
import { useConnection } from "./hooks/useConnection";
import { useTranscript } from "@/app/contexts/TranscriptContext";
import { useEvent } from "@/app/contexts/EventContext";
import { useHandleServerEvent } from "./hooks/useHandleServerEvent";
import { useSendClientEvent } from "./hooks/useSendClientEvent";
import { useSendSimulatedUserMessage } from "./hooks/useSendSimulatedUserMessage";
import { useUpdateSession } from "./hooks/useUpdateSession";
import { useSendEmail } from "./hooks/useSendEmail";
import { useCancelAssistantSpeech } from "./hooks/useCancelAssistantSpeech";
import { useHandleSendTextMessage } from "./hooks/useHandleSendTextMessage";
import { usePersistentState } from "./hooks/usePersistentState";
// Import our new audio output monitor hook
import { useOutputMonitor } from "@/app/hooks/useOutputMonitor";

// Utilities
import { createRealtimeConnection } from "./lib/realtimeConnection";

// Agent configs
import { allAgentSets, defaultAgentSetKey } from "@/app/agentConfigs";
import { useElementsStore } from "@/store/elementsStore";

function App() {
  const searchParams = useSearchParams();
  const { transcriptItems, addTranscriptMessage, addTranscriptBreadcrumb } =
    useTranscript();
  const { logClientEvent, logServerEvent } = useEvent();
  const [initialGreetingSent, setInitialGreetingSent] = useState(false);
  const { 
    sessionStatus, setSessionStatus, 
    pcRef, dcRef, dataChannel, setDataChannel, 
    audioElementRef, selectedAgentName, setSelectedAgentName, 
    selectedAgentConfigSet, setSelectedAgentConfigSet, 
    userText, setUserText, surgeryInfoNeeded,
    loadSurgicalPage, showTranslationsPage,
    micRef, micMuted, setMicMuted,
    createRequest // Get createRequest flag
  } = useElementsStore();

  // State to track the microphone stream
  const [micStream, setMicStream] = useState<MediaStream | null>(null);

  const audioConnectionRef = useRef<{
    audioContext: AudioContext | null;
    connected: boolean
  }>({
    audioContext: null,
    connected: false
  });

  const [isPTTUserSpeaking, setIsPTTUserSpeaking] = useState<boolean>(false);
  const [isPTTActive, setIsPTTActive] = usePersistentState("pushToTalkUI", false);
  const [isEventsPaneExpanded, setIsEventsPaneExpanded] = usePersistentState("logsExpanded", true);
  const [isAudioPlaybackEnabled, setIsAudioPlaybackEnabled] = usePersistentState("audioPlaybackEnabled", true);

  const handleServerEventRef = useHandleServerEvent();
  const sendClientEvent = useSendClientEvent();
  const { connectToRealtime, disconnectFromRealtime } = useConnection();
  const sendSimulatedUserMessage = useSendSimulatedUserMessage();
  const updateSession = useUpdateSession();
  const cancelAssistantSpeech = useCancelAssistantSpeech();
  const handleSendTextMessage = useHandleSendTextMessage();

  // Initialize microphone and store it.
  const initializeMicrophone = async (): Promise<MediaStream | null> => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      setMicStream(stream);
      micRef.current = stream;
      return stream;
    } catch (error) {
      console.error("Error accessing microphone:", error);
      return null;
    }
  };

  // Control microphone tracks based on micMuted flag.
  useEffect(() => {
    if (!micStream) return;
    console.log(`Setting microphone ${micMuted ? 'muted' : 'unmuted'}`);
    micStream.getAudioTracks().forEach(track => {
      track.enabled = !micMuted;
    });
  }, [micMuted, micStream]);

  // Import the new output monitor hook to update micMuted based on playback volume.
  useOutputMonitor(audioElementRef.current, setMicMuted);

  useEffect(() => {
    let finalAgentConfig = searchParams.get("agentConfig");
    if (!finalAgentConfig || !allAgentSets[finalAgentConfig]) {
      finalAgentConfig = defaultAgentSetKey;
      const url = new URL(window.location.toString());
      url.searchParams.set("agentConfig", finalAgentConfig);
      window.location.replace(url.toString());
      return;
    }
    const agents = allAgentSets[finalAgentConfig];
    const agentKeyToUse = agents[0]?.name || "";
    setSelectedAgentName(agentKeyToUse);
    setSelectedAgentConfigSet(agents);
  }, [searchParams]);

  useEffect(() => {
    const setupConnection = async () => {
      if (selectedAgentName && sessionStatus === "DISCONNECTED") {
        const stream = await initializeMicrophone();
        if (stream) {
          connectToRealtime(isAudioPlaybackEnabled, handleServerEventRef, stream);
        } else {
          console.error("Failed to initialize microphone");
        }
      }
    };
    setupConnection();
  }, [selectedAgentName]);

  useEffect(() => {
    if (
      sessionStatus === "CONNECTED" &&
      selectedAgentConfigSet &&
      selectedAgentName
    ) {
      const currentAgent = selectedAgentConfigSet.find(
        (a) => a.name === selectedAgentName
      );
      addTranscriptBreadcrumb(`Agent: ${selectedAgentName}`, currentAgent);
      if (!initialGreetingSent) {
        updateSession(true, isPTTActive);
        setInitialGreetingSent(true);
      } else {
        updateSession(true, isPTTActive);
      }
    }
  }, [selectedAgentConfigSet, selectedAgentName, sessionStatus]);

  const changeAgent = (agentName: string) => {
    setSelectedAgentName(agentName);
  };

  useEffect(() => {
    if (sessionStatus === "CONNECTED") {
      console.log(
        `updatingSession, isPTTActive=${isPTTActive} sessionStatus=${sessionStatus}`
      );
      updateSession(false, isPTTActive);
    }
  }, [isPTTActive]);

  const handleTalkButtonDown = () => {
    if (sessionStatus !== "CONNECTED" || dataChannel?.readyState !== "open")
      return;
    cancelAssistantSpeech();
    setIsPTTUserSpeaking(true);
    sendClientEvent({ type: "input_audio_buffer.clear" }, "clear PTT buffer");
  };

  const handleTalkButtonUp = () => {
    if (
      sessionStatus !== "CONNECTED" ||
      dataChannel?.readyState !== "open" ||
      !isPTTUserSpeaking
    )
      return;
    setIsPTTUserSpeaking(false);
    sendClientEvent({ type: "input_audio_buffer.commit" }, "commit PTT");
    sendClientEvent({ type: "response.create" }, "trigger response PTT");
  };

  const onToggleConnection = async () => {
    if (sessionStatus === "CONNECTED" || sessionStatus === "CONNECTING") {
      disconnectFromRealtime();
      if (micStream) {
        micStream.getTracks().forEach(track => track.stop());
        setMicStream(null);
        micRef.current = null;
      }
      setIsPTTUserSpeaking(false);
      setSessionStatus("DISCONNECTED");
    } else {
      const stream = await initializeMicrophone();
      if (stream) {
        connectToRealtime(isAudioPlaybackEnabled, handleServerEventRef, stream);
      } else {
        console.error("Failed to initialize microphone");
      }
    }
  };

  const handleAgentChange = (e: React.ChangeEvent<HTMLSelectElement>) => {
    const newAgentConfig = e.target.value;
    const url = new URL(window.location.toString());
    url.searchParams.set("agentConfig", newAgentConfig);
    window.location.replace(url.toString());
  };

  const handleSelectedAgentChange = (e: React.ChangeEvent<HTMLSelectElement>) => {
    const newAgentName = e.target.value;
    setSelectedAgentName(newAgentName);
  };

  useEffect(() => {
    if (audioElementRef.current) {
      if (isAudioPlaybackEnabled) {
        audioElementRef.current.play().catch((err) => {
          console.warn("Autoplay may be blocked by browser:", err);
        });
      } else {
        audioElementRef.current.pause();
      }
    }
  }, [isAudioPlaybackEnabled]);

  const agentSetKey = searchParams.get("agentConfig") || "default";

  return (
    <div className="text-base flex flex-col h-screen text-gray-800 relative rounded-md">
      <div className="p-5 text-lg font-semibold flex justify-between items-center">
        <div className="flex items-center">
          <div onClick={() => window.location.reload()} style={{ cursor: 'pointer' }}>
            <Image
              src="/openai-logomark.svg"
              alt="OpenAI Logo"
              width={30}
              height={30}
              className="mr-2"
            />
          </div>
          <div className="flex items-center">
            <div className="text-black ">
              Emirates International Hospital <span className="text-red-900">digital twin</span>
            </div>
          </div>
        </div>
        <div className="flex items-center">
          <label className="flex items-center text-base gap-1 mr-2 font-medium">
            ExpertiseDomain
          </label>
          <div className="relative inline-block">
            <select
              value={agentSetKey}
              onChange={handleAgentChange}
              className="appearance-none border border-gray-300 rounded-lg text-base px-2 py-1 pr-8 cursor-pointer font-normal focus:outline-none"
            >
              {Object.keys(allAgentSets).map((agentKey) => (
                <option key={agentKey} value={agentKey}>
                  {agentKey}
                </option>
              ))}
            </select>
            <div className="pointer-events-none absolute inset-y-0 right-0 flex items-center pr-2 text-gray-600">
              <svg className="h-4 w-4" viewBox="0 0 20 20" fill="currentColor">
                <path
                  fillRule="evenodd"
                  d="M5.23 7.21a.75.75 0 011.06.02L10 10.44l3.71-3.21a.75.75 0 111.04 1.08l-4.25 3.65a.75.75 0 01-1.04 0L5.21 8.27a.75.75 0 01.02-1.06z"
                  clipRule="evenodd"
                />
              </svg>
            </div>
          </div>
          {agentSetKey && (
            <div className="flex items-center ml-6">
              <label className="flex items-center text-base gap-1 mr-2 font-medium">
                currentHelper
              </label>
              <div className="text-sm font-medium px-2 py-1 bg-gray-100 rounded">
                {selectedAgentName}
              </div>
            </div>
          )}
        </div>
      </div>
      <div className="flex flex-1 gap-2 px-2 overflow-hidden relative">
        <Eih />
        {loadSurgicalPage ? (
          <SurgicalScribePage />
        ) : surgeryInfoNeeded?.current ? (
          <SurgeryInfoNeeded />
        ) : showTranslationsPage ? (
          <TranslationsPage changeAgent={changeAgent} />
        ) : createRequest ? ( // Check createRequest flag
          <PrintableForm /> // Render PrintableForm if true
        ) : (
          <Events isExpanded={isEventsPaneExpanded} />
        )}
      </div>
      <BottomToolbar
        onToggleConnection={onToggleConnection}
        isPTTActive={isPTTActive}
        setIsPTTActive={setIsPTTActive}
        isPTTUserSpeaking={isPTTUserSpeaking}
        handleTalkButtonDown={handleTalkButtonDown}
        handleTalkButtonUp={handleTalkButtonUp}
        isEventsPaneExpanded={isEventsPaneExpanded}
        setIsEventsPaneExpanded={setIsEventsPaneExpanded}
        isAudioPlaybackEnabled={isAudioPlaybackEnabled}
        setIsAudioPlaybackEnabled={setIsAudioPlaybackEnabled}
      />
    </div>
  );
}

export default App;
</file>

<file path="src/app/globals.css">
@tailwind base;
@tailwind components;
@tailwind utilities;

:root {
  --background: #fafafa;
  --foreground: #171717;
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

body {
  color: var(--foreground);
  background: var(--background);
  font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
    "Helvetica Neue", Arial, "Noto Sans", sans-serif;
}
</file>

<file path="src/app/layout.tsx">
import type { Metadata } from "next";
import "./globals.css";
import { TranscriptProvider } from "@/app/contexts/TranscriptContext";
import { EventProvider } from "@/app/contexts/EventContext";
// ElementsProvider removed - using zustand directly

export const metadata: Metadata = {
  title: "HealthCare Digital Twin",
  description: "A demo app written by Rassifarhat.",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body className={`antialiased`}>
        <EventProvider>
          <TranscriptProvider>
            {children}
          </TranscriptProvider>
        </EventProvider>
      </body>
    </html>
  );
}
</file>

<file path="src/app/page.tsx">
// app/page.tsx
"use client";
import React, { useEffect, useState } from "react";

import App from "./App";
import { motion } from "framer-motion";
import { useElementsStore } from "@/store/elementsStore";
import StarryBackground from "./components/UI/StarryBackground";

export default function Page() {
  const { theUserIsSpeaking } = useElementsStore();
  const [speaking, setSpeaking] = useState(false);

  // Update speaking state when theUserIsSpeaking changes
  useEffect(() => {
    // Direct state update - no need for interval
    if (theUserIsSpeaking !== speaking) {
      setSpeaking(theUserIsSpeaking);
    }
  }, [theUserIsSpeaking]); // Only depend on theUserIsSpeaking to prevent infinite loops

  return (
    <div className="relative w-screen h-screen overflow-hidden">
      {/* Full-screen animated background */}
      <motion.div
        key={speaking ? "speaking" : "not-speaking"}
        initial={{ opacity: 0, scale: 0.98 }}
        animate={{ opacity: 1, scale: 1.02 }}
        transition={{ 
          duration: speaking ? 0.5 : 1000,
          repeat: Infinity, 
          repeatType: "reverse", 
          ease: "easeInOut" 
        }}
        className={`absolute inset-0 z-0 rounded-md ${speaking ? 'bg-red-500' : 'bg-red-600'}`}
      />
      
      {/* Static App container with a 2px inset */}
      <div 
        className="absolute z-10" 
        style={{ top: "10px", right: "10px", bottom: "10px", left: "10px" }}
      >
       
       <StarryBackground>
        <App />
      </StarryBackground>
      
      </div>
    </div>
  );
}
</file>

<file path="src/app/types.ts">
export type SessionStatus = "DISCONNECTED" | "CONNECTING" | "CONNECTED";

export interface ToolParameterProperty {
  type: string;
  description?: string;
  enum?: string[];
  pattern?: string;
  properties?: Record<string, ToolParameterProperty>;
  required?: string[];
  additionalProperties?: boolean;
  items?: ToolParameterProperty;
}

export interface ToolParameters {
  type: string;
  properties: Record<string, ToolParameterProperty>;
  required?: string[];
  additionalProperties?: boolean;
}

export interface Tool {
  type: "function";
  name: string;
  description: string;
  parameters: ToolParameters;
}

export interface AgentConfig {
  name: string;
  publicDescription: string; // gives context to agent transfer tool
  instructions: string;
  tools: Tool[];
  toolLogic?: Record<
    string,
    (args: any, transcriptLogsFiltered: TranscriptItem[]) => Promise<any> | any
  >;
  downstreamAgents?: AgentConfig[] | { name: string; publicDescription: string }[];
}

export type AllAgentConfigsType = Record<string, AgentConfig[]>;

export interface TranscriptItem {
  itemId: string;
  type: "MESSAGE" | "BREADCRUMB";
  role?: "user" | "assistant";
  title?: string;
  data?: Record<string, any>;
  expanded: boolean;
  timestamp: string;
  createdAtMs: number;
  status: "IN_PROGRESS" | "DONE";
  isHidden: boolean;
}

export interface Log {
  id: number;
  timestamp: string;
  direction: string;
  eventName: string;
  data: any;
  expanded: boolean;
  type: string;
}

export interface ServerEvent {
  type: string;
  event_id?: string;
  item_id?: string;
  transcript?: string;
  delta?: string;
  session?: {
    id?: string;
  };
  item?: {
    id?: string;
    object?: string;
    type?: string;
    status?: string;
    name?: string;
    arguments?: string;
    role?: "user" | "assistant";
    content?: {
      type?: string;
      transcript?: string | null;
      text?: string;
    }[];
  };
  response?: {
    output?: {
      type?: string;
      name?: string;
      arguments?: any;
      call_id?: string;
    }[];
    status_details?: {
      error?: any;
    };
  };
}

export interface LoggedEvent {
  id: number;
  direction: "client" | "server";
  expanded: boolean;
  timestamp: string;
  eventName: string;
  eventData: Record<string, any>; // can have arbitrary objects logged
}
</file>

<file path="src/store/elementsStore.ts">
// src/store/elementsStore.ts
import { create } from "zustand";
import { AgentConfig, SessionStatus } from "@/app/types";
import { RefObject, createRef } from "react";

// Define a type for email status
export type EmailStatus = 'idle' | 'sending' | 'done';

interface ElementsState {
  // Agent-related state
  selectedAgentName: string;
  selectedAgentConfigSet: AgentConfig[] | null;
  setSelectedAgentName: (name: string) => void;
  setSelectedAgentConfigSet: (configSet: AgentConfig[] | null) => void;
  
  // Connection-related state
  dataChannel: RTCDataChannel | null;
  sessionStatus: SessionStatus;
  setDataChannel: (dc: RTCDataChannel | null) => void;
  setSessionStatus: (status: SessionStatus) => void;
  
  // User input state
  userText: string;
  setUserText: (text: string) => void;
  
  // TranslationsPage flags
  showTranslationsPage: boolean;
  setShowTranslationsPage: (show: boolean) => void;
  theUserIsSpeaking: boolean;
  setTheUserIsSpeaking: (speaking: boolean) => void;
  assistantVoiceFinished: boolean;
  setAssistantVoiceFinished: (finished: boolean) => void;
  micMuted: boolean;
  setMicMuted: (muted: boolean) => void;
  
  // Surgery info state
  surgeryInfoNeeded: RefObject<boolean | null>;
  setSurgeryInfoNeeded: (needed: boolean) => void;
  
  // Surgical page state
  loadSurgicalPage: boolean;
  setLoadSurgicalPage: (load: boolean) => void;
  
  // Email status state
  sendEmailStatus: EmailStatus;
  setSendEmailStatus: (status: EmailStatus) => void;
  createRequest: boolean;
  setCreateRequest: (create: boolean) => void;
  // Show request data flag
  showRequestData: boolean;
  setShowRequestData: (show: boolean) => void;
  
  // Refs
  pcRef: RefObject<RTCPeerConnection | null>;
  dcRef: RefObject<RTCDataChannel | null>;
  audioElementRef: RefObject<HTMLAudioElement | null>;
  micRef: RefObject<MediaStream | null>;
}

export const useElementsStore = create<ElementsState>((set) => ({
  // Agent-related state
  selectedAgentName: "",
  selectedAgentConfigSet: null,
  setSelectedAgentName: (name) => { 
    //console.log("SelectedAgentName", name);
    set({ selectedAgentName: name })},
    
  setSelectedAgentConfigSet: (configSet) => set({ selectedAgentConfigSet: configSet }),
  
  // Connection-related state
  dataChannel: null,
  sessionStatus: "DISCONNECTED",
  setDataChannel: (dc) => set({ dataChannel: dc }),
  setSessionStatus: (status) => set({ sessionStatus: status }),
  
  // User input state
  userText: "",
  setUserText: (text) => set({ userText: text }),
  
  // TranslationsPage flags - defaults to false
  showTranslationsPage: false,
  setShowTranslationsPage: (show) => set({ showTranslationsPage: show }),
  theUserIsSpeaking: false,
  setTheUserIsSpeaking: (speaking) => {
    console.log("store: TheUserIsSpeaking", speaking);
    set({ theUserIsSpeaking: speaking })},
  assistantVoiceFinished: false,
  setAssistantVoiceFinished: (finished) => {
    console.log("store: AssistantVoiceFinished", finished);
    set({ assistantVoiceFinished: finished })},
  micMuted: false,
  setMicMuted: (muted) => {
    console.log("store: MicMuted", muted);
    set({ micMuted: muted })
  },
  
  // Surgery info state - defaults to false
  surgeryInfoNeeded: (() => {
    const ref = createRef<boolean | null>();
    ref.current = false; // Initialize with false
    return ref;
  })(),
  setSurgeryInfoNeeded: (needed) => {
    if (useElementsStore.getState().surgeryInfoNeeded.current !== needed) {
      useElementsStore.getState().surgeryInfoNeeded.current = needed;
    }
  },
  
  // Surgical page state - defaults to false
  loadSurgicalPage: false,
  setLoadSurgicalPage: (load) => set({ loadSurgicalPage: load }),
  
  // Email status state - defaults to 'idle'
  sendEmailStatus: 'idle',
  setSendEmailStatus: (status) => set({ sendEmailStatus: status }),
  
  // Create request flag - defaults to false
  createRequest: false,
  setCreateRequest: (create) => set({ createRequest: create }),
  
  // Show request data flag - defaults to false
  showRequestData: false,
  setShowRequestData: (show) => set({ showRequestData: show }),
  
  // Refs (initialized once)
  pcRef: createRef<RTCPeerConnection | null>(),
  dcRef: createRef<RTCDataChannel | null>(),
  audioElementRef: createRef<HTMLAudioElement | null>(),
  micRef: createRef<MediaStream | null>(),
}))
</file>

<file path="src/store/patientDataStore.ts">
// src/store/patientDataStore.ts
import { create } from "zustand";

// Define the languages context interface
export interface LanguagesContext {
  patientLanguage: string;
  doctorLanguage: string;
}

export interface PatientDataForRequestType {
  complaint: string;
  diagnosis: string;
  plan: string;
  cptCode: string;
}

interface PatientDataState {
  // Patient surgical data
  patientSurgicalData: string;
  
  // Language information
  languageSpoken: string;
  setLanguageSpoken: (language: string) => void;
  
  // Languages context
  languagesContext: LanguagesContext;
  setLanguagesContext: (context: LanguagesContext) => void;
  
  // Translation text
  translationText: string;
  setTranslationText: (text: string) => void;
  
  // Operations for patient surgical data
  setPatientSurgicalData: (data: string) => void;
  appendPatientSurgicalData: (data: string) => void;
  clearPatientSurgicalData: () => void;
  
  // Patient data for request
  patientDataForRequest: PatientDataForRequestType;
  setPatientDataForRequest: (data: PatientDataForRequestType) => void;
}

export const usePatientDataStore = create<PatientDataState>((set) => ({
  // Initialize with empty string
  patientSurgicalData: "",
  
  // Initialize language information with empty value
  languageSpoken: "",
  setLanguageSpoken: (language) => {
    set({ 
    languageSpoken: language 
  })},
  
  // Initialize languages context with empty values
  languagesContext: {
    patientLanguage: "",
    doctorLanguage: ""
  },
  setLanguagesContext: (context) => { 
    set({ 
    languagesContext: context 
  })},
  
  // Initialize translation text with empty value
  translationText: "",
  setTranslationText: (text) => set({ 
    translationText: text 
  }),
  
  // Set patient surgical data (replaces existing data)
  setPatientSurgicalData: (data) => set({ 
    patientSurgicalData: data 
  }),
  
  // Append to existing patient surgical data
  appendPatientSurgicalData: (data) => set((state) => ({ 
    patientSurgicalData: state.patientSurgicalData + data 
  })),
  
  // Clear patient surgical data
  clearPatientSurgicalData: () => set({ 
    patientSurgicalData: "" 
  }),
  
  // Initialize patient data for request with default values
  patientDataForRequest: {
    complaint: " default ",
    diagnosis: " default ",
    plan: " default ",
    cptCode: " default ",
  },
  setPatientDataForRequest: (data) => set({
    patientDataForRequest: data
  }),
}));
</file>

<file path=".gitignore">
# dependencies
/node_modules
/.pnp
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files (can opt-in for committing if needed)
.env*

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts
todo.md
</file>

<file path="eslint.config.mjs">
import { dirname } from "path";
import { fileURLToPath } from "url";
import { FlatCompat } from "@eslint/eslintrc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const compat = new FlatCompat({
  baseDirectory: __dirname,
});

const eslintConfig = [
  ...compat.extends("next/core-web-vitals", "next/typescript"),
  {
    rules: {
      "@typescript-eslint/no-explicit-any": "off",
      "react-hooks/exhaustive-deps": "off"
    },
  },
];

export default eslintConfig;
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 OpenAI

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
</file>

<file path="next.config.ts">
import type { NextConfig } from "next";

const nextConfig: NextConfig = {
  /* config options here */
};

export default nextConfig;
</file>

<file path="package.json">
{
  "name": "realtime-examples",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@ai-sdk/openai": "^2.0.86",
    "@ai-sdk/react": "^2.0.115",
    "@types/three": "^0.174.0",
    "ai": "^5.0.113",
    "axios": "^1.8.2",
    "clsx": "^2.1.1",
    "framer-motion": "^12.4.7",
    "franc": "^6.2.0",
    "lucide-react": "^0.477.0",
    "marked": "^15.0.7",
    "next": "^15.2.4",
    "nodemailer": "^7.0.11",
    "openai": "^4.77.3",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "react-icons": "^5.5.0",
    "react-markdown": "^9.0.3",
    "react-to-print": "^3.0.5",
    "tailwind-merge": "^3.0.2",
    "three": "^0.174.0",
    "uuid": "^11.0.4",
    "zustand": "^5.0.3"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@types/node": "^20",
    "@types/nodemailer": "^7.0.4",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "eslint": "^9",
    "eslint-config-next": "15.1.4",
    "postcss": "^8",
    "tailwindcss": "^3.4.1",
    "typescript": "^5"
  }
}
</file>

<file path="postcss.config.mjs">
/** @type {import('postcss-load-config').Config} */
const config = {
  plugins: {
    tailwindcss: {},
  },
};

export default config;
</file>

<file path="README.md">

</file>

<file path="tailwind.config.ts">
import type { Config } from "tailwindcss";

export default {
  content: [
    "./src/pages/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/components/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/app/**/*.{js,ts,jsx,tsx,mdx}",
  ],
  theme: {
    extend: {
      colors: {
        background: "var(--background)",
        foreground: "var(--foreground)",
        health: {
          light: "#dddddd",
          normal: "#999999",
          dark: "#555555",
          verydark: "#333333",
        },
      },
    },
  },
  plugins: [],
} satisfies Config;
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts", "src/app/components/surgicalScribePage"],
  "exclude": ["node_modules"]
}
</file>

</files>
